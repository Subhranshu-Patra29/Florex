manage.py

#!/usr/bin/env python
"""Django's command-line utility for administrative tasks."""
import os
import sys


def main():
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'House.settings')
    try:
        from django.core.management import execute_from_command_line
    except ImportError as exc:
        raise ImportError(
            "Couldn't import Django. Are you sure it's installed and "
            "available on your PYTHONPATH environment variable? Did you "
            "forget to activate a virtual environment?"
        ) from exc
    execute_from_command_line(sys.argv)


if __name__ == '__main__':
    main()

####################################
g2p
####################################

add_archs.py

import numpy as np
import copy

room_label = [(0, 'LivingRoom', 1, "PublicArea",[220, 213, 205]),
              (1, 'MasterRoom', 0, "Bedroom",[138, 113, 91]),
              (2, 'Kitchen', 1, "FunctionArea",[244, 245, 247]),
              (3, 'Bathroom', 0, "FunctionArea",[224, 225, 227]),
              (4, 'DiningRoom', 1, "FunctionArea",[200, 193, 185]),
              (5, 'ChildRoom', 0, "Bedroom",[198, 173, 151]),
              (6, 'StudyRoom', 0, "Bedroom",[178, 153, 131]),
              (7, 'SecondRoom', 0, "Bedroom",[158, 133, 111]),
              (8, 'GuestRoom', 0, "Bedroom",[189, 172, 146]),
              (9, 'Balcony', 1, "PublicArea",[244, 237, 224]),
              (10, 'Entrance', 1, "PublicArea",[238, 235, 230]),
              (11, 'Storage', 0, "PublicArea",[226, 220, 206]),
              (12, 'Wall-in', 0, "PublicArea",[226, 220, 206]),
              (13, 'External', 0, "External",[255, 255, 255]),
              (14, 'ExteriorWall', 0, "ExteriorWall",[0, 0, 0]),
              (15, 'FrontDoor', 0, "FrontDoor",[255,255,0]),
              (16, 'InteriorWall', 0, "InteriorWall",[128,128,128]),
              (17, 'InteriorDoor', 0, "InteriorDoor",[255,255,255])]

class DirectedLine():
    def __init__(self,p1,p2):
        '''search direction : 0(horizontal) / 1(vertical)'''
        if np.abs(p1[0]-p2[0])<1e-6:
            self.dir = 1
            self.level = p1[0]
            self.minLevel = min(p1[1],p2[1])
            self.maxLevel = max(p1[1],p2[1])
        else:
            self.dir = 0
            self.level = p1[1]
            self.minLevel = min(p1[0],p2[0])
            self.maxLevel = max(p1[0],p2[0])
    
    def __repr__(self):
        if self.dir==0: return f'({self.level},[{self.minLevel},{self.maxLevel}])'
        else: return f'([{self.minLevel},{self.maxLevel}],{self.level})'
    
    @property
    def length(self):return self.maxLevel-self.minLevel
    
    def is_contact(self,line): 
        minl = min(self.minLevel,line.minLevel)
        maxl = max(self.maxLevel,line.maxLevel)
        length = maxl-minl
        return (
            self.dir==line.dir and 
            #self.level!=line.level and 
            abs(self.level-line.level)<6 and
            length < self.length+line.length
        )
    
    @staticmethod
    def lines_from_boundary(boundary):
        if len(boundary)==0:return []
        pts = boundary.tolist()+[boundary[0].tolist()]
        lines = [ DirectedLine(pts[i],pts[i+1]) for i in range(len(pts)-1)]
        return lines

class DirectedWall():
    def __init__(self):
        '''orientation : 0(right) / 1(down) / 2(left) / 3(up)'''
        self.dir = 0
        self.rect = np.array([0,0,0,0])
    
    @property
    def width(self):return self.rect[2]
    
    @property
    def height(self):return self.rect[3]
    
    @property
    def center(self):return self.rect[:2]+self.rect[2:]/2
    
    def setX(self,x):self.rect[0]=x
    def setY(self,y):self.rect[1]=y
    def setWidth(self,w):self.rect[2]=w
    def setHeight(self,h):self.rect[2]=h
    def setLeft(self,x):
        self.rect[2]=(self.rect[0]-x)+self.rect[2]
        self.rect[0]=x
    def setTop(self,y):
        self.rect[3]=(self.rect[1]-y)+self.rect[3]
        self.rect[1]=y
    
    def to_line(self):
        if self.dir in [0,2]:
            return DirectedLine([self.rect[0],self.rect[1]],[self.rect[0],self.rect[1]+self.rect[3]])
        else:
            return DirectedLine([self.rect[0],self.rect[1]],[self.rect[0]+self.rect[2],self.rect[1]])
    
    def __repr__(self):
        pos = ['right','down','left','up','None'][self.dir]
        return f'({pos},{self.rect})'

class Entry():
    def __init__(self):
        '''door type : 0(door) / 1(open wall)'''
        self.type = -1
        self.entry = None
        
    def __repr__(self):
        if self.type==0: return f'(door,{self.entry})'
        else: return f'(open wall,{self.entry})'   
        
class Room():
    def __init__(self):
        self.box = None
        self.category = None
        self.boundary = None
                
        self.map = None
        self.entry = None
        self.windows = []
    
    @property
    def label(self):return room_label[self.category][1]
    
    @property
    def type(self): return room_label[self.category][3]
    
    @property
    def center(self): return self.box.reshape(-1,2).mean(0)

    @staticmethod
    def rooms_from_data(data):
        rooms = []
        for i in range(len(data.rType)):
            room = Room()
            room.box = data.newBox[i]
            room.category = data.rType[i]
            room.boundary = data.rBoundary[i]
            room.lines = DirectedLine.lines_from_boundary(room.boundary)
            rooms.append(room)
        return rooms

    @staticmethod
    def from_node_box(node,box):
        x0,y0,x1,y1 = box
        room = Room()
        room.box = box
        room.category = node[-1]
        room.boundary = np.array([
                [x0,y0],
                [x0,y1],
                [x1,y1],
                [x1,y0]
            ])
        room.lines = DirectedLine.lines_from_boundary(room.boundary)
        # room.boundary = [
        #     DirectedLine((x0,y0),(x1,y0)), # top
        #     DirectedLine((x1,y0),(x1,y1)), # right
        #     DirectedLine((x0,y1),(x1,y1)), # bottom
        #     DirectedLine((x0,y0),(x0,y1)), # left
        #     ]
        return room
        
    @staticmethod
    def from_boundary(boundary):
        # pts = boundary[:,:2].tolist()
        # pts = pts+[pts[0]]
        room = Room()
        
        room.category = 0
        room.box = np.array([np.min(boundary[:,0]),np.min(boundary[:,1]),np.max(boundary[:,0]),np.max(boundary[:,1])])
        room.boundary = boundary[:,:2]
        room.lines = DirectedLine.lines_from_boundary(room.boundary)
        # room.boundary = [
        #     DirectedLine(pts[i],pts[i+1])
        #     for i in range(len(pts)-1)
        #     ]
        return room
        
    def __repr__(self):
        return f'({self.label},{self.type},{self.box},{self.entry},{self.windows})'
        
def find_contact_walls(room1,room2,reverse=False):
    contactWalls = []
    lines1 = copy.deepcopy(room1.lines) #DirectedLine.from_boundary(room1.boundary)#room1.lines
    center1 = room1.center
    lines2 = copy.deepcopy(room2.lines) #DirectedLine.from_boundary(room2.boundary)# room2.lines
    center2 = room2.center
    temp = []
    
    for i in range(len(lines1)):
        line1 = lines1[i]
        
        for j in range(len(lines2)):
            line2 = lines2[j]
            
            if line1.is_contact(line2):
                contactWall = DirectedWall()
                if line1.dir==0:
                    minh = line1.level if not reverse else line2.level #min(line1.level,line2.level)
                    maxh = line1.level if not reverse else line2.level #max(line1.level,line2.level)
                    minw = max(line1.minLevel,line2.minLevel)
                    maxw = min(line1.maxLevel,line2.maxLevel)
                    # @todo:boudanry not work!
                    if center1[1] > line1.level: contactWall.dir=1
                    else: contactWall.dir=3
                    contactWall.rect = np.array([minw,minh,maxw-minw,maxh-minh])
                else:
                    minw = line1.level if not reverse else line2.level#min(line1.level,line2.level)
                    maxw = line1.level if not reverse else line2.level#max(line1.level,line2.level)
                    minh = max(line1.minLevel,line2.minLevel)
                    maxh = min(line1.maxLevel,line2.maxLevel)
                    if center1[0] > line1.level: contactWall.dir=0
                    else: contactWall.dir=2
                    contactWall.rect = np.array([minw,minh,maxw-minw,maxh-minh])
                contactWalls.append(contactWall)
    return contactWalls

def find_longest_wall(contactWalls,dtype=1):
    contactLength = 0
    openWall = None
    for i in range(len(contactWalls)):
        maxLength = max(contactWalls[i].width,contactWalls[i].height)
        if maxLength>contactLength:
            contactLength = maxLength
            openWall = contactWalls[i]
    if contactLength!=0:
        # @todo: adjust door
        openWall = adjust_door(openWall,dtype)
        entry = Entry()
        entry.type = dtype
        entry.entry = openWall
        assert entry.entry.dir!=-1, "find longest wall with dir -1!"
        return entry
    return None

def find_closest_wall(candidateDoors,frontDoorCenter,dtype=1,boundary_lines=[]):
    dis = 1e8
    door = None
    for i in range(len(candidateDoors)):
        maxLength = max(candidateDoors[i].width,candidateDoors[i].height)
        if maxLength<12:continue

        valid = True
        line = candidateDoors[i].to_line()
        for b_line in boundary_lines:
            if line.is_contact(b_line):
                valid = False
                break
        if not valid: continue

        center = candidateDoors[i].center
        candidateDis = np.sum(np.power((center-frontDoorCenter),2))
        if dis>candidateDis:
            dis = candidateDis
            door = candidateDoors[i]
    if door is not None:
        door = adjust_door(door,dtype)
        entry = Entry()
        entry.type = dtype
        entry.entry = door
        assert entry.entry.dir!=-1, "find closest wall with dir -1!"
        return entry
    return None

def adjust_door(door,dtype=1):
    if door.dir in [1,3]:
        if dtype==1: 
            door.rect[0] = door.rect[0]+door.rect[2]/8
            door.rect[2] = door.rect[2]*3/4
        else:
            # door.rect[0] = door.center[0]-6
            door.rect[2] = min(2*6,door.rect[2])
    else:
        if dtype==1:
            door.rect[1] = door.rect[1]+door.rect[3]/8
            door.rect[3] = door.rect[3]*3/4
        else:
            # door.rect[1] = door.center[1]-6
            door.rect[3] = min(2*6,door.rect[3])
    return door

def add_interior_door(rooms,living_idx,house):
    frontDoorCenter = house.boundary[:2].mean(0)
    for i in range(len(rooms)):
        if i==living_idx:continue
        # 1. Balcony: find the longest door
        # 2. Public Area: find the longest door
        # 3. Others:
        #    3.1 Contact with living room: find the cloest door with the front door
        #    3.2 Others: find the longest wall
        if rooms[i].label == 'Balcony':
            contactWalls = []
            for j in range(len(rooms)):
                if i!=j:
                    contactWalls.extend(find_contact_walls(rooms[i],rooms[j]))
            
            rooms[i].entry = find_longest_wall(contactWalls,dtype=1)
        else:
            contactWalls = find_contact_walls(rooms[i],rooms[living_idx])
            if len(contactWalls)>0:
                if rooms[i].type == 'PublicArea':
                    rooms[i].entry = find_longest_wall(contactWalls,dtype=1)
                else:
                    candidateDoors = [ 
                        wall for wall in contactWalls 
                        if (wall.width>wall.height and wall.width>2*6) or 
                        (wall.height>wall.width and wall.height>2*6)
                    ]
                    if len(candidateDoors)==0:
                        rooms[i].entry = find_longest_wall(contactWalls,dtype=0)
                    else:
                        rooms[i].entry = find_closest_wall(contactWalls,frontDoorCenter,dtype=0,boundary_lines=house.lines)
            else:
                contactWalls = []
                for j in range(len(rooms)):
                    if i!=j:
                        contactWalls.extend(find_contact_walls(rooms[i],rooms[j]))
                if len(contactWalls)>0:
                    rooms[i].entry = find_closest_wall(contactWalls,frontDoorCenter,dtype=1,boundary_lines=house.lines)
            
    return rooms

def find_windows(contactWalls,wtypes=['mid'],keep_longest=False):
    windows = []
    contactLength = 1e8
    for i in range(len(contactWalls)):
        contactWall = contactWalls[i]
        maxLength = max(contactWall.width,contactWall.height)
        if ('large' in wtypes and maxLength>3*12):
            contactWalls[i] = adjust_window(contactWalls[i],'large')
            windows.append(contactWall)
        elif 'mid' in wtypes and maxLength>3*9:
            contactWalls[i] = adjust_window(contactWalls[i],'mid')
            windows.append(contactWall)
        elif 'small' in wtypes and maxLength>2*5:
            contactWalls[i] = adjust_window(contactWalls[i],'small')
            windows.append(contactWall)
        elif 'balcony' in wtypes and maxLength>2*5:
            contactWalls[i] = adjust_window(contactWalls[i],'balcony')
            windows.append(contactWall)
    return windows

def find_window_by_length(contactWalls,wtypes=['mid'],ltype='max'):
    window = None
    contactLength = 0 if ltype=='max' else 1e8
    ufunc = np.greater if ltype=='max' else np.less
    for i in range(len(contactWalls)):
        contactWall = contactWalls[i]
        maxLength = max(contactWall.width,contactWall.height)
        if ufunc(maxLength,contactLength):
            if 'large' in wtypes and maxLength>3*12:
                contactWalls[i] = adjust_window(contactWalls[i],'large')
                window = contactWalls[i]
                contactLength = maxLength
            elif 'mid' in wtypes and maxLength>3*9:
                contactWalls[i] = adjust_window(contactWalls[i],'mid')
                window = contactWalls[i]
                contactLength = maxLength
            elif 'small' in wtypes and maxLength>2*5:
                contactWalls[i] = adjust_window(contactWalls[i],'small')
                window = contactWalls[i]
                contactLength = maxLength
    return [window] if window is not None else []

def adjust_window(window,wtype='mid'):
    hl = {'small':5,'mid':9,'large':12}
    if window.dir in [1,3]:
        if wtype=='balcony':
            window.rect[0] = window.rect[0]+window.rect[2]/10
            window.rect[2] = window.rect[2]*4/5
        else:
            length = hl[wtype]
            window.rect[0] = window.center[0]-length
            window.rect[2] = 2*length
    else:
        if wtype=='balcony':
            window.rect[1] = window.rect[1]+window.rect[3]/10
            window.rect[3] = window.rect[3]*4/5
        else:
            length = hl[wtype]
            window.rect[1] = window.center[1]-length
            window.rect[3] = 2*length
    return window

def add_window(rooms,house):
    for i in range(len(rooms)):
        # 1. Balcony: small(half=5)
        # 2. Living Room: mid(half=9),large(half=12)
        # 3. Bathroom: shortest wall, small
        # 4. Others: longest wall, mid
        contactWalls = find_contact_walls(rooms[i],house,reverse=True)
        if rooms[i].label == 'Balcony':
            rooms[i].windows.extend(find_windows(contactWalls,['balcony']))
        elif rooms[i].label == 'LivingRoom':
            rooms[i].windows.extend(find_windows(contactWalls,['mid','large']))
        elif rooms[i].label == 'Bathroom':
            rooms[i].windows.extend(find_window_by_length(contactWalls,['small'],'min'))
        else:
            rooms[i].windows.extend(find_window_by_length(contactWalls,['mid'],'max'))
    return rooms

def rooms_to_numpy(rooms):
    doors = []
    windows = []
    for i in range(len(rooms)):
        if rooms[i].entry is not None:
            door = rooms[i].entry.entry
            doors.append([i,door.rect[0],door.rect[1],door.rect[2],door.rect[3],door.dir])
        if len(rooms[i].windows) > 0:
            ws = [[i,w.rect[0],w.rect[1],w.rect[2],w.rect[3],w.dir] for w in rooms[i].windows]
            windows.extend(ws)
    return np.array(doors),np.array(windows)

def add_door_window(data):
    boundary = data.boundary
    living_idx = np.where(data.rType==0)[0][0]
    rooms = Room.rooms_from_data(data)
    house = Room.from_boundary(boundary[:,:2])
    house.lines = house.lines[1:]    

    rooms = add_interior_door(rooms,living_idx,house)
    rooms = add_window(rooms,house)
    
    return rooms_to_numpy(rooms)

def add_dw_fp(data):
    doors,windows = add_door_window(data)
    data.doors = doors
    data.windows = windows
    return data


align.py

import numpy as np
import matlab
import matlab.engine as engine
import os
eng = engine.start_matlab()
eng.addpath(os.path.join(os.path.dirname(__file__),'matlab'),nargout=0)

GT_ThRESHOLD = 6
PRED_ThRESHOLD = 12
REFINE_ThRESHOLD = 18

def align_fp(boundary, boxes, types, edges, image, threshold, dtype=int):
    boundary = np.array(boundary,dtype=int).tolist()
    boxes    = np.array(boxes,dtype=int).tolist()
    types    = np.array(types,dtype=int).tolist()
    edges    = np.array(edges,dtype=int).tolist()
    image    = np.array(image,dtype=int).tolist()

    boxes_aligned, order, room_boundaries = eng.align_fp(
        matlab.double(boundary),
        matlab.double(boxes),
        matlab.double(types),
        matlab.double(edges),
        matlab.double(image),
        threshold,False,nargout=3
    )

    boxes_aligned   = np.array(boxes_aligned,dtype=dtype)
    order           = np.array(order,dtype=dtype).reshape(-1)-1
    room_boundaries = np.array([np.array(rb,dtype=float) for rb in room_boundaries],dtype=object) # poly with hole has value 'nan'

    return boxes_aligned, order, room_boundaries

def align_fp_gt(boundary, boxes, types, edges, dtype=int):
    return align_fp(boundary, boxes, types, edges, [], GT_ThRESHOLD, dtype)

def align_fp_pred(boundary, boxes, types, edges, dtype=int):
    return align_fp(boundary, boxes, types, edges, [], PRED_ThRESHOLD, dtype)

def align_fp_refine(boundary, boxes, types, edges, image, dtype=int):
    return align_fp(boundary, boxes, types, edges, image, REFINE_ThRESHOLD, dtype)


box_utils.py

#!/usr/bin/python
#
# Copyright 2018 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import torch

"""
Utilities for dealing with bounding boxes
"""


def box_abs2rel(boxes, inside_boxes, obj_to_img):
  inside_boxes = inside_boxes[obj_to_img]
  ix0, iy0, ix1, iy1 = inside_boxes[:, 0], inside_boxes[:, 1], inside_boxes[:, 2], inside_boxes[:, 3]
  xc = (boxes[:, 0] - ix0) / (ix1 - ix0)
  yc = (boxes[:, 1] - iy0) / (iy1 - iy0)
  w = boxes[:, 2] / (ix1 - ix0)
  h = boxes[:, 3] / (iy1 - iy0)
  return torch.stack([xc, yc, w, h], dim=1)


def box_rel2abs(boxes, inside_boxes, obj_to_img):
  inside_boxes = inside_boxes[obj_to_img]
  ix0, iy0, ix1, iy1 = inside_boxes[:, 0], inside_boxes[:, 1], inside_boxes[:, 2], inside_boxes[:, 3]
  xc = boxes[:, 0] * (ix1 - ix0) + ix0
  yc = boxes[:, 1] * (iy1 - iy0) + iy0
  w = boxes[:, 2] * (ix1 - ix0)
  h = boxes[:, 3] * (iy1 - iy0)
  return torch.stack([xc, yc, w, h], dim=1)

def norms_to_indices(boxes,H,W=None):
    if W is None:
        W=H
    x0,x1 = boxes[:,0]*(W-1),boxes[:,2]*(W-1)+1
    y0,y1 = boxes[:,1]*(H-1),boxes[:,3]*(H-1)+1
    return torch.stack([x0, y0, x1, y1], dim=1).round().long()

def apply_box_transform(anchors, transforms):
  """
  Apply box transforms to a set of anchor boxes.

  Inputs:
  - anchors: Anchor boxes of shape (N, 4), where each anchor is specified
    in the form [xc, yc, w, h]
  - transforms: Box transforms of shape (N, 4) where each transform is
    specified as [tx, ty, tw, th]

  Returns:
  - boxes: Transformed boxes of shape (N, 4) where each box is in the
    format [xc, yc, w, h]
  """
  # Unpack anchors
  xa, ya = anchors[:, 0], anchors[:, 1]
  wa, ha = anchors[:, 2], anchors[:, 3]

  # Unpack transforms
  tx, ty = transforms[:, 0], transforms[:, 1]
  tw, th = transforms[:, 2], transforms[:, 3]

  x = xa + tx * wa
  y = ya + ty * ha
  w = wa * tw.exp()
  h = ha * th.exp()

  boxes = torch.stack([x, y, w, h], dim=1)
  return boxes


def invert_box_transform(anchors, boxes):
  """
  Compute the box transform that, when applied to anchors, would give boxes.

  Inputs:
  - anchors: Box anchors of shape (N, 4) in the format [xc, yc, w, h]
  - boxes: Target boxes of shape (N, 4) in the format [xc, yc, w, h]

  Returns:
  - transforms: Box transforms of shape (N, 4) in the format [tx, ty, tw, th]
  """
  # Unpack anchors
  xa, ya = anchors[:, 0], anchors[:, 1]
  wa, ha = anchors[:, 2], anchors[:, 3]
  
  # Unpack boxes
  x, y = boxes[:, 0], boxes[:, 1]
  w, h = boxes[:, 2], boxes[:, 3]

  tx = (x - xa) / wa
  ty = (y - ya) / ha
  tw = w.log() - wa.log()
  th = h.log() - ha.log()

  transforms = torch.stack([tx, ty, tw, th], dim=1)
  return transforms


def centers_to_extents(boxes):
  """
  Convert boxes from [xc, yc, w, h] format to [x0, y0, x1, y1] format

  Input:
  - boxes: Input boxes of shape (N, 4) in [xc, yc, w, h] format

  Returns:
  - boxes: Output boxes of shape (N, 4) in [x0, y0, x1, y1] format
  """
  xc, yc = boxes[:, 0], boxes[:, 1]
  w, h = boxes[:, 2], boxes[:, 3]

  x0 = xc - w / 2
  x1 = x0 + w
  y0 = yc - h / 2
  y1 = y0 + h

  boxes_out = torch.stack([x0, y0, x1, y1], dim=1)
  return boxes_out


def extents_to_centers(boxes):
  """
  Convert boxes from [x0, y0, x1, y1] format to [xc, yc, w, h] format

  Input:
  - boxes: Input boxes of shape (N, 4) in [x0, y0, x1, y1] format

  Returns:
  - boxes: Output boxes of shape (N, 4) in [xc, yc, w, h] format
  """
  x0, y0 = boxes[:, 0], boxes[:, 1]
  x1, y1 = boxes[:, 2], boxes[:, 3]

  xc = 0.5 * (x0 + x1)
  yc = 0.5 * (y0 + y1)
  w = x1 - x0
  h = y1 - y0

  boxes_out = torch.stack([xc, yc, w, h], dim=1)
  return boxes_out


decorate.py

import numpy as np
import copy

room_label = [(0, 'LivingRoom', 1, "PublicArea",[220, 213, 205]),
              (1, 'MasterRoom', 0, "Bedroom",[138, 113, 91]),
              (2, 'Kitchen', 1, "FunctionArea",[244, 245, 247]),
              (3, 'Bathroom', 0, "FunctionArea",[224, 225, 227]),
              (4, 'DiningRoom', 1, "FunctionArea",[200, 193, 185]),
              (5, 'ChildRoom', 0, "Bedroom",[198, 173, 151]),
              (6, 'StudyRoom', 0, "Bedroom",[178, 153, 131]),
              (7, 'SecondRoom', 0, "Bedroom",[158, 133, 111]),
              (8, 'GuestRoom', 0, "Bedroom",[189, 172, 146]),
              (9, 'Balcony', 1, "PublicArea",[244, 237, 224]),
              (10, 'Entrance', 1, "PublicArea",[238, 235, 230]),
              (11, 'Storage', 0, "PublicArea",[226, 220, 206]),
              (12, 'Wall-in', 0, "PublicArea",[226, 220, 206]),
              (13, 'External', 0, "External",[255, 255, 255]),
              (14, 'ExteriorWall', 0, "ExteriorWall",[0, 0, 0]),
              (15, 'FrontDoor', 0, "FrontDoor",[255,255,0]),
              (16, 'InteriorWall', 0, "InteriorWall",[128,128,128]),
              (17, 'InteriorDoor', 0, "InteriorDoor",[255,255,255])]

class DirectedLine():
    def __init__(self,p1,p2):
        '''search direction : 0(horizontal) / 1(vertical)'''
        if np.abs(p1[0]-p2[0])<1e-6:
            self.dir = 1
            self.level = p1[0]
            self.minLevel = min(p1[1],p2[1])
            self.maxLevel = max(p1[1],p2[1])
        else:
            self.dir = 0
            self.level = p1[1]
            self.minLevel = min(p1[0],p2[0])
            self.maxLevel = max(p1[0],p2[0])
    
    def __repr__(self):
        if self.dir==0: return f'({self.level},[{self.minLevel},{self.maxLevel}])'
        else: return f'([{self.minLevel},{self.maxLevel}],{self.level})'
    
    @property
    def length(self):return self.maxLevel-self.minLevel
    
    def is_contact(self,line): 
        minl = min(self.minLevel,line.minLevel)
        maxl = max(self.maxLevel,line.maxLevel)
        length = maxl-minl
        return (
            self.dir==line.dir and 
            #self.level!=line.level and 
            abs(self.level-line.level)<6 and
            length < self.length+line.length
        )
    
    @staticmethod
    def lines_from_boundary(boundary):
        if len(boundary)==0:return []
        pts = boundary.tolist()+[boundary[0].tolist()]
        lines = [ DirectedLine(pts[i],pts[i+1]) for i in range(len(pts)-1)]
        return lines

class DirectedWall():
    def __init__(self):
        '''orientation : 0(right) / 1(down) / 2(left) / 3(up)'''
        self.dir = 0
        self.rect = np.array([0,0,0,0])
    
    @property
    def width(self):return self.rect[2]
    
    @property
    def height(self):return self.rect[3]
    
    @property
    def center(self):return self.rect[:2]+self.rect[2:]/2
    
    def setX(self,x):self.rect[0]=x
    def setY(self,y):self.rect[1]=y
    def setWidth(self,w):self.rect[2]=w
    def setHeight(self,h):self.rect[2]=h
    def setLeft(self,x):
        self.rect[2]=(self.rect[0]-x)+self.rect[2]
        self.rect[0]=x
    def setTop(self,y):
        self.rect[3]=(self.rect[1]-y)+self.rect[3]
        self.rect[1]=y
    
    def to_line(self):
        if self.dir in [0,2]:
            return DirectedLine([self.rect[0],self.rect[1]],[self.rect[0],self.rect[1]+self.rect[3]])
        else:
            return DirectedLine([self.rect[0],self.rect[1]],[self.rect[0]+self.rect[2],self.rect[1]])
    
    def __repr__(self):
        pos = ['right','down','left','up','None'][self.dir]
        return f'({pos},{self.rect})'

class Entry():
    def __init__(self):
        '''door type : 0(door) / 1(open wall)'''
        self.type = -1
        self.entry = None
        
    def __repr__(self):
        if self.type==0: return f'(door,{self.entry})'
        else: return f'(open wall,{self.entry})'   
        
class Room():
    def __init__(self):
        self.box = None
        self.category = None
        self.boundary = None
        
        self.map = None
        self.entry = None
        self.windows = []
    
    @property
    def label(self):return room_label[self.category][1]
    
    @property
    def type(self): return room_label[self.category][3]
    
    @property
    def center(self): return self.box.reshape(-1,2).mean(0)

    @staticmethod
    def rooms_from_data(data):
        rooms = []
        for i in range(len(data.rType)):
            room = Room()
            room.box = data.newBox[i]
            room.category = data.rType[i]
            room.boundary = data.rBoundary[i]
            room.lines = DirectedLine.lines_from_boundary(room.boundary)
            rooms.append(room)
        return rooms

    @staticmethod
    def from_node_box(node,box):
        x0,y0,x1,y1 = box
        room = Room()
        room.box = box
        room.category = node[-1]
        room.boundary = np.array([
                [x0,y0],
                [x0,y1],
                [x1,y1],
                [x1,y0]
            ])
        room.lines = DirectedLine.lines_from_boundary(room.boundary)
        # room.boundary = [
        #     DirectedLine((x0,y0),(x1,y0)), # top
        #     DirectedLine((x1,y0),(x1,y1)), # right
        #     DirectedLine((x0,y1),(x1,y1)), # bottom
        #     DirectedLine((x0,y0),(x0,y1)), # left
        #     ]
        return room
        
    @staticmethod
    def from_boundary(boundary):
        # pts = boundary[:,:2].tolist()
        # pts = pts+[pts[0]]
        room = Room()
        
        room.category = 0
        room.box = np.array([np.min(boundary[:,0]),np.min(boundary[:,1]),np.max(boundary[:,0]),np.max(boundary[:,1])])
        room.boundary = boundary[:,:2]
        room.lines = DirectedLine.lines_from_boundary(room.boundary)
        # room.boundary = [
        #     DirectedLine(pts[i],pts[i+1])
        #     for i in range(len(pts)-1)
        #     ]
        return room
        
    def __repr__(self):
        return f'({self.label},{self.type},{self.box},{self.entry},{self.windows})'
        
def find_contact_walls(room1,room2,reverse=False):
    contactWalls = []
    lines1 = copy.deepcopy(room1.lines) #DirectedLine.from_boundary(room1.boundary)#room1.lines
    center1 = room1.center
    lines2 = copy.deepcopy(room2.lines) #DirectedLine.from_boundary(room2.boundary)# room2.lines
    center2 = room2.center
    temp = []
    
    for i in range(len(lines1)):
        line1 = lines1[i]
        
        for j in range(len(lines2)):
            line2 = lines2[j]
            
            if line1.is_contact(line2):
                contactWall = DirectedWall()
                if line1.dir==0:
                    minh = line1.level if not reverse else line2.level #min(line1.level,line2.level)
                    maxh = line1.level if not reverse else line2.level #max(line1.level,line2.level)
                    minw = max(line1.minLevel,line2.minLevel)
                    maxw = min(line1.maxLevel,line2.maxLevel)
                    # @todo:boudanry not work!
                    if center1[1] > line1.level: contactWall.dir=1
                    else: contactWall.dir=3
                    contactWall.rect = np.array([minw,minh,maxw-minw,maxh-minh])
                else:
                    minw = line1.level if not reverse else line2.level#min(line1.level,line2.level)
                    maxw = line1.level if not reverse else line2.level#max(line1.level,line2.level)
                    minh = max(line1.minLevel,line2.minLevel)
                    maxh = min(line1.maxLevel,line2.maxLevel)
                    if center1[0] > line1.level: contactWall.dir=0
                    else: contactWall.dir=2
                    contactWall.rect = np.array([minw,minh,maxw-minw,maxh-minh])
                contactWalls.append(contactWall)
    return contactWalls

def find_longest_wall(contactWalls,dtype=1):
    contactLength = 0
    openWall = None
    for i in range(len(contactWalls)):
        maxLength = max(contactWalls[i].width,contactWalls[i].height)
        if maxLength>contactLength:
            contactLength = maxLength
            openWall = contactWalls[i]
    if contactLength!=0:
        # @todo: adjust door
        openWall = adjust_door(openWall,dtype)
        entry = Entry()
        entry.type = dtype
        entry.entry = openWall
        assert entry.entry.dir!=-1, "find longest wall with dir -1!"
        return entry
    return None

def find_closest_wall(candidateDoors,frontDoorCenter,dtype=1,boundary_lines=[]):
    dis = 1e8
    door = None
    for i in range(len(candidateDoors)):
        maxLength = max(candidateDoors[i].width,candidateDoors[i].height)
        if maxLength<12:continue

        valid = True
        line = candidateDoors[i].to_line()
        for b_line in boundary_lines:
            if line.is_contact(b_line):
                valid = False
                break
        if not valid: continue

        center = candidateDoors[i].center
        candidateDis = np.sum(np.power((center-frontDoorCenter),2))
        if dis>candidateDis:
            dis = candidateDis
            door = candidateDoors[i]
    if door is not None:
        door = adjust_door(door,dtype)
        entry = Entry()
        entry.type = dtype
        entry.entry = door
        assert entry.entry.dir!=-1, "find closest wall with dir -1!"
        return entry
    return None

def adjust_door(door,dtype=1):
    if door.dir in [1,3]:
        if dtype==1: 
            door.rect[0] = door.rect[0]+door.rect[2]/8
            door.rect[2] = door.rect[2]*3/4
        else:
            # door.rect[0] = door.center[0]-6
            door.rect[2] = min(2*6,door.rect[2])
    else:
        if dtype==1:
            door.rect[1] = door.rect[1]+door.rect[3]/8
            door.rect[3] = door.rect[3]*3/4
        else:
            # door.rect[1] = door.center[1]-6
            door.rect[3] = min(2*6,door.rect[3])
    return door

def add_interior_door(rooms,living_idx,house):
    frontDoorCenter = house.boundary[:2].mean(0)
    for i in range(len(rooms)):
        if i==living_idx:continue
        # 1. Balcony: find the longest door
        # 2. Public Area: find the longest door
        # 3. Others:
        #    3.1 Contact with living room: find the cloest door with the front door
        #    3.2 Others: find the longest wall
        if rooms[i].label == 'Balcony':
            contactWalls = []
            for j in range(len(rooms)):
                if i!=j:
                    contactWalls.extend(find_contact_walls(rooms[i],rooms[j]))
            
            rooms[i].entry = find_longest_wall(contactWalls,dtype=1)
        else:
            contactWalls = find_contact_walls(rooms[i],rooms[living_idx])
            if len(contactWalls)>0:
                if rooms[i].type == 'PublicArea':
                    rooms[i].entry = find_longest_wall(contactWalls,dtype=1)
                else:
                    candidateDoors = [ 
                        wall for wall in contactWalls 
                        if (wall.width>wall.height and wall.width>2*6) or 
                        (wall.height>wall.width and wall.height>2*6)
                    ]
                    if len(candidateDoors)==0:
                        rooms[i].entry = find_longest_wall(contactWalls,dtype=0)
                    else:
                        rooms[i].entry = find_closest_wall(contactWalls,frontDoorCenter,dtype=0,boundary_lines=house.lines)
            else:
                contactWalls = []
                for j in range(len(rooms)):
                    if i!=j:
                        contactWalls.extend(find_contact_walls(rooms[i],rooms[j]))
                if len(contactWalls)>0:
                    rooms[i].entry = find_closest_wall(contactWalls,frontDoorCenter,dtype=1,boundary_lines=house.lines)
            
    return rooms

def find_windows(contactWalls,wtypes=['mid'],keep_longest=False):
    windows = []
    contactLength = 1e8
    for i in range(len(contactWalls)):
        contactWall = contactWalls[i]
        maxLength = max(contactWall.width,contactWall.height)
        if ('large' in wtypes and maxLength>3*12):
            contactWalls[i] = adjust_window(contactWalls[i],'large')
            windows.append(contactWall)
        elif 'mid' in wtypes and maxLength>3*9:
            contactWalls[i] = adjust_window(contactWalls[i],'mid')
            windows.append(contactWall)
        elif 'small' in wtypes and maxLength>2*5:
            contactWalls[i] = adjust_window(contactWalls[i],'small')
            windows.append(contactWall)
        elif 'balcony' in wtypes and maxLength>2*5:
            contactWalls[i] = adjust_window(contactWalls[i],'balcony')
            windows.append(contactWall)
    return windows

def find_window_by_length(contactWalls,wtypes=['mid'],ltype='max'):
    window = None
    contactLength = 0 if ltype=='max' else 1e8
    ufunc = np.greater if ltype=='max' else np.less
    for i in range(len(contactWalls)):
        contactWall = contactWalls[i]
        maxLength = max(contactWall.width,contactWall.height)
        if ufunc(maxLength,contactLength):
            if 'large' in wtypes and maxLength>3*12:
                contactWalls[i] = adjust_window(contactWalls[i],'large')
                window = contactWalls[i]
                contactLength = maxLength
            elif 'mid' in wtypes and maxLength>3*9:
                contactWalls[i] = adjust_window(contactWalls[i],'mid')
                window = contactWalls[i]
                contactLength = maxLength
            elif 'small' in wtypes and maxLength>2*5:
                contactWalls[i] = adjust_window(contactWalls[i],'small')
                window = contactWalls[i]
                contactLength = maxLength
    return [window] if window is not None else []

def adjust_window(window,wtype='mid'):
    hl = {'small':5,'mid':9,'large':12}
    if window.dir in [1,3]:
        if wtype=='balcony':
            window.rect[0] = window.rect[0]+window.rect[2]/10
            window.rect[2] = window.rect[2]*4/5
        else:
            length = hl[wtype]
            window.rect[0] = window.center[0]-length
            window.rect[2] = 2*length
    else:
        if wtype=='balcony':
            window.rect[1] = window.rect[1]+window.rect[3]/10
            window.rect[3] = window.rect[3]*4/5
        else:
            length = hl[wtype]
            window.rect[1] = window.center[1]-length
            window.rect[3] = 2*length
    return window

def add_window(rooms,house):
    for i in range(len(rooms)):
        # 1. Balcony: small(half=5)
        # 2. Living Room: mid(half=9),large(half=12)
        # 3. Bathroom: shortest wall, small
        # 4. Others: longest wall, mid
        contactWalls = find_contact_walls(rooms[i],house,reverse=True)
        if rooms[i].label == 'Balcony':
            rooms[i].windows.extend(find_windows(contactWalls,['balcony']))
        elif rooms[i].label == 'LivingRoom':
            rooms[i].windows.extend(find_windows(contactWalls,['mid','large']))
        elif rooms[i].label == 'Bathroom':
            rooms[i].windows.extend(find_window_by_length(contactWalls,['small'],'min'))
        else:
            rooms[i].windows.extend(find_window_by_length(contactWalls,['mid'],'max'))
    return rooms

def rooms_to_numpy(rooms):
    doors = []
    windows = []
    for i in range(len(rooms)):
        if rooms[i].entry is not None:
            door = rooms[i].entry.entry
            doors.append([i,door.rect[0],door.rect[1],door.rect[2],door.rect[3],door.dir])
        if len(rooms[i].windows) > 0:
            ws = [[i,w.rect[0],w.rect[1],w.rect[2],w.rect[3],w.dir] for w in rooms[i].windows]
            windows.extend(ws)
    return np.array(doors),np.array(windows)

def add_door_window(data):
    boundary = data.boundary
    living_idx = np.where(data.rType==0)[0][0]
    rooms = Room.rooms_from_data(data)
    house = Room.from_boundary(boundary[:,:2])
    house.lines = house.lines[1:]    

    rooms = add_interior_door(rooms,living_idx,house)
    rooms = add_window(rooms,house)
    
    return rooms_to_numpy(rooms)

def add_dw_fp(data):
    doors,windows = add_door_window(data)
    data.doors = doors
    data.windows = windows
    return data


floorplan.py

import torch
import scipy.io as sio
import numpy as np
import cv2
import copy
from .utils import *


class FloorPlan():

    def __init__(self, data, train=False, rot=None):
        self.data = copy.deepcopy(data)
        self._get_rot()
        if rot is not None:
            if train:
                boxes = self.data.box[:, :4][:, [1, 0, 3, 2]]
                boxes = align_box(boxes, self.rot, rot)[:, [1, 0, 3, 2]]
                self.data.box[:, :4] = boxes
            points = self.data.boundary[:, :2][:, [1, 0]]
            points = align_points(points, self.rot, rot)[:, [1, 0]]
            self.data.boundary[:, :2] = points
            self._get_rot()

    def _get_rot(self):
        door_line = self.data.boundary[:2, :2]  # [:,[1,0]]
        c = door_line.mean(0) - np.array([127.5,127.5])
        theta = np.arctan2(c[1], c[0]) + np.pi  # [-pi,pi]
        self.rot = theta

    def get_input_boundary(self, tensor=True):
        external = self.data.boundary[:, :2]
        door = self.data.boundary[:2, :2]

        boundary = np.zeros((128, 128), dtype=float)
        inside = np.zeros((128, 128), dtype=float)
        front = np.zeros((128, 128), dtype=float)

        pts = np.concatenate([external, external[:1]]) // 2
        pts_door = door // 2

        cv2.fillPoly(inside, pts.reshape(1, -1, 2), 1.0)
        cv2.polylines(boundary, pts.reshape(1, -1, 2), True, 1.0, 3)
        cv2.polylines(boundary, pts_door.reshape(1, -1, 2), True, 0.5, 3)
        cv2.polylines(front, pts_door.reshape(1, -1, 2), True, 1.0, 3)

        input_image = np.stack([inside, boundary, front], -1)
        if tensor: input_image = torch.tensor(input_image).permute((2, 0, 1)).float()
        return input_image

    def get_inside_box(self, tensor=True):
        external = self.data.boundary[:, :2]

        X, Y = np.linspace(0, 1, 256), np.linspace(0, 1, 256)
        x0, x1 = np.min(external[:, 0]), np.max(external[:, 0])
        y0, y1 = np.min(external[:, 1]), np.max(external[:, 1])
        box = np.array([[X[x0], Y[y0], X[x1], Y[y1]]])
        if tensor: box = torch.tensor(box).float()
        return box

    def get_rooms(self, tensor=True):
        rooms = self.data.box[:, -1]
        if tensor: rooms = torch.tensor(rooms).long()
        return rooms

    def get_attributes(self, gsize=5, alevel=10, relative=True, tensor=True):
        boxes = self.data.box[:, :4][:, [1, 0, 3, 2]]
        external = self.data.boundary

        h, w = 256, 256
        if relative:
            external = np.asarray(external)
            x0, x1 = np.min(external[:, 0]), np.max(external[:, 0])
            y0, y1 = np.min(external[:, 1]), np.max(external[:, 1])
            h, w = y1 - y0, x1 - x0
            boxes = boxes - np.array([y0, x0, y0, x0], dtype=float)
        boxes /= np.array([h, w, h, w])
        boxes[:, 2:] -= boxes[:, :2]  # y1,x1->h,w
        boxes[:, :2] += boxes[:, 2:] / 2  # y0,x0->yc,xc
        
        l = len(boxes)
        gbins = np.linspace(0,1,gsize+1) # [1,gsize]
        gbins[0],gbins[-1]=-np.inf,np.inf
        abins = np.linspace(0,1,alevel+1) # [1,gsize]
        abins[0],abins[-1]=-np.inf,np.inf

        attributes = np.zeros((l,gsize*gsize+alevel))
        # pos: xc*gsize+yc*gsize*gsize
        attributes[range(l),(np.digitize(boxes[:,0],gbins)-1)*gsize+np.digitize(boxes[:,1],gbins)-1]=1
        # area:(w*h)
        attributes[range(l),gsize*gsize+np.digitize(boxes[:,2:].prod(1),abins)-1]=1
        if tensor: attributes = torch.tensor(attributes).float()
        return attributes

    def get_triples(self, random=False, tensor=True):
        boxes = self.data.box[:, :4][:, [1, 0, 3, 2]]

        triples = []
        # add edge relation
        for u, v, _ in self.data.edge:
            uy0, ux0, uy1, ux1 = boxes[u]
            vy0, vx0, vy1, vx1 = boxes[v]
            uc = (uy0 + uy1) / 2, (ux0 + ux1) / 2
            vc = (vy0 + vy1) / 2, (vx0 + vx1) / 2

            # surrounding/inside -> X four quadrants
            if ux0 < vx0 and ux1 > vx1 and uy0 < vy0 and uy1 > vy1:
                relation = 'surrounding'
            elif ux0 >= vx0 and ux1 <= vx1 and uy0 >= vy0 and uy1 <= vy1:
                relation = 'inside'
            else:
                relation = point_box_relation(uc, boxes[v])

            triples.append([u, vocab['pred_name_to_idx'][relation], v])

        triples = np.array(triples, dtype=int)
        if tensor: triples = torch.tensor(triples).long()
        return triples

    def vis_box(self):
        h, w = 128, 128
        image = np.full((h, w, 4), 0, dtype=np.uint8)

        boxes = self.data.box[:, :4] // 2
        objs = self.data.box[:, -1]

        for i, obj in enumerate(objs):
            if obj == 14: continue
            color = colormap_255[obj]
            box = boxes[i]
            cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (color[0], color[1], color[2], 255), 3)

        return image

    def get_test_data(self, tensor=True):
        boundary = self.get_input_boundary(tensor=tensor)
        inside_box = self.get_inside_box(tensor=tensor)
        rooms = self.get_rooms(tensor=tensor)
        attrs = self.get_attributes(tensor=tensor)
        triples = self.get_triples(random=False, tensor=tensor)
        return boundary, inside_box, rooms, attrs, triples

    def adapt_graph(self, fp_graph):
        fp = FloorPlan(fp_graph.data, train=True, rot=self.rot)
        g_external = fp.data.boundary[:, :2]
        gx0, gx1 = np.min(g_external[:, 0]), np.max(g_external[:, 0])
        gy0, gy1 = np.min(g_external[:, 1]), np.max(g_external[:, 1])
        gw, gh = gx1 - gx0, gy1 - gy0

        fp.data.boundary = self.data.boundary
        b_external = self.data.boundary[:, :2]
        bx0, bx1 = np.min(b_external[:, 0]), np.max(b_external[:, 0])
        by0, by1 = np.min(b_external[:, 1]), np.max(b_external[:, 1])
        bh, bw = by1 - by0, bx1 - bx0
        box_adapter = lambda box: (((box - np.array([gx0, gy0, gx0, gy0])) * np.array([bw, bh, bw, bh])) / np.array(
            [gw, gh, gw, gh]) + np.array([bx0, by0, bx0, by0])).astype(int)

        fp.data.box[:, :4] = np.apply_along_axis(box_adapter, 1, fp.data.box[:, :4])
        return fp

    def adjust_graph(self):
        external = self.data.boundary[:, :2]
        bx0, bx1 = np.min(external[:, 0]), np.max(external[:, 0])
        by0, by1 = np.min(external[:, 1]), np.max(external[:, 1])
        hw_b = np.array([by1 - by0, bx1 - bx0])
        step = hw_b / 10

        pts = np.concatenate([external, external[:1]])
        mask = np.zeros((256, 256), dtype=np.uint8)
        cv2.fillPoly(mask, pts.reshape(1, -1, 2), 255)
        # plt.imshow(mask)
        # plt.show()
        mask = cv2.resize(mask[by0:by1 + 1, bx0:bx1 + 1], (10, 10))
        # plt.imshow(mask)
        # plt.show()
        mask[mask > 0] = 255

        outside_rooms = []
        for i in range(len(self.data.box)):
            box = self.data.box[i][:4][[1, 0, 3, 2]]
            center = (box[:2] + box[2:]) / 2
            center55 = ((center - np.array([by0, bx0])) * 10 / hw_b).astype(int)

            if not mask[center55[0], center55[1]]:
                outside_rooms.append([i, center55])

        candicate_coords55 = {}
        for i, coords55 in outside_rooms:
            row, col = coords55
            # left/right/up/down
            candicate_coords55[i] = np.array([
                next((col-c for c in range(col,-1,-1) if mask[row,c]==255),255),
                next((c-col for c in range(col+1,5) if mask[row,c]==255),255),
                next((row-r for r in range(row,-1,-1) if mask[r,col]==255),255),
                next((r-row for r in range(row+1,5) if mask[r,col]==255),255)])

        signs = np.array([
            [0, -1, 0, -1],
            [0, 1, 0, 1],
            [-1, 0, -1, 0],
            [1, 0, 1, 0]
        ])

        for i, coords55 in outside_rooms:
            deltas = candicate_coords55[i]
            idx = np.argmin(deltas)
            self.data.box[i, :4] += (signs[idx] * deltas[idx] * np.tile(step, 2)).astype(int)[[1, 0, 3, 2]]


if __name__ == "__main__":
    pass


graph.py


#!/usr/bin/python
#
# Copyright 2018 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import torch
import torch.nn as nn

from .layers import build_mlp

"""
PyTorch modules for dealing with graphs.
"""


def _init_weights(module):
    if hasattr(module, 'weight'):
        if isinstance(module, nn.Linear):
            nn.init.kaiming_normal_(module.weight)


class GraphTripleConv(nn.Module):
    """
    A single layer of scene graph convolution.
    """

    def __init__(self, input_dim, attributes_dim=0, output_dim=None, hidden_dim=512,
                 pooling='avg', mlp_normalization='none'):
        super(GraphTripleConv, self).__init__()
        if output_dim is None:
            output_dim = input_dim
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.hidden_dim = hidden_dim

        assert pooling in ['sum', 'avg'], 'Invalid pooling "%s"' % pooling
        self.pooling = pooling
        net1_layers = [3 * input_dim + 2 * attributes_dim, hidden_dim, 2 * hidden_dim + output_dim]
        net1_layers = [l for l in net1_layers if l is not None]
        self.net1 = build_mlp(net1_layers, batch_norm=mlp_normalization)
        self.net1.apply(_init_weights)

        net2_layers = [hidden_dim, hidden_dim, output_dim]
        self.net2 = build_mlp(net2_layers, batch_norm=mlp_normalization)
        self.net2.apply(_init_weights)

    def forward(self, obj_vecs, pred_vecs, edges):
        """
        Inputs:
        - obj_vecs: FloatTensor of shape (O, D) giving vectors for all objects
        - pred_vecs: FloatTensor of shape (T, D) giving vectors for all predicates
        - edges: LongTensor of shape (T, 2) where edges[k] = [i, j] indicates the
          presence of a triple [obj_vecs[i], pred_vecs[k], obj_vecs[j]]

        Outputs:
        - new_obj_vecs: FloatTensor of shape (O, D) giving new vectors for objects
        - new_pred_vecs: FloatTensor of shape (T, D) giving new vectors for predicates
        """
        dtype, device = obj_vecs.dtype, obj_vecs.device
        O, T = obj_vecs.size(0), pred_vecs.size(0)
        Din, H, Dout = self.input_dim, self.hidden_dim, self.output_dim

        # Break apart indices for subjects and objects; these have shape (T,)
        s_idx = edges[:, 0].contiguous()
        o_idx = edges[:, 1].contiguous()

        # Get current vectors for subjects and objects; these have shape (T, Din)
        cur_s_vecs = obj_vecs[s_idx]
        cur_o_vecs = obj_vecs[o_idx]

        # Get current vectors for triples; shape is (T, 3 * Din)
        # Pass through net1 to get new triple vecs; shape is (T, 2 * H + Dout)
        cur_t_vecs = torch.cat([cur_s_vecs, pred_vecs, cur_o_vecs], dim=1)
        new_t_vecs = self.net1(cur_t_vecs)

        # Break apart into new s, p, and o vecs; s and o vecs have shape (T, H) and
        # p vecs have shape (T, Dout)
        new_s_vecs = new_t_vecs[:, :H]
        new_p_vecs = new_t_vecs[:, H:(H + Dout)]
        new_o_vecs = new_t_vecs[:, (H + Dout):(2 * H + Dout)]

        # Allocate space for pooled object vectors of shape (O, H)
        pooled_obj_vecs = torch.zeros(O, H, dtype=dtype, device=device)

        # Use scatter_add to sum vectors for objects that appear in multiple triples;
        # we first need to expand the indices to have shape (T, D)
        s_idx_exp = s_idx.view(-1, 1).expand_as(new_s_vecs)
        o_idx_exp = o_idx.view(-1, 1).expand_as(new_o_vecs)
        pooled_obj_vecs = pooled_obj_vecs.scatter_add(0, s_idx_exp, new_s_vecs)
        pooled_obj_vecs = pooled_obj_vecs.scatter_add(0, o_idx_exp, new_o_vecs)

        if self.pooling == 'avg':
            # Figure out how many times each object has appeared, again using
            # some scatter_add trickery.
            obj_counts = torch.zeros(O, dtype=dtype, device=device)
            ones = torch.ones(T, dtype=dtype, device=device)
            obj_counts = obj_counts.scatter_add(0, s_idx, ones)
            obj_counts = obj_counts.scatter_add(0, o_idx, ones)

            # Divide the new object vectors by the number of times they
            # appeared, but first clamp at 1 to avoid dividing by zero;
            # objects that appear in no triples will have output vector 0
            # so this will not affect them.
            obj_counts = obj_counts.clamp(min=1)
            pooled_obj_vecs = pooled_obj_vecs / obj_counts.view(-1, 1)

        # Send pooled object vectors through net2 to get output object vectors,
        # of shape (O, Dout)
        new_obj_vecs = self.net2(pooled_obj_vecs)

        return new_obj_vecs, new_p_vecs


class GraphTripleConvNet(nn.Module):
    """ A sequence of scene graph convolution layers  """

    def __init__(self, input_dim, num_layers=5, hidden_dim=512, pooling='avg',
                 mlp_normalization='none'):
        super(GraphTripleConvNet, self).__init__()

        self.num_layers = num_layers
        self.gconvs = nn.ModuleList()
        gconv_kwargs = {
            'input_dim': input_dim,
            'hidden_dim': hidden_dim,
            'pooling': pooling,
            'mlp_normalization': mlp_normalization,
        }
        for _ in range(self.num_layers):
            self.gconvs.append(GraphTripleConv(**gconv_kwargs))

    def forward(self, obj_vecs, pred_vecs, edges):
        for i in range(self.num_layers):
            gconv = self.gconvs[i]
            obj_vecs, pred_vecs = gconv(obj_vecs, pred_vecs, edges)
        return obj_vecs, pred_vecs


layers.py

#!/usr/bin/python
#
# Copyright 2018 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import functools

import torch
import torch.nn as nn
from torch.nn.functional import interpolate

class PPM(nn.Module):
    def __init__(self, in_dim, reduction_dim, bins, BatchNorm):
        super(PPM, self).__init__()
        self.features = []
        for bin in bins:
            self.features.append(nn.Sequential(
                nn.AdaptiveAvgPool2d(bin),
                nn.Conv2d(in_dim, reduction_dim, kernel_size=1, bias=False),
                BatchNorm(reduction_dim),
                #nn.ReLU(inplace=True)
                nn.LeakyReLU(inplace=True)
            ))
        self.features = nn.ModuleList(self.features)

    def forward(self, x):
        x_size = x.size()
        out = [x]
        for f in self.features:
            out.append(interpolate(f(x), x_size[2:], mode='bilinear', align_corners=True))
        return torch.cat(out, 1)

def get_normalization_2d(channels, normalization):
    if normalization == 'instance':
        return nn.InstanceNorm2d(channels)
    elif normalization == 'batch':
        return nn.BatchNorm2d(channels)
    elif normalization == 'none':
        return None
    else:
        raise ValueError('Unrecognized normalization type "%s"' % normalization)


def get_activation(name):
    kwargs = {}
    if name.lower().startswith('leakyrelu'):
        if '-' in name:
            slope = float(name.split('-')[1])
            kwargs = {'negative_slope': slope}
    name = 'leakyrelu'
    activations = {
        'relu': nn.ReLU,
        'leakyrelu': nn.LeakyReLU,
    }
    if name.lower() not in activations:
        raise ValueError('Invalid activation "%s"' % name)
    return activations[name.lower()](**kwargs)


def _init_conv(layer, method):
    if not isinstance(layer, nn.Conv2d):
        return
    if method == 'default':
        return
    elif method == 'kaiming-normal':
        nn.init.kaiming_normal(layer.weight)
    elif method == 'kaiming-uniform':
        nn.init.kaiming_uniform(layer.weight)


class Flatten(nn.Module):
    def forward(self, x):
        return x.view(x.size(0), -1)

    def __repr__(self):
        return 'Flatten()'


class Unflatten(nn.Module):
    def __init__(self, size):
        super(Unflatten, self).__init__()
        self.size = size

    def forward(self, x):
        return x.view(*self.size)

    def __repr__(self):
        size_str = ', '.join('%d' % d for d in self.size)
        return 'Unflatten(%s)' % size_str


class GlobalAvgPool(nn.Module):
    def forward(self, x):
        N, C = x.size(0), x.size(1)
        return x.view(N, C, -1).mean(dim=2)


class ResidualBlock(nn.Module):
    def __init__(self, channels, normalization='batch', activation='relu',
                 padding='same', kernel_size=3, init='default'):
        super(ResidualBlock, self).__init__()

        K = kernel_size
        P = _get_padding(K, padding)
        C = channels
        self.padding = P
        layers = [
            get_normalization_2d(C, normalization),
            get_activation(activation),
            nn.Conv2d(C, C, kernel_size=K, padding=P),
            get_normalization_2d(C, normalization),
            get_activation(activation),
            nn.Conv2d(C, C, kernel_size=K, padding=P),
        ]
        layers = [layer for layer in layers if layer is not None]
        for layer in layers:
            _init_conv(layer, method=init)
        self.net = nn.Sequential(*layers)

    def forward(self, x):
        P = self.padding
        shortcut = x
        if P == 0:
            shortcut = x[:, :, P:-P, P:-P]
        y = self.net(x)
        return shortcut + self.net(x)


def _get_padding(K, mode):
    """ Helper method to compute padding size """
    if mode == 'valid':
        return 0
    elif mode == 'same':
        assert K % 2 == 1, 'Invalid kernel size %d for "same" padding' % K
        return (K - 1) // 2


def build_cnn(arch, normalization='batch', activation='leakyrelu', padding='same',
              pooling='max', init='default'):
    """
    Build a CNN from an architecture string, which is a list of layer
    specification strings. The overall architecture can be given as a list or as
    a comma-separated string.

    All convolutions *except for the first* are preceeded by normalization and
    nonlinearity.

    All other layers support the following:
    - IX: Indicates that the number of input channels to the network is X.
          Can only be used at the first layer; if not present then we assume
          3 input channels.
    - CK-X: KxK convolution with X output channels
    - CK-X-S: KxK convolution with X output channels and stride S
    - R: Residual block keeping the same number of channels
    - UX: Nearest-neighbor upsampling with factor X
    - PX: Spatial pooling with factor X
    - FC-X-Y: Flatten followed by fully-connected layer

    Returns a tuple of:
    - cnn: An nn.Sequential
    - channels: Number of output channels
    """
    if isinstance(arch, str):
        arch = arch.split(',')
    cur_C = 3
    if len(arch) > 0 and arch[0][0] == 'I':
        cur_C = int(arch[0][1:])
        arch = arch[1:]

    first_conv = True
    flat = False
    layers = []
    for i, s in enumerate(arch):
        if s[0] == 'C':
            if not first_conv:
                layers.append(get_normalization_2d(cur_C, normalization))
                layers.append(get_activation(activation))
            first_conv = False
            vals = [int(i) for i in s[1:].split('-')]
            if len(vals) == 2:
                K, next_C = vals
                stride = 1
            elif len(vals) == 3:
                K, next_C, stride = vals
            # K, next_C = (int(i) for i in s[1:].split('-'))
            P = _get_padding(K, padding)
            conv = nn.Conv2d(cur_C, next_C, kernel_size=K, padding=P, stride=stride)
            layers.append(conv)
            _init_conv(layers[-1], init)
            cur_C = next_C
        elif s[0] == 'R':
            norm = 'none' if first_conv else normalization
            res = ResidualBlock(cur_C, normalization=norm, activation=activation,
                                padding=padding, init=init)
            layers.append(res)
            first_conv = False
        elif s[0] == 'U':
            factor = int(s[1:])
            layers.append(Interpolate(scale_factor=factor, mode='nearest'))
        elif s[0] == 'P':
            factor = int(s[1:])
            if pooling == 'max':
                pool = nn.MaxPool2d(kernel_size=factor, stride=factor)
            elif pooling == 'avg':
                pool = nn.AvgPool2d(kernel_size=factor, stride=factor)
            layers.append(pool)
        elif s[:2] == 'FC':
            _, Din, Dout = s.split('-')
            Din, Dout = int(Din), int(Dout)
            if not flat:
                layers.append(Flatten())
            flat = True
            layers.append(nn.Linear(Din, Dout))
            if i + 1 < len(arch):
                layers.append(get_activation(activation))
            cur_C = Dout
        else:
            raise ValueError('Invalid layer "%s"' % s)
    layers = [layer for layer in layers if layer is not None]
    # for layer in layers:
    #   print(layer)
    return nn.Sequential(*layers), cur_C


def build_mlp(dim_list, activation='leakyrelu', batch_norm='none',
              dropout=0, final_nonlinearity=True):
    layers = []
    for i in range(len(dim_list) - 1):
        dim_in, dim_out = dim_list[i], dim_list[i + 1]
        layers.append(nn.Linear(dim_in, dim_out))
        final_layer = (i == len(dim_list) - 2)
        if not final_layer or final_nonlinearity:
            if batch_norm == 'batch':
                layers.append(nn.BatchNorm1d(dim_out))
            if activation == 'relu':
                layers.append(nn.ReLU())
            elif activation == 'leakyrelu':
                layers.append(nn.LeakyReLU())
        if dropout > 0:
            layers.append(nn.Dropout(p=dropout))
    return nn.Sequential(*layers)


class ResnetBlock(nn.Module):
    def __init__(self, dim, padding_type, norm_layer, activation=nn.ReLU(True), use_dropout=False):
        super(ResnetBlock, self).__init__()
        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, activation, use_dropout)

    def build_conv_block(self, dim, padding_type, norm_layer, activation, use_dropout):
        conv_block = []
        p = 0
        if padding_type == 'reflect':
            conv_block += [nn.ReflectionPad2d(1)]
        elif padding_type == 'replicate':
            conv_block += [nn.ReplicationPad2d(1)]
        elif padding_type == 'zero':
            p = 1
        else:
            raise NotImplementedError('padding [%s] is not implemented' % padding_type)

        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p),
                       norm_layer(dim),
                       activation]
        if use_dropout:
            conv_block += [nn.Dropout(0.5)]

        p = 0
        if padding_type == 'reflect':
            conv_block += [nn.ReflectionPad2d(1)]
        elif padding_type == 'replicate':
            conv_block += [nn.ReplicationPad2d(1)]
        elif padding_type == 'zero':
            p = 1
        else:
            raise NotImplementedError('padding [%s] is not implemented' % padding_type)
        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p),
                       norm_layer(dim)]

        return nn.Sequential(*conv_block)

    def forward(self, x):
        out = x + self.conv_block(x)
        return out


class ConditionalBatchNorm2d(nn.Module):
    def __init__(self, num_features, num_classes):
        super(ConditionalBatchNorm2d).__init__()
        self.num_features = num_features
        self.bn = nn.BatchNorm2d(num_features, affine=False)
        self.embed = nn.Embedding(num_classes, num_features * 2)
        self.embed.weight.data[:, :num_features].normal_(1, 0.02)  # Initialise scale at N(1, 0.02)
        self.embed.weight.data[:, num_features:].zero_()  # Initialise bias at 0

    def forward(self, x, y):
        out = self.bn(x)
        gamma, beta = self.embed(y).chunk(2, 1)
        out = gamma.view(-1, self.num_features, 1, 1) * out + beta.view(-1, self.num_features, 1, 1)
        return out


def get_norm_layer(norm_type='instance'):
    if norm_type == 'batch':
        norm_layer = functools.partial(nn.BatchNorm2d, affine=True)
    elif norm_type == 'instance':
        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False)
    elif norm_type == 'conditional':
        norm_layer = functools.partial(ConditionalBatchNorm2d)
    else:
        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)
    return norm_layer


class Interpolate(nn.Module):
    def __init__(self, size=None, scale_factor=None, mode='nearest', align_corners=None):
        super(Interpolate, self).__init__()
        self.size = size
        self.scale_factor = scale_factor
        self.mode = mode
        self.align_corners = align_corners

    def forward(self, x):
        return interpolate(x, size=self.size, scale_factor=self.scale_factor, mode=self.mode,
                           align_corners=self.align_corners)


layout.py

#!/usr/bin/python
#
# Copyright 2018 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import torch
import torch.nn as nn
import torch.nn.functional as F

from . import box_utils


"""
Functions for computing image layouts from object vectors, bounding boxes,
and segmentation masks. These are used to compute course scene layouts which
are then fed as input to the cascaded refinement network.
"""


def boxes_to_layout(vecs, boxes, obj_to_img, H, W=None, pooling='sum'):
  """
  Inputs:
  - vecs: Tensor of shape (O, D) giving vectors
  - boxes: Tensor of shape (O, 4) giving bounding boxes in the format
    [x0, y0, x1, y1] in the [0, 1] coordinate space
  - obj_to_img: LongTensor of shape (O,) mapping each element of vecs to
    an image, where each element is in the range [0, N). If obj_to_img[i] = j
    then vecs[i] belongs to image j.
  - H, W: Size of the output

  Returns:
  - out: Tensor of shape (N, D, H, W)
  """
  O, D = vecs.size()
  if W is None:
    W = H

  grid = _boxes_to_grid(boxes, H, W)

  # If we don't add extra spatial dimensions here then out-of-bounds
  # elements won't be automatically set to 0
  img_in = vecs.view(O, D, 1, 1).expand(O, D, 8, 8)
  sampled = F.grid_sample(img_in, grid)   # (O, D, H, W)

  # Explicitly masking makes everything quite a bit slower.
  # If we rely on implicit masking the interpolated boxes end up
  # blurred around the edges, but it should be fine.
  # mask = ((X < 0) + (X > 1) + (Y < 0) + (Y > 1)).clamp(max=1)
  # sampled[mask[:, None]] = 0

  out = _pool_samples(sampled, obj_to_img, pooling=pooling)

  return out


def masks_to_layout(vecs, boxes, masks, obj_to_img, H, W=None, pooling='sum'):
  """
  Inputs:
  - vecs: Tensor of shape (O, D) giving vectors
  - boxes: Tensor of shape (O, 4) giving bounding boxes in the format
    [x0, y0, x1, y1] in the [0, 1] coordinate space
  - masks: Tensor of shape (O, M, M) giving binary masks for each object
  - obj_to_img: LongTensor of shape (O,) mapping objects to images
  - H, W: Size of the output image.

  Returns:
  - out: Tensor of shape (N, D, H, W)
  """
  O, D = vecs.size()
  M = masks.size(1)
  assert masks.size() == (O, M, M)
  if W is None:
    W = H
  grid = _boxes_to_grid(boxes, H, W)
  img_in = vecs.view(O, D, 1, 1) * masks.float().view(O, 1, M, M)
  sampled = F.grid_sample(img_in, grid)
  out = _pool_samples(sampled, obj_to_img, pooling=pooling)
  return out


def _boxes_to_grid(boxes, H, W):
  """
  Input:
  - boxes: FloatTensor of shape (O, 4) giving boxes in the [x0, y0, x1, y1]
    format in the [0, 1] coordinate space
  - H, W: Scalars giving size of output

  Returns:
  - grid: FloatTensor of shape (O, H, W, 2) suitable for passing to grid_sample
  """
  O = boxes.size(0)
  boxes = box_utils.centers_to_extents(boxes)
  boxes = boxes.view(O, 4, 1, 1)

  # w,h = boxes[:, 2], boxes[:, 3]
  # # All these are (O, 1, 1)
  # x0, y0 = boxes[:, 0]-w/2, boxes[:, 1]-h/2
  # x1, y1 = boxes[:, 0]+w/2, boxes[:, 1]+h/2

  x0, y0 = boxes[:, 0], boxes[:, 1]
  ww, hh = boxes[:, 2] - x0, boxes[:, 3] - y0
  # ww = x1 - x0
  # hh = y1 - y0

  X = torch.linspace(0, 1, steps=W).view(1, 1, W).to(boxes)
  Y = torch.linspace(0, 1, steps=H).view(1, H, 1).to(boxes)
  X = (X - x0) / ww # (O, 1, W)
  Y = (Y - y0) / hh  # (O, H, 1)
  
  # Stack does not broadcast its arguments so we need to expand explicitly
  X = X.expand(O, H, W)
  Y = Y.expand(O, H, W)
  grid = torch.stack([X, Y], dim=3)  # (O, H, W, 2)

  # Right now grid is in [0, 1] space; transform to [-1, 1]
  grid = grid.mul(2).sub(1)

  return grid


def _pool_samples(samples, obj_to_img, pooling='sum'):
  """
  Input:
  - samples: FloatTensor of shape (O, D, H, W)
  - obj_to_img: LongTensor of shape (O,) with each element in the range
    [0, N) mapping elements of samples to output images

  Output:
  - pooled: FloatTensor of shape (N, D, H, W)
  """
  dtype, device = samples.dtype, samples.device
  O, D, H, W = samples.size()
  N = obj_to_img.data.max().item() + 1
  
  # Use scatter_add to sum the sampled outputs for each image
  out = torch.zeros(N, D, H, W, dtype=dtype, device=device)
  idx = obj_to_img.view(O, 1, 1, 1).expand(O, D, H, W)
  #out = out.scatter_add(0, idx, samples)

  if pooling == 'avg':
    # Divide each output mask by the number of objects; use scatter_add again
    # to count the number of objects per image.
    out = out.scatter_add(0, idx, samples)
    ones = torch.ones(O, dtype=dtype, device=device)
    obj_counts = torch.zeros(N, dtype=dtype, device=device)
    obj_counts = obj_counts.scatter_add(0, obj_to_img, ones)
    obj_counts = obj_counts.clamp(min=1)
    out = out / obj_counts.view(N, 1, 1, 1)
  elif pooling == 'max':
    all_out = []
    obj_to_img_list = [i.item() for i in list(obj_to_img)]
    for i in range(N):
        start = obj_to_img_list.index(i)
        end = len(obj_to_img_list) - obj_to_img_list[::-1].index(i)
        all_out.append(torch.max(samples[start:end, :, :, :], dim=0)[0])
    out = torch.stack(all_out)
  elif pooling == 'sum':
    out = out.scatter_add(0, idx, samples)
    #raise ValueError('Invalid pooling "%s"' % pooling)

  return out

def masks_to_seg(boxes, masks, objs, obj_to_img, H, W=None, num_classes=15):
  """
  Inputs:
  - vecs: Tensor of shape (O, D) giving vectors
  - boxes: Tensor of shape (O, 4) giving bounding boxes in the format
    [x0, y0, x1, y1] in the [0, 1] coordinate space
  - obj_to_img: LongTensor of shape (O,) mapping each element of vecs to
    an image, where each element is in the range [0, N). If obj_to_img[i] = j
    then vecs[i] belongs to image j.
  - H, W: Size of the output

  Returns:
  - out: Tensor of shape (N, D, H, W)
  """
  dtype, device = boxes.dtype, boxes.device
  O, D = boxes.size()
  M = masks.size(1)
  assert masks.size() == (O, M, M)
  if W is None:
    W = H
  N = obj_to_img.data.max().item() + 1
  grid = _boxes_to_grid(boxes, H, W)
  mask_sampled = F.grid_sample(masks.float().view(O, 1, M, M), grid)
  seg = torch.zeros((N,num_classes,H,W)).to(device)
  # obj_to_img_list = [i.item() for i in list(obj_to_img)]
  for i in range(N):
    obj_to_i = (obj_to_img==i).nonzero().view(-1)
    # start = obj_to_img_list.index(i)
    # end = len(obj_to_img_list) - obj_to_img_list[::-1].index(i)
    # for j in range(start,end):
    for j in obj_to_i:
      obj = objs[j]
      seg[i,obj]=seg[i,obj]+mask_sampled[j]
  return seg

def boxes_to_seg(boxes, objs, obj_to_img, H, W=None,num_classes=15):
  """
  Inputs:
  - vecs: Tensor of shape (O, D) giving vectors
  - boxes: Tensor of shape (O, 4) giving bounding boxes in the format
    [x0, y0, x1, y1] in the [0, 1] coordinate space
  - obj_to_img: LongTensor of shape (O,) mapping each element of vecs to
    an image, where each element is in the range [0, N). If obj_to_img[i] = j
    then vecs[i] belongs to image j.
  - H, W: Size of the output

  Returns:
  - out: Tensor of shape (N, D, H, W)
  """
  dtype, device = boxes.dtype, boxes.device
  O, D = boxes.size()
  if W is None:
    W = H
  N = obj_to_img.data.max().item() + 1

  grid = _boxes_to_grid(boxes, H, W)
  mask_sampled = F.grid_sample(torch.ones(O,1,8,8).to(boxes), grid)
  
  seg = torch.zeros((N,num_classes,H,W)).to(device)
  obj_to_img_list = [i.item() for i in list(obj_to_img)]
  for i in range(N):
    start = obj_to_img_list.index(i)
    end = len(obj_to_img_list) - obj_to_img_list[::-1].index(i)
    for j in range(start,end):
    #obj_to_i = (obj_to_img==i).nonzero().view(-1)
    #for j in obj_to_i:
      obj = objs[j]
      seg[i,obj]=seg[i,obj]+mask_sampled[j]
  return seg

if __name__ == '__main__':
  vecs = torch.FloatTensor([
            [1, 0, 0], [0, 1, 0], [0, 0, 1],
            [1, 0, 0], [0, 1, 0], [0, 0, 1],
         ])
  boxes = torch.FloatTensor([
            [0.25, 0.125, 0.5, 0.875],
            [0, 0, 1, 0.25],
            [0.6125, 0, 0.875, 1],
            [0, 0.8, 1, 1.0],
            [0.25, 0.125, 0.5, 0.875],
            [0.6125, 0, 0.875, 1],
          ])
  obj_to_img = torch.LongTensor([0, 0, 0, 1, 1, 1])
  # vecs = torch.FloatTensor([[[1]]])
  # boxes = torch.FloatTensor([[[0.25, 0.25, 0.75, 0.75]]])
  vecs, boxes = vecs.cuda(), boxes.cuda()
  obj_to_img = obj_to_img.cuda()
  out = boxes_to_layout(vecs, boxes, obj_to_img, 256, pooling='sum')
  
  from torchvision.utils import save_image
  save_image(out.data, 'out.png')


  masks = torch.FloatTensor([
            [
              [0, 0, 1, 0, 0],
              [0, 1, 1, 1, 0],
              [1, 1, 1, 1, 1],
              [0, 1, 1, 1, 0],
              [0, 0, 1, 0, 0],
            ],
            [
              [0, 0, 1, 0, 0],
              [0, 1, 0, 1, 0],
              [1, 0, 0, 0, 1],
              [0, 1, 0, 1, 0],
              [0, 0, 1, 0, 0],
            ],
            [
              [0, 0, 1, 0, 0],
              [0, 1, 1, 1, 0],
              [1, 1, 1, 1, 1],
              [0, 1, 1, 1, 0],
              [0, 0, 1, 0, 0],
            ],
            [
              [0, 0, 1, 0, 0],
              [0, 1, 1, 1, 0],
              [1, 1, 1, 1, 1],
              [0, 1, 1, 1, 0],
              [0, 0, 1, 0, 0],
            ],
            [
              [0, 0, 1, 0, 0],
              [0, 1, 1, 1, 0],
              [1, 1, 1, 1, 1],
              [0, 1, 1, 1, 0],
              [0, 0, 1, 0, 0],
            ],
            [
              [0, 0, 1, 0, 0],
              [0, 1, 1, 1, 0],
              [1, 1, 1, 1, 1],
              [0, 1, 1, 1, 0],
              [0, 0, 1, 0, 0],
            ]
          ])
  masks = masks.cuda()
  out = masks_to_layout(vecs, boxes, masks, obj_to_img, 256)
  save_image(out.data, 'out_masks.png')


model.py

#!/usr/bin/python
#
# Copyright 2018 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licens8.0es/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import math
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision.ops import RoIAlign

from . import box_utils
from .graph import GraphTripleConv, GraphTripleConvNet
from .layout import boxes_to_layout, masks_to_layout, boxes_to_seg, masks_to_seg
from .layers import build_mlp,build_cnn
from .utils import vocab

class Model(nn.Module):
  def __init__(self,
              embedding_dim=128,
              image_size=(128,128),
              input_dim=3,
              attribute_dim=35,
              # graph_net
              gconv_dim=128,
              gconv_hidden_dim=512,
              gconv_num_layers=5,
              # inside_cnn
              inside_cnn_arch="C3-32-2,C3-64-2,C3-128-2,C3-256-2",
              # refinement_net
              refinement_dims=(1024, 512, 256, 128, 64),
              # box_refine
              box_refine_arch = "I15,C3-64-2,C3-128-2,C3-256-2",
              roi_output_size = (8,8),
              roi_spatial_scale = 1.0/8.0,
              roi_cat_feature = True,
              # others
              mlp_activation='leakyrelu',
              mlp_normalization='none',
              cnn_activation='leakyrelu',
              cnn_normalization='batch'
              ):
    super(Model, self).__init__()
    ''' embedding '''
    self.vocab = vocab
    num_objs = len(vocab['object_idx_to_name'])
    num_preds = len(vocab['pred_idx_to_name'])
    num_doors = len(vocab['door_idx_to_name'])
    self.obj_embeddings = nn.Embedding(num_objs, embedding_dim)
    self.pred_embeddings = nn.Embedding(num_preds, embedding_dim)
    self.image_size = image_size
    self.feature_dim = embedding_dim+attribute_dim

    ''' graph_net '''
    self.gconv = GraphTripleConv(
      embedding_dim,
      attributes_dim=attribute_dim, 
      output_dim=gconv_dim,
      hidden_dim=gconv_hidden_dim,
      mlp_normalization=mlp_normalization
    )
    self.gconv_net = GraphTripleConvNet(
      gconv_dim,
      num_layers=gconv_num_layers-1,
      mlp_normalization=mlp_normalization
    )
  
    ''' inside_cnn '''
    inside_cnn,inside_feat_dim = build_cnn(
        f'I{input_dim},{inside_cnn_arch}',
        padding='valid'
    )
    self.inside_cnn = nn.Sequential(
      inside_cnn,
      nn.AdaptiveAvgPool2d(1)
    )
    inside_output_dim = inside_feat_dim
    obj_vecs_dim = gconv_dim+inside_output_dim

    ''' box_net '''
    box_net_dim = 4
    box_net_layers = [obj_vecs_dim, gconv_hidden_dim, box_net_dim]
    self.box_net = build_mlp(
      box_net_layers,
      activation=mlp_activation, 
      batch_norm=mlp_normalization
    )
    
    ''' relationship_net '''
    rel_aux_layers = [obj_vecs_dim, gconv_hidden_dim, num_doors]
    self.rel_aux_net = build_mlp(
      rel_aux_layers,
      activation=mlp_activation, 
      batch_norm=mlp_normalization
    )

    ''' refinement_net '''
    if refinement_dims!=None:
      self.refinement_net,_ = build_cnn(f"I{obj_vecs_dim},C3-128,C3-64,C3-{num_objs}")
    else:
      self.refinement_net = None

    ''' roi '''
    self.box_refine_backbone = None
    self.roi_cat_feature = roi_cat_feature
    if box_refine_arch!=None:
      box_refine_cnn,box_feat_dim = build_cnn(
        box_refine_arch,
        padding='valid'
      )
      self.box_refine_backbone = box_refine_cnn
      self.roi_align = RoIAlign(roi_output_size,roi_spatial_scale,-1) #(256,8,8)
      self.down_sample = nn.AdaptiveAvgPool2d(1)
      box_refine_layers = [obj_vecs_dim+256 if self.roi_cat_feature else 256, 512, 4]
      self.box_reg =build_mlp(
          box_refine_layers,
          activation=mlp_activation, 
          batch_norm=mlp_normalization
      )

  def forward(
    self, 
    objs, 
    triples, 
    boundary,
    obj_to_img=None,
    attributes=None,
    boxes_gt=None, 
    generate=False,
    refine=False,
    relative=False,
    inside_box=None
    ):
    """
    Required Inputs:
    - objs: LongTensor of shape (O,) giving categories for all objects
    - triples: LongTensor of shape (T, 3) where triples[t] = [s, p, o]
      means that there is a triple (objs[s], p, objs[o])

    Optional Inputs:
    - obj_to_img: LongTensor of shape (O,) where obj_to_img[o] = i
      means that objects[o] is an object in image i. If not given then
      all objects are assumed to belong to the same image.
    - boxes_gt: FloatTensor of shape (O, 4) giving boxes to use for computing
      the spatial layout; if not given then use predicted boxes.
    """
    # input size
    O, T = objs.size(0), triples.size(0)
    s, p, o = triples.chunk(3, dim=1)           # All have shape (T, 1)
    s, p, o = [x.squeeze(1) for x in [s, p, o]] # Now have shape (T,)
    edges = torch.stack([s, o], dim=1)          # Shape is (T, 2)
    B = boundary.size(0)
    H, W = self.image_size
  
    if obj_to_img is None:
      obj_to_img = torch.zeros(O, dtype=objs.dtype, device=objs.device)
    
    ''' embedding '''
    obj_vecs = self.obj_embeddings(objs)
    pred_vecs = self.pred_embeddings(p)

    ''' attribute '''
    if attributes is not None:
      obj_vecs = torch.cat([obj_vecs,attributes],1)
    obj_vecs_orig = obj_vecs
    
    ''' gconv '''
    obj_vecs, pred_vecs = self.gconv(obj_vecs, pred_vecs, edges)
    obj_vecs, pred_vecs = self.gconv_net(obj_vecs, pred_vecs, edges)

    ''' inside '''
    inside_vecs = self.inside_cnn(boundary).view(B,-1)
    obj_vecs = torch.cat([obj_vecs,inside_vecs[obj_to_img]],dim=1)

    ''' box '''
    boxes_pred = self.box_net(obj_vecs)
    if relative: boxes_pred = box_utils.box_rel2abs(boxes_pred,inside_box,obj_to_img)

    ''' relation '''
    # unused, for door position predition
    # rel_scores = self.rel_aux_net(obj_vecs)

    ''' generate '''
    gene_layout = None
    boxes_refine = None
    layout_boxes = boxes_pred if boxes_gt is None else boxes_gt
    if generate:
      layout_features = boxes_to_layout(obj_vecs,layout_boxes,obj_to_img,H,W)
      gene_layout = self.refinement_net(layout_features)
      
    ''' box refine '''
    if refine:
      gene_feat = self.box_refine_backbone(gene_layout)
      rois = torch.cat([
        obj_to_img.float().view(-1,1),
        box_utils.centers_to_extents(layout_boxes)*H
      ],-1)
      roi_feat = self.down_sample(self.roi_align(gene_feat,rois)).flatten(1)
      roi_feat = torch.cat([
        roi_feat,
        obj_vecs
      ],-1)
      boxes_refine = self.box_reg(roi_feat)
      if relative: boxes_refine = box_utils.box_rel2abs(boxes_refine,inside_box,obj_to_img)

    return boxes_pred, gene_layout, boxes_refine


plot.py

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from shapely import geometry
from .utils import room_label
from matplotlib.transforms import Bbox
import matplotlib.image as mpimg
from matplotlib.patches import PathPatch

# Load texture images and map to room type index
texture_map = {
    0: mpimg.imread(r"D:\\major project\\Florex\\Interface\\texture\\Bedroom.jpg"),
    1: mpimg.imread(r"D:\\major project\\Florex\\Interface\\texture\\StudyRoom.jpg"),
    2: mpimg.imread(r"D:\\major project\\Florex\\Interface\\texture\\FunctionArea.jpg"),
    3: mpimg.imread(r"D:\\major project\\Florex\\Interface\\texture\\PublicArea.jpg"),
    # Add more mappings if needed
}

def get_color_map():
    color = np.array([
        [244,242,229], # living room
        [253,244,171], # bedroom
        [234,216,214], # kitchen
        [205,233,252], # bathroom
        [208,216,135], # balcony
        [249,222,189], # Storage
        [ 79, 79, 79], # exterior wall
        [255,225, 25], # FrontDoor
        [128,128,128], # interior wall
        [255,255,255]
    ],dtype=np.int64)
    cIdx  = np.array([1,2,3,4,1,2,2,2,2,5,1,6,1,10,7,8,9,10])-1
    return color[cIdx]
cmap = get_color_map()/255.0

def get_figure(size=512):
    if np.array(size).size==1:
        w,h = size,size
    else:
        w,h = size[0],size[1]
    fig = plt.figure()
    dpi = fig.get_dpi()
    fig.set_size_inches(w/dpi,h/dpi)
    fig.set_frameon(False)
    return fig    

def get_axes(size=512,fig=None,rect=[0,0,1,1]):
    if fig is None: fig = get_figure(size)

    ax = fig.add_axes(rect)
    #ax.set_frame_on(False)
    ax.set_aspect('equal')
    ax.set_xlim([0,255])
    ax.set_ylim([0,255])
    ax.invert_yaxis()
    ax.set_axis_off()
    
    return ax

def plot_category(category,show_boundary=True,ax=None):
    if ax is None: ax = get_axes()
    img = np.ones((category.shape[0],category.shape[1],4))
    img[...,:3] = cmap[category]
    img[category==13,3] = 0
    if not show_boundary: 
        img[np.isin(category,[14,15])]=[1.,1.,1.,0.]
    ax.imshow(img)
    return ax

def plot_boundary(boundary, wall_thickness=6,ax=None):
    if ax is None: ax = get_axes()
    
    is_new = boundary[:,-1]==1
    poly_boundary = geometry.Polygon(boundary[~is_new,:2])
    x,y = poly_boundary.exterior.xy
    ax.fill(x,y,fc='none',ec=cmap[14],lw=wall_thickness,joinstyle='round')

    door = boundary[:2,:2]
    idx = np.argmin(np.sum(door,axis=-1), axis=0)
    if idx==1: door = door[[1,0]]

    ori = boundary[0,2]
    if ori%2==0:
        door = door+np.array([
            [wall_thickness/4,0],[-wall_thickness/4,0]
        ])
    else:
        door = door+np.array([
            [0,wall_thickness/4],
            [0,-wall_thickness/4]
        ])
    ax.plot(door[:,0],door[:,1],color=cmap[15],lw=wall_thickness+1)

    return ax

def plot_graph(boundary, boxes, types, edges, wall_thickness=6,with_boundary=True,ax=None):
    if ax is None: ax = get_axes()

    if with_boundary: plot_boundary(boundary,wall_thickness,ax)

    boxes = boxes.astype(float)
    r_node = np.zeros((len(boxes),3))
    for k in range(len(boxes)):
        r_node[k,:2] = (boxes[k,:2]+boxes[k,2:])/2
        r_node[k,2] = (boxes[k,2]-boxes[k,0])*(boxes[k,3]-boxes[k,1])
    
    for i in range(len(edges)):
        idx = edges[i,:2]
        ax.plot(r_node[idx,0],r_node[idx,1],'-',color=[0.7,0.7,0.7],lw=wall_thickness/2)

    is_new = boundary[:,-1]==1
    poly_boundary = geometry.Polygon(boundary[~is_new,:2])
    for i in range(len(r_node)):
        s = round(10*r_node[i,2])/poly_boundary.area*3+wall_thickness*3
        ax.plot(r_node[i,0],r_node[i,1],'o',mec=cmap[16],mfc=cmap[types[i]],ms=s)

    return ax

def plot_fp(boundary, boxes, types, doors=[], windows=[], wall_thickness=6, fontsize=0, keep_box=False, alpha=1.0, ax=None):
    if ax is None: ax = get_axes()

    is_new = boundary[:,-1]==1
    poly_boundary = geometry.Polygon(boundary[~is_new,:2])
    poly = dict()
    
    for k in range(len(boxes)):
        poly_room = geometry.box(*boxes[k])
        poly[k] = poly_boundary.intersection(poly_room)
        if poly[k].area==0: 
            print(f'ploting empty box {k}!') 
            continue

        if keep_box:
            poly[k] = geometry.box(*poly[k].bounds)
            x, y = poly[k].exterior.xy
            patch = patches.Polygon(np.column_stack([x, y]), closed=True, transform=ax.transData, edgecolor=cmap[16], linewidth=wall_thickness, joinstyle='round')

            room_type = types[k]
            if room_type in texture_map:
                img = texture_map[room_type]
                
                # define bounding box to place texture
                bounds = poly[k].bounds  # (minx, miny, maxx, maxy)
                ax.imshow(img, extent=bounds, clip_path=patch, clip_on=True, zorder=1)
                ax.add_patch(patch)
            else:
                ax.add_patch(patch)
                patch.set_facecolor(cmap[room_type])
                patch.set_alpha(alpha)
        else:
            if poly[k].geom_type!='Polygon':
                for p in poly[k]:
                    if p.geom_type!='Polygon': continue
                    x,y = p.exterior.xy
                    ax.fill(x,y,fc=cmap[types[k]],ec=cmap[16],alpha=alpha,lw=wall_thickness,joinstyle='round')
            else:
                x,y = poly[k].exterior.xy
                ax.fill(x,y,fc=cmap[types[k]],ec=cmap[16],alpha=alpha,lw=wall_thickness,joinstyle='round')

    plot_boundary(boundary,wall_thickness,ax)

    if len(doors)>0:
        plot_door(doors, wall_thickness/3, ax)
    if len(windows)>0:
        plot_window(windows, wall_thickness/3, ax)

    if fontsize!=0:         
        for k in range(len(boxes)):
            if poly[k].area==0: continue
            cx, cy = poly[k].centroid.x,poly[k].centroid.y
            ax.text(cx, cy, room_label[types[k]][1], fontsize=fontsize,horizontalalignment='center',verticalalignment='center')
    
    return ax

def plot_window(windows, thickness=2, ax=None):
    if ax is None: ax = get_axes()
    for k in range(len(windows)):
        window = windows[k]
        seg = np.zeros((2,2))
        seg[0] = window[1:3]
        seg[1] = window[1:3]+ window[3:5]
    
        box = np.concatenate([seg.min(0),seg.max(0)],axis=-1)

        if window[3] < window[4]:
            box = box + np.array([-1,0,1,0]) * thickness
            if window[4] > 0:
                box[1] = box[1] + thickness
                seg[0,1] = seg[0,1] + thickness
            else:
                box[3] = box[3] - thickness
                seg[0,1] = seg[0,1] - thickness
        else:
            box = box + np.array([0,-1,0,1]) * thickness
            if window[3] > 0:
                box[0] = box[0] + thickness
                seg[0,0] = seg[0,0] + thickness
            else:
                box[2] = box[2] - thickness
                seg[0,0] = seg[0,0] - thickness
        
        ax.fill(box[[0,0,2,2,0]], box[[1,3,3,1,1]], 'w')
        
        ax.plot(box[[0,0,2,2,0]], box[[1,3,3,1,1]], color=[0.4,0.4,0.4], lw=1)
        ax.plot(seg[:,0], seg[:,1], color=[0.4,0.4,0.4], lw=1)
    
    return ax

def plot_door(doors, thickness, ax=None):
    if ax is None: ax = get_axes()
    for k in range(len(doors)):
        door = doors[k]
        seg = np.zeros((2,2))
        seg[0] = door[1:3]
        seg[1] = door[1:3]+ door[3:5]
    
        box = np.concatenate([seg.min(0),seg.max(0)],axis=-1)

        if door[3] < door[4]:
            box = box + np.array([-1,0,1,0]) * thickness
            if door[4] > 0:
                box[1] = box[1] + thickness
            else:
                box[3] = box[3] - thickness
        else:
            box = box + np.array([0,-1,0,1]) * thickness
            if door[3] > 0:
                box[0] = box[0] + thickness
            else:
                box[2] = box[2] - thickness
        
        ax.fill(box[[0,0,2,2,0]], box[[1,3,3,1,1]], 'w', ec=cmap[16])

    return ax
        

retrieval.py

import numpy as np
import time
def compute_tf(b):
    '''
    input: boundary points array (x,y,dir,isNew)
    return: tf.x, tf.y
    '''
    if b.shape[1]>2:
        b=b[:,:2]
    b = np.concatenate((b,b[:1]))
    nPoint = len(b)-1
    lineVec = b[1:]-b[:-1]
    lineLength = np.linalg.norm(lineVec,axis=1)
    
    perimeter = lineLength.sum()
    lineVec = lineVec/perimeter
    lineLength = lineLength/perimeter

    angles = np.zeros(nPoint)
    for i in range(nPoint):
        z = np.cross(lineVec[i],lineVec[(i+1)%nPoint])
        sign = np.sign(z)
        angles[i] = np.arccos(np.dot(lineVec[i],lineVec[(i+1)%nPoint]))*sign

    x = np.zeros(nPoint+1)
    y = np.zeros(nPoint+1)
    s = 0
    for i in range(1,nPoint+1):
        x[i] = lineLength[i-1]+x[i-1]
        y[i-1] = angles[i-1]+s
        s = y[i-1]
    y[-1] = s
    return x,y

def sample_tf(x,y,ndim=1000):
    '''
    input: tf.x,tf.y, ndim
    return: n-dim tf values
    '''
    t = np.linspace(0,1,ndim)
    return np.piecewise(t,[t>=xx for xx in x],y)

class DataRetriever():
    def __init__(self,tf_train,centroids,clusters):
        '''
        tf_train: tf of training data
        centroids: tf cluster centroids of training data
        clusters: data index for each cluster of training data
        '''
        self.tf_train = tf_train
        self.centroids = centroids
        self.clusters = clusters
    
    def retrieve_bf(self,datum,k=20):
        # compute tf for the data boundary
        x,y = compute_tf(datum.boundary)
        y_sampled = sample_tf(x,y,1000)
        dist = np.linalg.norm(y_sampled-self.tf_train,axis=1)
        if k>np.log2(len(self.tf_train)):
            index = np.argsort(dist)[:k]
        else:
            index = np.argpartition(dist,k)[:k]
            index = index[np.argsort(dist[index])]
        return index

    def retrieve_cluster(self,datum,k=20,multi_clusters=False):
        '''
        datum: test data
        k: retrieval num
        return: index for training data 
        '''
        # compute tf for the data boundary
        x,y = compute_tf(datum.boundary)
        y_sampled = sample_tf(x,y,1000)
        # compute distance to cluster centers
        dist = np.linalg.norm(y_sampled-self.centroids,axis=1)

        if multi_clusters:
            # more candicates
            c = int(np.max(np.clip(np.log2(k),1,5)))
            cluster_idx = np.argsort(dist)[:c]
            cluster = np.unique(self.clusters[cluster_idx].reshape(-1))
        else:
            # only candicates
            cluster_idx = np.argmin(dist)
            cluster = self.clusters[cluster_idx]

        # compute distance to cluster samples
        dist = np.linalg.norm(y_sampled-self.tf_train[cluster],axis=1)
        index = cluster[np.argsort(dist)[:k]]
        return index

if __name__ == "__main__":
    import scipy.io as sio
    import pickle
    from time import time
    import cv2
    import matplotlib.pyplot as plt

    def vis_boundary(b):
        img = np.ones((256,256,3))
        img = cv2.line(img,tuple(b[0,:2]),tuple(b[1,:2]),(1.,1.,0.),thickness=2)
        for i in range(1,len(b)-1):
            img = cv2.line(img,tuple(b[i,:2]),tuple(b[i+1,:2]),(0.,0.,0.),thickness=2)
        img = cv2.line(img,tuple(b[0,:2]),tuple(b[-1,:2]),(0.,0.,0.),thickness=2)
        plt.imshow(img)
        plt.show()

    #data_train = sio.loadmat('data_train70.mat',squeeze_me=True,struct_as_record=False)['data']
    #data_test = #sio.loadmat('data_test15.mat',squeeze_me=True,struct_as_record=False)['data']
    t1 = time()
    train_data = pickle.load(open('data_train_converted.pkl','rb'))['data']
    t2 = time()
    print('load train',t2-t1)

    t1 = time()
    test_data = pickle.load(open('data_test_converted.pkl','rb'))
    test_data, testNameList, trainNameList = test_data['data'], list(test_data['testNameList']), list(
        test_data['trainNameList'])
    t2 = time()
    print('load test',t2-t1)

    t1 = time()
    tf_train = np.load('tf_train.npy')
    centroids = np.load('centroids_train.npy')
    clusters = np.load('clusters_train.npy')
    t2 = time()
    print('load tf/centroids/clusters',t2-t1)

    retriever = DataRetriever(tf_train,centroids,clusters)

    datum = np.random.choice(test_data,1)[0]
    vis_boundary(datum.boundary)

    t1 = time()
    index = retriever.retrieve_cluster(datum,k=10,multi_clusters=False)
    t2 = time()
    print('cluster',t2-t1)
    data_retrieval = train_data[index]
    vis_boundary(data_retrieval[0].boundary)

    t1 = time()
    index = retriever.retrieve_bf(datum,k=10)
    t2 = time()
    print('bf',t2-t1)
    data_retrieval = train_data[index]
    vis_boundary(data_retrieval[0].boundary)


utils.py

import numpy as np

# index,name,type(private/public),floorTexture
room_label = [(0, 'LivingRoom', 1, "PublicArea",[220, 213, 205]),
              (1, 'MasterRoom', 0, "Bedroom",[138, 113, 91]),
              (2, 'Kitchen', 1, "FunctionArea",[244, 245, 247]),
              (3, 'Bathroom', 0, "FunctionArea",[224, 225, 227]),
              (4, 'DiningRoom', 1, "FunctionArea",[200, 193, 185]),
              (5, 'ChildRoom', 0, "Bedroom",[198, 173, 151]),
              (6, 'StudyRoom', 0, "Bedroom",[178, 153, 131]),
              (7, 'SecondRoom', 0, "Bedroom",[158, 133, 111]),
              (8, 'GuestRoom', 0, "Bedroom",[189, 172, 146]),
              (9, 'Balcony', 1, "PublicArea",[244, 237, 224]),
              (10, 'Entrance', 1, "PublicArea",[238, 235, 230]),
              (11, 'Storage', 0, "PublicArea",[226, 220, 206]),
              (12, 'Wall-in', 0, "PublicArea",[226, 220, 206]),
              (13, 'External', 0, "External",[255, 255, 255]),
              (14, 'ExteriorWall', 0, "ExteriorWall",[0, 0, 0]),
              (15, 'FrontDoor', 0, "FrontDoor",[255,255,0]),
              (16, 'InteriorWall', 0, "InteriorWall",[128,128,128]),
              (17, 'InteriorDoor', 0, "InteriorDoor",[255,255,255])]

# color palette for nyu40 labels
def create_color_palette():
    return [
       (0, 0, 0),
       (174, 199, 232),		# wall
       (152, 223, 138),		# floor
       (31, 119, 180), 		# cabinet
       (255, 187, 120),		# bed
       (188, 189, 34), 		# chair
       (140, 86, 75),  		# sofa
       (255, 152, 150),		# table
       (214, 39, 40),  		# door
       (197, 176, 213),		# window
       (148, 103, 189),		# bookshelf
       (196, 156, 148),		# picture
       (23, 190, 207), 		# counter
       (178, 76, 76),  
       (247, 182, 210),		# desk
       (66, 188, 102), 
       (219, 219, 141),		# curtain
       (140, 57, 197), 
       (202, 185, 52), 
       (51, 176, 203), 
       (200, 54, 131), 
       (92, 193, 61),  
       (78, 71, 183),  
       (172, 114, 82), 
       (255, 127, 14), 		# refrigerator
       (91, 163, 138), 
       (153, 98, 156), 
       (140, 153, 101),
       (158, 218, 229),		# shower curtain
       (100, 125, 154),
       (178, 127, 135),
       (120, 185, 128),
       (146, 111, 194),
       (44, 160, 44),  		# toilet
       (112, 128, 144),		# sink
       (96, 207, 209), 
       (227, 119, 194),		# bathtub
       (213, 92, 176), 
       (94, 106, 211), 
       (82, 84, 163),  		# otherfurn
       (100, 85, 144)
    ]
color_palette = create_color_palette()[1:]

semantics_cmap = {
    'living room': '#e6194b',#[230,25,75]
    'kitchen': '#3cb44b',#[60,180,75]
    'bedroom': '#ffe119',#[255,225,25]
    'bathroom': '#0082c8',#[0,130,200]
    'balcony': '#f58230',#[245,130,48]
    'corridor': '#911eb4',#[145,30,180]
    'dining room': '#46f0f0',#[70,240,240]
    'study': '#f032e6',#[240,50,230]
    'studio': '#d2f53c',#[210,245,60]
    'store room': '#fabebe',#[250,190,190]
    'garden': '#008080',#[0,128,128]
    'laundry room': '#e6beff',#[230,190,255]
    'office': '#aa6e28',#[170,110,40]
    'basement': '#fffac8',#[255,250,200]
    'garage': '#800000',#[128,0,0]
    'undefined': '#aaffc3',#[170,255,195]
    'door': '#808000',#[128,128,0]
    'window': '#ffd7b4',#[255,215,180]
    'outwall': '#000000',#[0,0,0]
}

colormap_255 = [
    [230,  25,  75],#LivingRoom
    [ 60, 180,  75],#MasterRoom
    [170, 255, 195],#Kitchen
    [  0, 130, 200],#Bathroom
    [245, 130,  48],#DiningRoom
    [145,  30, 180],#ChildRoom
    [ 70, 240, 240],#StudyRoom
    [240,  50, 230],#SecondRoom
    [210, 245,  60],#GuestRoom
    [250, 190, 190],#Balcony
    [  0, 128, 128],#Entrance
    [230, 190, 255],#Storage
    [170, 110,  40],#Wall-in
    [255, 255, 255],#External
    [128,   0,   0],#ExteriorWall
    [255, 225,  25],#FrontDoor
    [128, 128, 128],#InteriorWall
    [255, 255, 255],#InteriorDoor
    #[255, 215, 180],
    [  0,   0, 128],
    [128, 128,   0],
    [255, 255, 255],
    [  0,   0,   0]
]

cmaps = {
    'nyu40': color_palette,
    'semantics': semantics_cmap,
    '255': colormap_255
}

category = [category for category in room_label if category[1] not in set(['External',
                                                                           'ExteriorWall', 'FrontDoor', 'InteriorWall', 'InteriorDoor'])]

num_category = len(category)

pixel2length = 18/256

def label2name(label=0):
    if label < 0 or label > 17:
        raise Exception("Invalid label!", label)
    else:
        return room_label[label][1]


def label2index(label=0):
    if label < 0 or label > 17:
        raise Exception("Invalid label!", label)
    else:
        return label


def index2label(index=0):
    if index < 0 or index > 17:
        raise Exception("Invalid index!", index)
    else:
        return index


def compute_centroid(mask):
    sum_h = 0
    sum_w = 0
    count = 0
    shape_array = mask.shape
    for h in range(shape_array[0]):
        for w in range(shape_array[1]):
            if mask[h, w] != 0:
                sum_h += h
                sum_w += w
                count += 1
    return (sum_h//count, sum_w//count)


def log(file, msg='', is_print=True):
    if is_print:
        print(msg)
    file.write(msg + '\n')
    file.flush()


def collide2d(bbox1, bbox2, th=0):
    return not(
        (bbox1[0]-th > bbox2[2]) or
        (bbox1[2]+th < bbox2[0]) or
        (bbox1[1]-th > bbox2[3]) or
        (bbox1[3]+th < bbox2[1])
    )
#
# def rot90_2D(pts,k=1,cnt=np.array([127.5,127.5])):
#     ang = k*np.pi/2
#     R = np.array([[np.cos(ang),np.sin(ang)],[-np.sin(ang),np.cos(ang)]])
#     return np.dot(pts-cnt,R)+cnt
# def fliplr_2D(pts,size=255):
#     return np.stack([pts[:,0],size-pts[:,1]],1)
#
# def align_image(image,rot_old,rot_new=0):
#     k = np.ceil((rot_old-rot_new+2*np.pi)%(2*np.pi)/(np.pi/4))//2
#     return np.rot90(image,k)
#
# def align_box(box,rot_old,rot_new=0):
#     k = np.ceil((rot_old-rot_new+2*np.pi)%(2*np.pi)/(np.pi/4))//2
#     box = rot90_2D(box.reshape(-1,2),k).reshape(-1,4)
#     return np.concatenate([np.minimum(box[:,:2],box[:,2:]),np.maximum(box[:,:2],box[:,2:])],-1)#.round().astype(int)
#
# def fliplr_box(box,size=255):
#     box=fliplr_2D(box.reshape(-1,2),size=size).reshape(-1,4)
#     return np.concatenate([np.minimum(box[:,:2],box[:,2:]),np.maximum(box[:,:2],box[:,2:])],-1)#.round().astype(int)


def rot90_2D(pts, k=1, cnt=np.array([127.5, 127.5])):
    ang = k * np.pi / 2
    R = np.array([[np.cos(ang), np.sin(ang)], [-np.sin(ang), np.cos(ang)]])
    return np.dot(pts - cnt, R) + cnt


def fliplr_2D(pts, size=255):
    return np.stack([pts[:, 0], size - pts[:, 1]], 1)


def align_image(image, rot_old, rot_new=0):
    k = np.ceil((rot_old - rot_new + 2 * np.pi) % (2 * np.pi) / (np.pi / 4)) // 2
    return np.rot90(image, k)


def align_box(box, rot_old, rot_new=0):
    k = np.ceil((rot_old - rot_new + 2 * np.pi) % (2 * np.pi) / (np.pi / 4)) // 2
    box = rot90_2D(box.reshape(-1, 2), k).reshape(-1, 4)
    return np.concatenate([np.minimum(box[:, :2], box[:, 2:]), np.maximum(box[:, :2], box[:, 2:]) + 1],
                          -1).round().astype(int)


def align_points(points, rot_old, rot_new=0):
    k = np.ceil((rot_old - rot_new + 2 * np.pi) % (2 * np.pi) / (np.pi / 4)) // 2
    points = rot90_2D(points, k)
    return points.round().astype(int)

def graph2labels(graph):
    edges = graph.edges
    return sorted([
        tuple(sorted((room_label[graph.nodes[u]['category']][1],
        room_label[graph.nodes[v]['category']][1])))
        for u,v in edges
    ])

def graph2labels_withtype(graph):
    edges = graph.edges(data=True)
    return sorted([
        ('acc' if d['type'] else 'adj',
        *sorted(
            (room_label[graph.nodes[u]['category']][1],
            room_label[graph.nodes[v]['category']][1]))
        ) 
        for u,v,d in edges
    ])

def graph2functions(graph):
    edges = graph.edges
    return sorted([
        tuple(sorted((graph.nodes[u]['function'],
        graph.nodes[v]['function'])))
        for u,v in edges
    ])

def graph2functions_withtype(graph):
    edges = graph.edges(data=True)
    return sorted([
        ('acc' if d['type'] else 'adj',
        *sorted(
            (graph.nodes[u]['function'],
            graph.nodes[v]['function']))
        )
        for u,v,d in edges
    ])

def counter2labels(counter):
    return sorted({
        room_label[key][1]:value 
        for key,value in counter.items()
    }.items())

def counter2functions(counter):
    counter_new = {
        room_label[key][1]:value 
        for key,value in counter.items()
    }
    counter_new['Bedroom']=0
    for key in counter:
        if room_label[key][3]=='Bedroom':
            counter_new['Bedroom']+=counter_new.pop(room_label[key][1])
    return sorted(counter_new.items())

def point_box_relation(u,vbox):
    uy,ux = u
    vy0, vx0, vy1, vx1 = vbox

    if (ux<vx0 and uy<=vy0) or (ux==vx0 and uy==vy0):
        relation = 'left-above'
    elif (vx0<=ux<vx1 and uy<=vy0):
        relation = 'above'
    elif (vx1<=ux and uy<vy0) or (ux==vx1 and uy==vy0):
        relation = 'right-above'
    elif (vx1<=ux and vy0<=uy<vy1):
        relation = 'right-of'
    elif (vx1<ux and vy1<=uy) or (ux==vx1 and uy==vy1):
        relation = 'right-below'
    elif (vx0<ux<=vx1 and vy1<=uy):
        relation = 'below'
    elif (ux<=vx0 and vy1<uy) or (ux==vx0 and uy==vy1):
        relation = 'left-below'
    elif(ux<=vx0 and vy0<uy<=vy1):
        relation = "left-of"
    elif(vx0<ux<vx1 and vy0<uy<vy1):
        relation = "inside"

    return relation

def get_vocab():
    room_label = [(0, 'LivingRoom', 1, "PublicArea"),
              (1, 'MasterRoom', 0, "Bedroom"),
              (2, 'Kitchen', 1, "FunctionArea"),
              (3, 'Bathroom', 0, "FunctionArea"),
              (4, 'DiningRoom', 1, "FunctionArea"),
              (5, 'ChildRoom', 0, "Bedroom"),
              (6, 'StudyRoom', 0, "Bedroom"),
              (7, 'SecondRoom', 0, "Bedroom"),
              (8, 'GuestRoom', 0, "Bedroom"),
              (9, 'Balcony', 1, "PublicArea"),
              (10, 'Entrance', 1, "PublicArea"),
              (11, 'Storage', 0, "PublicArea"),
              (12, 'Wall-in', 0, "PublicArea"),
              (13, 'External', 0, "External"),
              (14, 'Internal', 0, "Internal")]
    
    predicates = [
        'left-above',
        'left-below',
        'left-of',
        'above',
        'inside',
        'surrounding',
        'below',
        'right-of',
        'right-above',
        'right-below'
    ]

    door_pos = [
        'nan',
        'bottom',
        'bottom-right','right-bottom',
        'right',
        'right-top','top-right',
        'top',
        'top-left','left-top',
        'left',
        'left-bottom','bottom-left'
    ]

    vocab = {
        'object_name_to_idx':{},
        'object_to_idx':{},
        'object_idx_to_name':[],
        'pred_idx_to_name':[],
        'pred_name_to_idx':{},
        'door_idx_to_name':[],
        'door_name_to_idx':{}
    }
    
    vocab['object_name_to_idx'] = { label:index for index,label,_,_ in room_label[:] }
    vocab['object_to_idx'] = {str(index):index for index,lable,_,_ in room_label}
    vocab['object_idx_to_name'] = [label for index,label,_,_ in room_label]
    vocab['pred_idx_to_name'] = [p for i,p in enumerate(predicates)]
    vocab['pred_name_to_idx'] = {p:i for i,p in enumerate(predicates)}
    vocab['door_idx_to_name'] = [p for i,p in enumerate(door_pos)]
    vocab['door_name_to_idx'] = {p:i for i,p in enumerate(door_pos)}

    return vocab

vocab = get_vocab()



####################################
House
####################################

asgi.py

"""
ASGI config for House project.

It exposes the ASGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/3.0/howto/deployment/asgi/
"""

import os

from django.core.asgi import get_asgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'House.settings')

application = get_asgi_application()


settings.py

"""
Django settings for House project.

Generated by 'django-admin startproject' using Django 3.0.2.

For more information on this file, see
https://docs.djangoproject.com/en/3.0/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/3.0/ref/settings/
"""

import os

# Build paths inside the project like this: os.path.join(BASE_DIR, ...)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))


# Quick-start development settings - unsuitable for production
# See https://docs.djangoproject.com/en/3.0/howto/deployment/checklist/

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = 'y&ol628+upm0r&=8pilr@u_w_0ji!1afp!st*y#ympn3u@!3s%'

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = True

ALLOWED_HOSTS = []


# Application definition

INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
]

MIDDLEWARE = [
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'House.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [os.path.join(BASE_DIR, 'templates')]
        ,
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'House.wsgi.application'


# Database
# https://docs.djangoproject.com/en/3.0/ref/settings/#databases

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.sqlite3',
        'NAME': os.path.join(BASE_DIR, 'db.sqlite3'),
    }
}


# Password validation
# https://docs.djangoproject.com/en/3.0/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]


# Internationalization
# https://docs.djangoproject.com/en/3.0/topics/i18n/

LANGUAGE_CODE = 'en-us'

TIME_ZONE = 'UTC'

USE_I18N = True

USE_L10N = True

USE_TZ = True


# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/3.0/howto/static-files/

STATIC_URL = '/static/'
HERE = os.path.dirname(os.path.abspath(__file__))
HERE = os.path.join(HERE, '../')
STATICFILES_DIRS = (
    os.path.join(HERE, 'static/'),
)
ALLOWED_HOSTS = ['*']


urls.py

"""House URL Configuration

The `urlpatterns` list routes URLs to views. For more information please see:
    https://docs.djangoproject.com/en/3.0/topics/http/urls/
Examples:
Function views
    1. Add an import:  from my_app import views
    2. Add a URL to urlpatterns:  path('', views.home, name='home')
Class-based views
    1. Add an import:  from other_app.views import Home
    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')
Including another URLconf
    1. Import the include() function: from django.urls import include, path
    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))
"""
from django.contrib import admin
from django.urls import path

from Houseweb import views

urlpatterns = [
    # path('admin/', admin.site.urls),
    path('index/LoadTestBoundary', views.LoadTestBoundary),
    path('index/NumSearch/', views.NumSearch),
    path(r'index/LoadTrainHouse/', views.LoadTrainHouse),
    path(r'index/TransGraph/', views.TransGraph),
    path(r'index/TransGraph_net/', views.TransGraph_net),
    path(r'index/Init/', views.Init),
    path(r'index/AdjustGraph/', views.AdjustGraph),
    path(r'index/GraphSearch/', views.GraphSearch),
    path(r'index/RelBox/', views.RelBox),
    path(r'index/Save_Editbox/', views.Save_Editbox),

    path('render/', views.render_mat_file, name='render_mat'),

    path('home', views.home),


]


wsgi.py

"""
WSGI config for House project.

It exposes the WSGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/3.0/howto/deployment/wsgi/
"""

import os

from django.core.wsgi import get_wsgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'House.settings')

application = get_wsgi_application()


###################################
Houseweb
###################################

views.py


from django.shortcuts import render
from django.http import HttpResponse, JsonResponse
import json
import model.test as mltest
import model.utils as mdul
from model.floorplan import *
import retrieval.retrieval as rt
import time
import pickle
import scipy.io as sio
import numpy as np
from model.decorate import *
import math
import pandas as pd
import matlab.engine
import os
import scipy.io as sio
import numpy as np
import matplotlib.pyplot as plt
from django.shortcuts import render
from django.http import HttpResponse, FileResponse
from django.views.decorators.csrf import csrf_exempt
from django.conf import settings
from g2p.plotcopy import plot_fp
import base64
from io import BytesIO

global test_data, test_data_topk, testNameList, trainNameList
global train_data,  trainTF, train_data_eNum, train_data_rNum
global engview, model
global tf_train, centroids, clusters


def home(request):
    return render(request, "home.html", )


def Init(request):
    start = time.perf_counter()
    getTestData()
    getTrainData()
    loadMatlabEng()
    loadModel()
    loadRetrieval()
    end = end = time.perf_counter()

    print('Init(model+test+train+engine+retrieval) time: %s Seconds' % (end - start))

    return HttpResponse(None)


def loadMatlabEng():
    startengview = time.perf_counter()

    global engview
    engview = matlab.engine.start_matlab()
    engview.addpath(r'./align_fp/', nargout=0)
    endengview = time.perf_counter()
    print(' matlab.engineview time: %s Seconds' % (endengview - startengview))


def loadRetrieval():
    global tf_train, centroids, clusters
    t1 = time.perf_counter()
    tf_train = np.load(r'D:\\major project\\Florex\\Interface\\retrieval\\tf_train.npy')
    centroids = np.load(r'D:\\major project\\Florex\\Interface\\retrieval\\centroids_train.npy')
    clusters = np.load(r'D:\\major project\\Florex\\Interface\\retrieval\\clusters_train.npy')
    t2 = time.perf_counter()
    print('load tf/centroids/clusters', t2 - t1)


def getTestData():
    start = time.perf_counter()

    global test_data, testNameList, trainNameList
 
    test_data = pickle.load(open('./static/Data/data_test_converted.pkl', 'rb'))
    test_data, testNameList, trainNameList = test_data['data'], list(test_data['testNameList']), list(
        test_data['trainNameList'])
    end = time.perf_counter()
    print('getTestData time: %s Seconds' % (end - start))


def getTrainData():
    start = time.perf_counter()
    global train_data, trainNameList, trainTF, train_data_eNum, train_data_rNum
    
    train_data = pickle.load(open('./static/Data/data_train_converted.pkl', 'rb'))
    train_data, trainNameList, trainTF = train_data['data'], list(train_data['nameList']), list(train_data['trainTF'])
    
    train_data_eNum = pickle.load(open('./static/Data/data_train_eNum.pkl', 'rb'))
    train_data_eNum = train_data_eNum['eNum']
    train_data_rNum = np.load('./static/Data/rNum_train.npy')
    end = time.perf_counter()
    print('getTrainData time: %s Seconds' % (end - start))


def loadModel():
    global model, train_data, trainNameList
    start = time.perf_counter()
    model = mltest.load_model()
    end = time.perf_counter()
    print('loadModel time: %s Seconds' % (end - start))
    start = time.perf_counter()
    test = train_data[trainNameList.index("75119")]
    mltest.test(model, FloorPlan(test, train=True))
    end = time.perf_counter()
    print('test Model time: %s Seconds' % (end - start))


def LoadTestBoundary(request):
    start = time.perf_counter()

    testName = request.GET.get('testName').split(".")[0]
    test_index = testNameList.index(testName)
    data = test_data[test_index]
    data_js = {}
    data_js["door"] = str(data.boundary[0][0]) + "," + str(data.boundary[0][1]) + "," + str(
        data.boundary[1][0]) + "," + str(data.boundary[1][1])
    ex = ""
    for i in range(len(data.boundary)):
        ex = ex + str(data.boundary[i][0]) + "," + str(data.boundary[i][1]) + " "
    data_js['exterior'] = ex
    end = time.perf_counter()
    print('LoadTestBoundary time: %s Seconds' % (end - start))
    return HttpResponse(json.dumps(data_js), content_type="application/json")


def get_filter_func(mask, acc, num):
    filters = [
        None if not mask else (
            np.equal if acc[i] else np.greater_equal
        )
        for i in range(len(mask))
    ]

    def filter_func(data):
        for i in range(len(filters)):
            if (filters[i] is not None) and (not filters[i](data[i], num[i])): return False
        return True

    return filter_func


def filter_graph(graph_):
    filters = graph_

    def filter_graphfunc(data):
        sub = data - filters
        return ((sub >= 0).all())

    return filter_graphfunc


def NumSearch(request):
    start = time.perf_counter()

    data_new = json.loads(request.GET.get("userInfo"))
    testName = data_new[0].split(".")[0]
    test_index = testNameList.index(testName)
    topkList = []
    topkList.clear()
    data = test_data[test_index]

   
    multi_clusters=False
    test_data_topk = rt.retrieval(data, 1000,multi_clusters)
    
    if len(data_new) > 1:
        roomactarr = data_new[1]
        roomexaarr = data_new[2]
        roomnumarr = [int(x) for x in data_new[3]]
        
        test_num = train_data_rNum[test_data_topk]
        filter_func = get_filter_func(roomactarr, roomexaarr, roomnumarr)
        indices = np.where(list(map(filter_func, test_num)))
        indices = list(indices)
        if len(indices[0]) < 20:
            topk = len(indices[0])
        else:
            topk = 20
        topkList.clear()
        for i in range(topk):
            topkList.append(str(trainNameList[int(test_data_topk[indices[0][i]])]) + ".png")
    end = time.perf_counter()
    print('NumberSearch time: %s Seconds' % (end - start))
    return HttpResponse(json.dumps(topkList), content_type="application/json")


def FindTraindata(trainname):
    start = time.perf_counter()

    train_index = trainNameList.index(trainname)
    data = train_data[train_index]
    data_js = {}
    data_js["hsname"] = trainname

    data_js["door"] = str(data.boundary[0][0]) + "," + str(data.boundary[0][1]) + "," + str(
        data.boundary[1][0]) + "," + str(data.boundary[1][1])
    print("testboundary", data_js["door"])
    ex = ""
    for i in range(len(data.boundary)):
        ex = ex + str(data.boundary[i][0]) + "," + str(data.boundary[i][1]) + " "
    data_js['exterior'] = ex

    data_js["hsedge"] = [[int(u), int(v)] for u, v in data.edge[:, [0, 1]]]

    hsbox = [[[float(x1), float(y1), float(x2), float(y2)], [mdul.room_label[cate][1]]] for
             x1, y1, x2, y2, cate in data.box[:]]
    external = np.asarray(data.boundary)
    xmin, xmax = np.min(external[:, 0]), np.max(external[:, 0])
    ymin, ymax = np.min(external[:, 1]), np.max(external[:, 1])
    
    area_ = (ymax - ymin) * (xmax - xmin)
    
    data_js["rmsize"] = [
        [[20 * math.sqrt((float(x2) - float(x1)) * (float(y2) - float(y1)) / float(area_))], [mdul.room_label[cate][1]]]
        for
        x1, y1, x2, y2, cate in data.box[:]]
   

    box_order = data.order
    data_js["hsbox"] = []
    for i in range(len(box_order)):
        data_js["hsbox"].append(hsbox[int(float(box_order[i])) - 1])

    data_js["rmpos"] = [[int(cate), str(mdul.room_label[cate][1]), float((x1 + x2) / 2), float((y1 + y2) / 2)] for
                        x1, y1, x2, y2, cate in data.box[:]]
    end = time.perf_counter()
    print('find train data time: %s Seconds' % (end - start))
    return data_js


def LoadTrainHouse(request):
    trainname = request.GET.get("roomID").split(".")[0]
    data_js = FindTraindata(trainname)
    return HttpResponse(json.dumps(data_js), content_type="application/json")


'''
 transfer the graph of the training data into the graph of the test data
'''


def TransGraph(request):
    start = time.perf_counter()

    userInfo = request.GET.get("userInfo")
    testname = userInfo.split(',')[0]
    trainname = request.GET.get("roomID")
    mlresult = mltest.get_userinfo(testname, trainname)

    fp_end = mlresult
   
    sio.savemat("./static/" + userInfo.split(',')[0].split('.')[0] + ".mat", {"data": fp_end.data})

    data_js = {}
    # fp_end  hsedge
    data_js["hsedge"] = (fp_end.get_triples(tensor=False)[:, [0, 2, 1]]).astype(float).tolist()

    # fp_rmsize
    external = np.asarray(fp_end.data.boundary)
    xmin, xmax = np.min(external[:, 0]), np.max(external[:, 0])
    ymin, ymax = np.min(external[:, 1]), np.max(external[:, 1])
    area_ = (ymax - ymin) * (xmax - xmin)
    data_js["rmsize"] = [
        [[20 * math.sqrt((float(x2) - float(x1)) * (float(y2) - float(y1)) / float(area_))], [mdul.room_label[cate][1]]]
        for
        x1, y1, x2, y2, cate in fp_end.data.box[:]]
    # fp_end rmpos

    rooms = fp_end.get_rooms(tensor=False)

    
    center = [[(x1 + x2) / 2, (y1 + y2) / 2] for x1, y1, x2, y2 in fp_end.data.box[:, :4]]

    # boxes_pred
    data_js["rmpos"] = []
    for k in range(len(center)):
        node = float(rooms[k]), mdul.room_label[int(rooms[k])][1], center[k][0], center[k][1], float(k)
        data_js["rmpos"].append(node)

    test_index = testNameList.index(testname.split(".")[0])
    data = test_data[test_index]
    ex = ""
    for i in range(len(data.boundary)):
        ex = ex + str(data.boundary[i][0]) + "," + str(data.boundary[i][1]) + " "
    data_js['exterior'] = ex
    data_js["door"] = str(data.boundary[0][0]) + "," + str(data.boundary[0][1]) + "," + str(
        data.boundary[1][0]) + "," + str(data.boundary[1][1])
    end = time.perf_counter()
    print('TransGraph time: %s Seconds' % (end - start))
    return HttpResponse(json.dumps(data_js), content_type="application/json")


def AdjustGraph(request):
    start = time.perf_counter()

    # newNode index-typename-cx-cy
    # oldNode index-typename-cx-cy
    # newEdge u-v
    NewGraph = json.loads(request.GET.get("NewGraph"))
    testname = request.GET.get("userRoomID")
    trainname = request.GET.get("adptRoomID")
    s = time.perf_counter()
    mlresult = mltest.get_userinfo_adjust(testname, trainname, NewGraph)
    e = time.perf_counter()
    print('get_userinfo_adjust: %s Seconds' % (e - s))
    fp_end = mlresult[0]
    global boxes_pred
    boxes_pred = mlresult[1]
    
    data_js = {}
    data_js["hsedge"] = (fp_end.get_triples(tensor=False)[:, [0, 2, 1]]).astype(float).tolist()
  
    rooms = fp_end.get_rooms(tensor=False)
    center = [[(x1 + x2) / 2, (y1 + y2) / 2] for x1, y1, x2, y2 in fp_end.data.box[:, :4]]

    box_order = mlresult[2]
    '''
    handle the information of the room boxes 
    boxes_pred: the prediction from net
    box_order: The order in which boxes are drawn

    '''
    room = []
    for o in range(len(box_order)):
        room.append(float((rooms[int(float(box_order[o][0])) - 1])))
    boxes_end = []
    for i in range(len(box_order)):
        tmp = []
        for j in range(4):
            tmp.append(float(boxes_pred[int(float(box_order[i][0])) - 1][j]))
        boxes_end.append(tmp)
    
    data_js['roomret'] = []
    for k in range(len(room)):
        data = boxes_end[k], [mdul.room_label[int(room[k])][1]], box_order[k][0] - 1
        data_js['roomret'].append(data)
    
    # change the box size
    global relbox
    relbox = data_js['roomret']
    global reledge
    reledge = data_js["hsedge"]

    test_index = testNameList.index(testname.split(".")[0])
    data = test_data[test_index]
    ex = ""
    for i in range(len(data.boundary)):
        ex = ex + str(data.boundary[i][0]) + "," + str(data.boundary[i][1]) + " "
    data_js['exterior'] = ex
    data_js["door"] = str(data.boundary[0][0]) + "," + str(data.boundary[0][1]) + "," + str(
        data.boundary[1][0]) + "," + str(data.boundary[1][1])

    external = np.asarray(data.boundary)
    xmin, xmax = np.min(external[:, 0]), np.max(external[:, 0])
    ymin, ymax = np.min(external[:, 1]), np.max(external[:, 1])
    area_ = (ymax - ymin) * (xmax - xmin)
    data_js['rmsize'] = []
    for i in range(len(data_js['roomret'])):
        rmsize = 20 * math.sqrt((float(data_js['roomret'][i][0][2]) - float(data_js['roomret'][i][0][0])) * (
                float(data_js['roomret'][i][0][3]) - float(data_js['roomret'][i][0][1])) / float(area_)), \
                 data_js["roomret"][i][1][0]
        data_js["rmsize"].append(rmsize)

    data_js["rmpos"] = []

    newGraph = NewGraph[0]
    for i in range(len(data_js['roomret'])):
        for k in range(len(newGraph)):
            if (data_js['roomret'][i][1][0] == newGraph[k][1]):
                x_center = int((data_js['roomret'][i][0][0] + data_js['roomret'][i][0][2]) / 2)
                y_center = int((data_js['roomret'][i][0][1] + data_js['roomret'][i][0][3]) / 2)
                x_graph = newGraph[k][2]
                y_graph = newGraph[k][3]
                if ((int(x_graph - 30) < x_center < int(x_graph + 30))):
                    node = float(rooms[k]), newGraph[k][1], x_center, y_center, float(
                        newGraph[k][0])
                    data_js["rmpos"].append(node)
                    newGraph.pop(k)
                    break
                if ((int(y_graph - 30) < y_center < int(y_graph + 30))):
                    node = float(rooms[k]), newGraph[k][1], x_center, y_center, float(
                        newGraph[k][0])
                    data_js["rmpos"].append(node)
                    newGraph.pop(k)

                    break
    
    fp_end.data = add_dw_fp(fp_end.data)
    data_js["indoor"] = []
    
    boundary = data.boundary
    
    isNew = boundary[:, 3]
    frontDoor = boundary[[0, 1]]  
    frontDoor = frontDoor[:, [0, 1]]  
    frontsum = frontDoor.sum(axis=1).tolist()
    idx = frontsum.index(min(frontsum))
    wallThickness = 3
    if idx == 1:
        frontDoor = frontDoor[[1, 0], :]
    orient = boundary[0][2]
    if orient == 0 or orient == 2:
        frontDoor[0][0] = frontDoor[0][0] + wallThickness / 4
        frontDoor[1][0] = frontDoor[1][0] - wallThickness / 4
    if orient == 1 or orient == 3:
        frontDoor[0][1] = frontDoor[0][1] + wallThickness / 4
        frontDoor[1][1] = frontDoor[1][1] - wallThickness / 4
    

    data_js["windows"] = []
    for indx, x, y, w, h, r in fp_end.data.windows:
        if w != 0:
            tmp = [x + 2, y - 2, w - 2, 4]
            data_js["windows"].append(tmp)
        if h != 0:
            tmp = [x - 2, y, 4, h]
            data_js["windows"].append(tmp)
    data_js["windowsline"] = []
    for indx, x, y, w, h, r in fp_end.data.windows:
        if w != 0:
            tmp = [x + 2, y, w + x, y]
            data_js["windowsline"].append(tmp)
        if h != 0:
            tmp = [x, y, x, h + y]
            data_js["windowsline"].append(tmp)
    
    sio.savemat("./static/" + testname.split(',')[0].split('.')[0] + ".mat", {"data": fp_end.data})

    end = time.perf_counter()
    print('AdjustGraph time: %s Seconds' % (end - start))
    return HttpResponse(json.dumps(data_js), content_type="application/json")


def RelBox(request):
    id = request.GET.get("selectRect")
    print(id)
    global relbox
    global reledge
    rdirgroup=get_dir(id,relbox,reledge)
    return HttpResponse(json.dumps(rdirgroup), content_type="application/json")

def get_dir(id,relbox,reledge):
    rel = []
    selectindex = int(id.split("_")[1])
    select = np.zeros(4).astype(int)
    for i in range(len(relbox)):
        a = math.ceil(relbox[i][0][0]), math.ceil(relbox[i][0][1]), math.ceil(relbox[i][0][2]), math.ceil(
            relbox[i][0][3]), int(relbox[i][2])
        rel.append(a)
        if (selectindex == int(relbox[i][2])):
            # select:x1,x0,y0,y1.relbox:x0,y0,x1,y1
            select[0] = math.ceil(relbox[i][0][2])
            select[1] = math.ceil(relbox[i][0][0])
            select[2] = math.ceil(relbox[i][0][1])
            select[3] = math.ceil(relbox[i][0][3])
    rel = np.array(rel)
    df = pd.DataFrame({'x0': rel[:, 0], 'y0': rel[:, 1], 'x1': rel[:, 2], 'y1': rel[:, 3], 'rindex': rel[:, 4]})
    group_label = [(0, 'x1', "right"),
                   (1, 'x0', "left"),
                   (2, 'y0', "top"),
                   (3, 'y1', "down")]
    dfgroup = []
    for i in range(len(group_label)):
        dfgroup.append(df.groupby(group_label[i][1], as_index=True).get_group(name=select[i]))
    rdirgroup = []
    for i in range(len(dfgroup)):
        dir = dfgroup[i]
        rdir = []
        for k in range(len(dir)):
            idx = (dir.loc[dir['rindex'] == (dir.iloc[[k]].values)[0][4]].index.values)[0]
            rdir.append(relbox[idx][1][0].__str__() + "_" + (dir.iloc[[k]].values)[0][4].__str__())
        rdirgroup.append(rdir)
    reledge = np.array(reledge)
    data1 = reledge[np.where((reledge[:, [0]] == selectindex))[0]]
    data2 = reledge[np.where((reledge[:, [1]] == selectindex))[0]]
    reledge1 = np.vstack((data1, data2))
    return rdirgroup
def Save_Editbox(request):
    global indxlist,boxes_pred
    NewGraph = json.loads(request.GET.get("NewGraph"))
    NewLay = json.loads(request.GET.get("NewLay"))
    userRoomID = request.GET.get("userRoomID")
    adptRoomID = request.GET.get("adptRoomID")
    
    NewLay=np.array(NewLay)
    NewLay=NewLay[np.argsort(NewLay[:, 1])][:,2:]
    NewLay=NewLay.astype(float).tolist()

    test_index = testNameList.index(userRoomID.split(".")[0])
    test_ = test_data[test_index]
    
    Boundary = test_.boundary
    boundary=[[float(x),float(y),float(z),float(k)] for x,y,z,k in list(Boundary)]
    test_fp =FloorPlan(test_)

    train_index = trainNameList.index(adptRoomID.split(".")[0])
    train_ =train_data[train_index]
    train_fp =FloorPlan(train_,train=True)
    fp_end = test_fp.adapt_graph(train_fp)
    fp_end.adjust_graph()
    newNode = NewGraph[0]
    newEdge = NewGraph[1]
    oldNode = NewGraph[2]
    temp = []
    for newindx, newrmname, newx, newy,scalesize in newNode:
        for type, oldrmname, oldx, oldy, oldindx in oldNode:
            if (int(newindx) == oldindx):
                tmp=int(newindx), (newx - oldx), ( newy- oldy),float(scalesize)
                temp.append(tmp)
    newbox=[]
    if mltest.adjust==True:
        oldbox = []
        for i in range(len(boxes_pred)):
            indxtmp=[boxes_pred[i][0],boxes_pred[i][1],boxes_pred[i][2],boxes_pred[i][3],boxes_pred[i][0]]
            oldbox.append(indxtmp)
    if mltest.adjust==False:
        indxlist=[]
        oldbox=fp_end.data.box.tolist()
        for i in range(len(oldbox)):
            indxlist.append([oldbox[i][4]])
        indxlist=np.array(indxlist)
        adjust=True
    oldbox=fp_end.data.box.tolist()
    X=0
    Y=0
    for i in range(len(oldbox)):
        X= X+(oldbox[i][2]-oldbox[i][0])
        Y= Y+(oldbox[i][3]-oldbox[i][1])
    x_ave=(X/len(oldbox))/2
    y_ave=(Y/len(oldbox))/2

    index_mapping = {}
    #  The room that already exists
    #  Move: Just by the distance
    for newindx, tempx, tempy,scalesize in temp:
        index_mapping[newindx] = len(newbox)
        tmpbox=[]
        scalesize = int(scalesize)
        if scalesize<1:
            scale = math.sqrt(scalesize)
            scalex = (oldbox[newindx][2] - oldbox[newindx][0]) * (1 - scale) / 2
            scaley = (oldbox[newindx][3] - oldbox[newindx][1]) * (1 - scale) / 2
            tmpbox = [(oldbox[newindx][0] + tempx) + scalex, (oldbox[newindx][1] + tempy)+scaley,
                      (oldbox[newindx][2] + tempx) - scalex, (oldbox[newindx][3] + tempy) - scaley, oldbox[newindx][4]]
        if scalesize == 1:
            tmpbox = [(oldbox[newindx][0] + tempx) , (oldbox[newindx][1] + tempy) ,(oldbox[newindx][2] + tempx), (oldbox[newindx][3] + tempy), oldbox[newindx][4]]

        if scalesize>1:
            scale=math.sqrt(scalesize)
            scalex = (oldbox[newindx][2] - oldbox[newindx][0]) * ( scale-1) / 2
            scaley = (oldbox[newindx][3] - oldbox[newindx][1]) * (scale-1) / 2
            tmpbox = [(oldbox[newindx][0] + tempx) - scalex, (oldbox[newindx][1] + tempy) - scaley,
                      (oldbox[newindx][2] + tempx) + scalex, (oldbox[newindx][3] + tempy) + scaley, oldbox[newindx][4]]

        newbox.append(tmpbox)

    #  The room just added
    #  Move: The room node with the average size of the existing room
    for newindx, newrmname, newx, newy,scalesize in newNode:
        if int(newindx)>(len(oldbox)-1):
            scalesize=int(scalesize)
            index_mapping[int(newindx)] = (len(newbox))
            tmpbox=[]
            if scalesize < 1:
                scale = math.sqrt(scalesize)
                scalex = x_ave * (1 - scale) / 2
                scaley = y_ave* (1 - scale) / 2
                tmpbox = [(newx-x_ave) +scalex,(newy-y_ave) +scaley,(newx+x_ave)-scalex,(newy+y_ave)-scaley,vocab['object_name_to_idx'][newrmname]]

            if scalesize == 1:
                tmpbox = [(newx - x_ave), (newy - y_ave), (newx + x_ave), (newy + y_ave),vocab['object_name_to_idx'][newrmname]]
            if scalesize > 1:
                scale = math.sqrt(scalesize)
                scalex = x_ave * (scale - 1) / 2
                scaley = y_ave * (scale - 1) / 2
                tmpbox = [(newx-x_ave) - scalex, (newy-y_ave)  - scaley,(newx+x_ave) + scalex, (newy+y_ave) + scaley,vocab['object_name_to_idx'][newrmname]]
            # tmpboxin = [(newx-x_ave) ,(newy-y_ave) ,(newx+x_ave) ,(newy+y_ave) ,vocab['object_name_to_idx'][newrmname]]
            # print(tmpboxin)
            # print(tmpbox)
            # print(scalesize)
            newbox.append(tmpbox)

    fp_end.data.box=np.array(newbox)
    
    adjust_Edge=[]
    for u, v in newEdge:
        tmp=[index_mapping[int(u)],index_mapping[int(v)], 0]
        adjust_Edge.append(tmp)
    fp_end.data.edge=np.array(adjust_Edge)
    rType = fp_end.get_rooms(tensor=False)

    rEdge = fp_end.get_triples(tensor=False)[:, [0, 2, 1]]
    Edge = [[float(u), float(v), float(type2)] for u, v, type2 in rEdge]
    Box=NewLay
    boundary_mat = matlab.double(boundary)
    rType_mat = matlab.double(rType.tolist())
    Edge_mat = matlab.double(Edge)
    Box_mat=matlab.double(Box)
    fp_end.data.boundary =np.array(boundary)
    fp_end.data.rType =np.array(rType).astype(int)
    fp_end.data.refineBox=np.array(Box)
    fp_end.data.rEdge=np.array(Edge)

    box_refine = engview.align_fp(boundary_mat, Box_mat,  rType_mat,Edge_mat ,18,False, nargout=3)
    box_out=box_refine[0]
    box_order=box_refine[1]
    rBoundary=box_refine[2]
    fp_end.data.newBox = np.array(box_out)
    fp_end.data.order = np.array(box_order)
    fp_end.data.rBoundary = [np.array(rb) for rb in rBoundary]
    fp_end.data = add_dw_fp(fp_end.data)
    sio.savemat("./static/" + userRoomID + ".mat", {"data": fp_end.data})
    flag=1
    return HttpResponse(json.dumps(flag), content_type="application/json")


def TransGraph_net(request):
    userInfo = request.GET.get("userInfo")
    testname = userInfo.split(',')[0]
    trainname = request.GET.get("roomID")
    mlresult = mltest.get_userinfo_net(testname, trainname)

    fp_end = mlresult[0]
    boxes_pred = mlresult[1]

    data_js = {}
    # fp_end  hsedge
    data_js["hsedge"] = (fp_end.get_triples(tensor=False)[:, [0, 2, 1]]).astype(float).tolist()

    # fp_end rmpos
    rooms = fp_end.get_rooms(tensor=False)
    room = rooms
    center = [[(x1 + x2) / 2, (y1 + y2) / 2] for x1, y1, x2, y2 in fp_end.data.box[:, :4]]

    

    # boxes_pred
    data_js["rmpos"] = []
    for k in range(len(center)):
        node = float(room[k]), mdul.room_label[int(room[k])][1], center[k][0], center[k][1]
        data_js["rmpos"].append(node)
    boxes_end = boxes_pred.tolist()
    data_js['roomret'] = []
    for k in range(len(room)):
        data = boxes_end[k], [mdul.room_label[int(room[k])][1]]
        data_js['roomret'].append(data)

    test_index = testNameList.index(testname.split(".")[0])
    data = test_data[test_index]
    ex = ""
    for i in range(len(data.boundary)):
        ex = ex + str(data.boundary[i][0]) + "," + str(data.boundary[i][1]) + " "
    data_js['exterior'] = ex
    x0, x1 = np.min(data.boundary[:, 0]), np.max(data.boundary[:, 0])
    y0, y1 = np.min(data.boundary[:, 1]), np.max(data.boundary[:, 1])
    data_js['bbxarea'] = float((x1 - x0) * (y1 - y0))
    return HttpResponse(json.dumps(data_js), content_type="application/json")


def GraphSearch(request):
    s=time.perf_counter()
    # Graph
    Searchtype = ["BedRoom", "Bathroom", "Kitchen", "Balcony", "Storage"]
    BedRoomlist = ["MasterRoom", "SecondRoom", "GuestRoom", "ChildRoom", "StudyRoom"]
    NewGraph = json.loads(request.GET.get("NewGraph"))
   
    testname = request.GET.get("userRoomID")
    newNode = NewGraph[0]
    newEdge = NewGraph[1]
    r_Num = np.zeros((1, 14)).tolist()
    r_Mask = np.zeros((1, 14)).tolist()
    r_Acc = np.zeros((1, 14)).tolist()
    r_Num[0][0] = 1
    r_Mask[0][0] = 1
    r_Acc[0][0] = 1

    for indx, rmname, x, y, scalesize in newNode:
        r_Num[0][mdul.vocab['object_name_to_idx'][rmname]] = r_Num[0][mdul.vocab['object_name_to_idx'][rmname]] + 1
        r_Mask[0][mdul.vocab['object_name_to_idx'][rmname]] = 1
        if rmname in BedRoomlist:
            r_Num[0][13] = r_Num[0][13] + 1
            r_Mask[0][13] = 1

    test_index = testNameList.index(testname.split(".")[0])
    topkList = []
    topkList.clear()
    data = test_data[test_index]
   
    Numrooms = json.loads(request.GET.get("Numrooms"))
    

    roomactarr = Numrooms[0]
    roomexaarr = Numrooms[1]
    roomnumarr = [int(x) for x in Numrooms[2]]
    test_data_topk=np.arange(0,74995)

    if np.sum(roomactarr) != 1 or np.sum(roomexaarr) != 1 or np.sum(roomnumarr) != 1:
        test_num = train_data_rNum[test_data_topk]
        # Number filter
     
        filter_func = get_filter_func(roomactarr, roomexaarr, roomnumarr)
        indices = np.where(list(map(filter_func, test_num)))
        # print("np.where(list(map(fil", test_num)
        indices = list(indices)
        test_data_topk = test_data_topk[indices[0]]

    test_num = train_data_eNum[test_data_topk]
    # Graph filter
    
    edgematrix = np.zeros((5, 5))
    for indx1, indx2 in newEdge:
        tmp1 = ""
        tmp2 = ""
        for indx, rmname, x, y, scalesize in newNode:
            if indx1 == indx:
                if rmname in BedRoomlist:
                    tmp1 = "BedRoom"
                else:
                    tmp1 = rmname
        for indx, rmname, x, y, scalesize in newNode:
            if indx2 == indx:
                if rmname in BedRoomlist:
                    tmp2 = "BedRoom"
                else:
                    tmp2 = rmname
        if tmp1 != "" and tmp2 != "":
            edgematrix[Searchtype.index(tmp1)][Searchtype.index(tmp2)] = edgematrix[Searchtype.index(tmp1)][
                                                                             Searchtype.index(tmp2)] + 1
            edgematrix[Searchtype.index(tmp2)][Searchtype.index(tmp1)] = edgematrix[Searchtype.index(tmp2)][
                                                                             Searchtype.index(tmp1)] + 1
    edge = edgematrix.reshape((1, 25))
    filter_graphfunc = filter_graph(edge)
    # rNum_list
    eNumData = []
   
    indices = np.where(list(map(filter_graphfunc, test_num)))

    indices = list(indices)
    tf_trainsub=tf_train[test_data_topk[indices[0]]]
    re_data = train_data[test_data_topk[indices[0]]]
    test_data_tftopk=retrieve_bf(tf_trainsub, data, k=20)
    re_data=re_data[test_data_tftopk]
    if len(re_data) < 20:
        topk = len(re_data)
    else:
        topk = 20
    topkList = []
    for i in range(topk):
        topkList.append(str(re_data[i].name) + ".png")
        
    e=time.perf_counter()
    print('Graph Search time: %s Seconds' % (e - s))

    print("topkList", topkList)
    return HttpResponse(json.dumps(topkList), content_type="application/json")


def retrieve_bf(tf_trainsub, datum, k=20):
    # compute tf for the data boundary
    x, y = rt.compute_tf(datum.boundary)
    y_sampled = rt.sample_tf(x, y, 1000)
    dist = np.linalg.norm(y_sampled - tf_trainsub, axis=1)
    if k > np.log2(len(tf_trainsub)):
        index = np.argsort(dist)[:k]
    else:
        index = np.argpartition(dist, k)[:k]
        index = index[np.argsort(dist[index])]
    return index
from PIL import Image, ImageDraw
import numpy as np

def render_mat_file(request):
    rendered_image = None
    filename = None
    error = None

    if request.method == 'POST' and request.FILES.get('mat_file'):
        mat_file = request.FILES['mat_file']
        filename = mat_file.name

        # Save uploaded file
        upload_path = os.path.join(settings.BASE_DIR, 'temp_upload.mat')
        with open(upload_path, 'wb+') as f:
            for chunk in mat_file.chunks():
                f.write(chunk)

        try:
            # === YOUR EXACT CODE STARTS HERE ===
            mat_data = sio.loadmat(upload_path, struct_as_record=False, squeeze_me=True)
            data = mat_data['data']  # This is the key! It's 'data' struct

            boundary = np.array(data.boundary)
            newBox = np.array(data.newBox)
            order = np.array(data.order, dtype=int) - 1  # Convert to 0-index
            rType = np.array(data.rType)
            doors = np.array(data.doors)
            windows = np.array(data.windows)

            # Clear any previous plot
            plt.close('all')

            # Use your original plot_fp
            ax = plot_fp(boundary, newBox[order], rType[order], doors, windows)

            # Get the current figure
            fig = plt.gcf()
            fig.set_size_inches(10, 10)  # Nice size

            # Save to BytesIO instead of file
            buf = BytesIO()
            fig.savefig(buf, format='png', dpi=150, bbox_inches='tight', facecolor='#1e1e1e')
            buf.seek(0)

            # Convert to base64
            img_str = base64.b64encode(buf.getvalue()).decode()
            rendered_image = f"data:image/png;base64,{img_str}"

            plt.close(fig)  # Clean up

        except Exception as e:
            error = f"Error: {str(e)}"
            import traceback
            traceback.print_exc()

        finally:
            if os.path.exists(upload_path):
                os.remove(upload_path)

    return render(request, "render_mat.html", {
        'rendered_image': rendered_image,
        'filename': filename,
        'error': error,
    })


if __name__ == "__main__":
    pass



########################################
model
########################################

box_utils.py

#!/usr/bin/python
#
# Copyright 2018 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import torch

"""
Utilities for dealing with bounding boxes
"""


def box_abs2rel(boxes, inside_boxes, obj_to_img):
  inside_boxes = inside_boxes[obj_to_img]
  ix0, iy0, ix1, iy1 = inside_boxes[:, 0], inside_boxes[:, 1], inside_boxes[:, 2], inside_boxes[:, 3]
  xc = (boxes[:, 0] - ix0) / (ix1 - ix0)
  yc = (boxes[:, 1] - iy0) / (iy1 - iy0)
  w = boxes[:, 2] / (ix1 - ix0)
  h = boxes[:, 3] / (iy1 - iy0)
  return torch.stack([xc, yc, w, h], dim=1)


def box_rel2abs(boxes, inside_boxes, obj_to_img):
  inside_boxes = inside_boxes[obj_to_img]
  ix0, iy0, ix1, iy1 = inside_boxes[:, 0], inside_boxes[:, 1], inside_boxes[:, 2], inside_boxes[:, 3]
  xc = boxes[:, 0] * (ix1 - ix0) + ix0
  yc = boxes[:, 1] * (iy1 - iy0) + iy0
  w = boxes[:, 2] * (ix1 - ix0)
  h = boxes[:, 3] * (iy1 - iy0)
  return torch.stack([xc, yc, w, h], dim=1)

def norms_to_indices(boxes,H,W=None):
    if W is None:
        W=H
    x0,x1 = boxes[:,0]*(W-1),boxes[:,2]*(W-1)+1
    y0,y1 = boxes[:,1]*(H-1),boxes[:,3]*(H-1)+1
    return torch.stack([x0, y0, x1, y1], dim=1).round().long()

def apply_box_transform(anchors, transforms):
  """
  Apply box transforms to a set of anchor boxes.

  Inputs:
  - anchors: Anchor boxes of shape (N, 4), where each anchor is specified
    in the form [xc, yc, w, h]
  - transforms: Box transforms of shape (N, 4) where each transform is
    specified as [tx, ty, tw, th]

  Returns:
  - boxes: Transformed boxes of shape (N, 4) where each box is in the
    format [xc, yc, w, h]
  """
  # Unpack anchors
  xa, ya = anchors[:, 0], anchors[:, 1]
  wa, ha = anchors[:, 2], anchors[:, 3]

  # Unpack transforms
  tx, ty = transforms[:, 0], transforms[:, 1]
  tw, th = transforms[:, 2], transforms[:, 3]

  x = xa + tx * wa
  y = ya + ty * ha
  w = wa * tw.exp()
  h = ha * th.exp()

  boxes = torch.stack([x, y, w, h], dim=1)
  return boxes


def invert_box_transform(anchors, boxes):
  """
  Compute the box transform that, when applied to anchors, would give boxes.

  Inputs:
  - anchors: Box anchors of shape (N, 4) in the format [xc, yc, w, h]
  - boxes: Target boxes of shape (N, 4) in the format [xc, yc, w, h]

  Returns:
  - transforms: Box transforms of shape (N, 4) in the format [tx, ty, tw, th]
  """
  # Unpack anchors
  xa, ya = anchors[:, 0], anchors[:, 1]
  wa, ha = anchors[:, 2], anchors[:, 3]
  
  # Unpack boxes
  x, y = boxes[:, 0], boxes[:, 1]
  w, h = boxes[:, 2], boxes[:, 3]

  tx = (x - xa) / wa
  ty = (y - ya) / ha
  tw = w.log() - wa.log()
  th = h.log() - ha.log()

  transforms = torch.stack([tx, ty, tw, th], dim=1)
  return transforms


def centers_to_extents(boxes):
  """
  Convert boxes from [xc, yc, w, h] format to [x0, y0, x1, y1] format

  Input:
  - boxes: Input boxes of shape (N, 4) in [xc, yc, w, h] format

  Returns:
  - boxes: Output boxes of shape (N, 4) in [x0, y0, x1, y1] format
  """
  xc, yc = boxes[:, 0], boxes[:, 1]
  w, h = boxes[:, 2], boxes[:, 3]

  x0 = xc - w / 2
  x1 = x0 + w
  y0 = yc - h / 2
  y1 = y0 + h

  boxes_out = torch.stack([x0, y0, x1, y1], dim=1)
  return boxes_out


def extents_to_centers(boxes):
  """
  Convert boxes from [x0, y0, x1, y1] format to [xc, yc, w, h] format

  Input:
  - boxes: Input boxes of shape (N, 4) in [x0, y0, x1, y1] format

  Returns:
  - boxes: Output boxes of shape (N, 4) in [xc, yc, w, h] format
  """
  x0, y0 = boxes[:, 0], boxes[:, 1]
  x1, y1 = boxes[:, 2], boxes[:, 3]

  xc = 0.5 * (x0 + x1)
  yc = 0.5 * (y0 + y1)
  w = x1 - x0
  h = y1 - y0

  boxes_out = torch.stack([xc, yc, w, h], dim=1)
  return boxes_out

decorate.py

import numpy as np
import copy

room_label = [(0, 'LivingRoom', 1, "PublicArea",[220, 213, 205]),
              (1, 'MasterRoom', 0, "Bedroom",[138, 113, 91]),
              (2, 'Kitchen', 1, "FunctionArea",[244, 245, 247]),
              (3, 'Bathroom', 0, "FunctionArea",[224, 225, 227]),
              (4, 'DiningRoom', 1, "FunctionArea",[200, 193, 185]),
              (5, 'ChildRoom', 0, "Bedroom",[198, 173, 151]),
              (6, 'StudyRoom', 0, "Bedroom",[178, 153, 131]),
              (7, 'SecondRoom', 0, "Bedroom",[158, 133, 111]),
              (8, 'GuestRoom', 0, "Bedroom",[189, 172, 146]),
              (9, 'Balcony', 1, "PublicArea",[244, 237, 224]),
              (10, 'Entrance', 1, "PublicArea",[238, 235, 230]),
              (11, 'Storage', 0, "PublicArea",[226, 220, 206]),
              (12, 'Wall-in', 0, "PublicArea",[226, 220, 206]),
              (13, 'External', 0, "External",[255, 255, 255]),
              (14, 'ExteriorWall', 0, "ExteriorWall",[0, 0, 0]),
              (15, 'FrontDoor', 0, "FrontDoor",[255,255,0]),
              (16, 'InteriorWall', 0, "InteriorWall",[128,128,128]),
              (17, 'InteriorDoor', 0, "InteriorDoor",[255,255,255])]

class DirectedLine():
    def __init__(self,p1,p2):
        '''search direction : 0(horizontal) / 1(vertical)'''
        if np.abs(p1[0]-p2[0])<1e-6:
            self.dir = 1
            self.level = p1[0]
            self.minLevel = min(p1[1],p2[1])
            self.maxLevel = max(p1[1],p2[1])
        else:
            self.dir = 0
            self.level = p1[1]
            self.minLevel = min(p1[0],p2[0])
            self.maxLevel = max(p1[0],p2[0])
    
    def __repr__(self):
        if self.dir==0: return f'({self.level},[{self.minLevel},{self.maxLevel}])'
        else: return f'([{self.minLevel},{self.maxLevel}],{self.level})'
    
    @property
    def length(self):return self.maxLevel-self.minLevel
    
    def is_contact(self,line): 
        minl = min(self.minLevel,line.minLevel)
        maxl = max(self.maxLevel,line.maxLevel)
        length = maxl-minl
        return (
            self.dir==line.dir and 
            #self.level!=line.level and 
            abs(self.level-line.level)<6 and
            length < self.length+line.length
        )
    
    @staticmethod
    def lines_from_boundary(boundary):
        if len(boundary)==0:return []
        pts = boundary.tolist()+[boundary[0].tolist()]
        lines = [ DirectedLine(pts[i],pts[i+1]) for i in range(len(pts)-1)]
        return lines

class DirectedWall():
    def __init__(self):
        '''orientation : 0(right) / 1(down) / 2(left) / 3(up)'''
        self.dir = 0
        self.rect = np.array([0,0,0,0])
    
    @property
    def width(self):return self.rect[2]
    
    @property
    def height(self):return self.rect[3]
    
    @property
    def center(self):return self.rect[:2]+self.rect[2:]/2
    
    def setX(self,x):self.rect[0]=x
    def setY(self,y):self.rect[1]=y
    def setWidth(self,w):self.rect[2]=w
    def setHeight(self,h):self.rect[2]=h
    def setLeft(self,x):
        self.rect[2]=(self.rect[0]-x)+self.rect[2]
        self.rect[0]=x
    def setTop(self,y):
        self.rect[3]=(self.rect[1]-y)+self.rect[3]
        self.rect[1]=y
    
    def to_line(self):
        if self.dir in [0,2]:
            return DirectedLine([self.rect[0],self.rect[1]],[self.rect[0],self.rect[1]+self.rect[3]])
        else:
            return DirectedLine([self.rect[0],self.rect[1]],[self.rect[0]+self.rect[2],self.rect[1]])
    
    def __repr__(self):
        pos = ['right','down','left','up','None'][self.dir]
        return f'({pos},{self.rect})'

class Entry():
    def __init__(self):
        '''door type : 0(door) / 1(open wall)'''
        self.type = -1
        self.entry = None
        
    def __repr__(self):
        if self.type==0: return f'(door,{self.entry})'
        else: return f'(open wall,{self.entry})'   
        
class Room():
    def __init__(self):
        self.box = None
        self.category = None
        self.boundary = None
        
        self.map = None
        self.entry = None
        self.windows = []
    
    @property
    def label(self):return room_label[self.category][1]
    
    @property
    def type(self): return room_label[self.category][3]
    
    @property
    def center(self): return self.box.reshape(-1,2).mean(0)

    @staticmethod
    def rooms_from_data(data):
        rooms = []
        for i in range(len(data.rType)):
            room = Room()
            room.box = data.newBox[i]
            room.category = data.rType[i]
            room.boundary = data.rBoundary[i]
            room.lines = DirectedLine.lines_from_boundary(room.boundary)
            rooms.append(room)
        return rooms

    @staticmethod
    def from_node_box(node,box):
        x0,y0,x1,y1 = box
        room = Room()
        room.box = box
        room.category = node[-1]
        room.boundary = np.array([
                [x0,y0],
                [x0,y1],
                [x1,y1],
                [x1,y0]
            ])
        room.lines = DirectedLine.lines_from_boundary(room.boundary)
        # room.boundary = [
        #     DirectedLine((x0,y0),(x1,y0)), # top
        #     DirectedLine((x1,y0),(x1,y1)), # right
        #     DirectedLine((x0,y1),(x1,y1)), # bottom
        #     DirectedLine((x0,y0),(x0,y1)), # left
        #     ]
        return room
        
    @staticmethod
    def from_boundary(boundary):
        # pts = boundary[:,:2].tolist()
        # pts = pts+[pts[0]]
        room = Room()
        
        room.category = 0
        room.box = np.array([np.min(boundary[:,0]),np.min(boundary[:,1]),np.max(boundary[:,0]),np.max(boundary[:,1])])
        room.boundary = boundary[:,:2]
        room.lines = DirectedLine.lines_from_boundary(room.boundary)
        # room.boundary = [
        #     DirectedLine(pts[i],pts[i+1])
        #     for i in range(len(pts)-1)
        #     ]
        return room
        
    def __repr__(self):
        return f'({self.label},{self.type},{self.box},{self.entry},{self.windows})'
        
def find_contact_walls(room1,room2,reverse=False):
    contactWalls = []
    lines1 = copy.deepcopy(room1.lines) #DirectedLine.from_boundary(room1.boundary)#room1.lines
    center1 = room1.center
    lines2 = copy.deepcopy(room2.lines) #DirectedLine.from_boundary(room2.boundary)# room2.lines
    center2 = room2.center
    temp = []
    
    for i in range(len(lines1)):
        line1 = lines1[i]
        
        for j in range(len(lines2)):
            line2 = lines2[j]
            
            if line1.is_contact(line2):
                contactWall = DirectedWall()
                if line1.dir==0:
                    minh = line1.level if not reverse else line2.level #min(line1.level,line2.level)
                    maxh = line1.level if not reverse else line2.level #max(line1.level,line2.level)
                    minw = max(line1.minLevel,line2.minLevel)
                    maxw = min(line1.maxLevel,line2.maxLevel)
                    # @todo:boudanry not work!
                    if center1[1] > line1.level: contactWall.dir=1
                    else: contactWall.dir=3
                    contactWall.rect = np.array([minw,minh,maxw-minw,maxh-minh])
                else:
                    minw = line1.level if not reverse else line2.level#min(line1.level,line2.level)
                    maxw = line1.level if not reverse else line2.level#max(line1.level,line2.level)
                    minh = max(line1.minLevel,line2.minLevel)
                    maxh = min(line1.maxLevel,line2.maxLevel)
                    if center1[0] > line1.level: contactWall.dir=0
                    else: contactWall.dir=2
                    contactWall.rect = np.array([minw,minh,maxw-minw,maxh-minh])
                contactWalls.append(contactWall)
    return contactWalls

def find_longest_wall(contactWalls,dtype=1):
    contactLength = 0
    openWall = None
    for i in range(len(contactWalls)):
        maxLength = max(contactWalls[i].width,contactWalls[i].height)
        if maxLength>contactLength:
            contactLength = maxLength
            openWall = contactWalls[i]
    if contactLength!=0:
        # @todo: adjust door
        openWall = adjust_door(openWall,dtype)
        entry = Entry()
        entry.type = dtype
        entry.entry = openWall
        assert entry.entry.dir!=-1, "find longest wall with dir -1!"
        return entry
    return None

def find_closest_wall(candidateDoors,frontDoorCenter,dtype=1,boundary_lines=[]):
    dis = 1e8
    door = None
    for i in range(len(candidateDoors)):
        maxLength = max(candidateDoors[i].width,candidateDoors[i].height)
        if maxLength<12:continue

        valid = True
        line = candidateDoors[i].to_line()
        for b_line in boundary_lines:
            if line.is_contact(b_line):
                valid = False
                break
        if not valid: continue

        center = candidateDoors[i].center
        candidateDis = np.sum(np.power((center-frontDoorCenter),2))
        if dis>candidateDis:
            dis = candidateDis
            door = candidateDoors[i]
    if door is not None:
        door = adjust_door(door,dtype)
        entry = Entry()
        entry.type = dtype
        entry.entry = door
        assert entry.entry.dir!=-1, "find closest wall with dir -1!"
        return entry
    return None

def adjust_door(door,dtype=1):
    if door.dir in [1,3]:
        if dtype==1: 
            door.rect[0] = door.rect[0]+door.rect[2]/8
            door.rect[2] = door.rect[2]*3/4
        else:
            # door.rect[0] = door.center[0]-6
            door.rect[2] = min(2*6,door.rect[2])
    else:
        if dtype==1:
            door.rect[1] = door.rect[1]+door.rect[3]/8
            door.rect[3] = door.rect[3]*3/4
        else:
            # door.rect[1] = door.center[1]-6
            door.rect[3] = min(2*6,door.rect[3])
    return door

def add_interior_door(rooms,living_idx,house):
    frontDoorCenter = house.boundary[:2].mean(0)
    for i in range(len(rooms)):
        if i==living_idx:continue
        # 1. Balcony: find the longest door
        # 2. Public Area: find the longest door
        # 3. Others:
        #    3.1 Contact with living room: find the cloest door with the front door
        #    3.2 Others: find the longest wall
        if rooms[i].label == 'Balcony':
            contactWalls = []
            for j in range(len(rooms)):
                if i!=j:
                    contactWalls.extend(find_contact_walls(rooms[i],rooms[j]))
            
            rooms[i].entry = find_longest_wall(contactWalls,dtype=1)
        else:
            contactWalls = find_contact_walls(rooms[i],rooms[living_idx])
            if len(contactWalls)>0:
                if rooms[i].type == 'PublicArea':
                    rooms[i].entry = find_longest_wall(contactWalls,dtype=1)
                else:
                    candidateDoors = [ 
                        wall for wall in contactWalls 
                        if (wall.width>wall.height and wall.width>2*6) or 
                        (wall.height>wall.width and wall.height>2*6)
                    ]
                    if len(candidateDoors)==0:
                        rooms[i].entry = find_longest_wall(contactWalls,dtype=0)
                    else:
                        rooms[i].entry = find_closest_wall(contactWalls,frontDoorCenter,dtype=0,boundary_lines=house.lines)
            else:
                contactWalls = []
                for j in range(len(rooms)):
                    if i!=j:
                        contactWalls.extend(find_contact_walls(rooms[i],rooms[j]))
                if len(contactWalls)>0:
                    rooms[i].entry = find_closest_wall(contactWalls,frontDoorCenter,dtype=1,boundary_lines=house.lines)
            
    return rooms

def find_windows(contactWalls,wtypes=['mid'],keep_longest=False):
    windows = []
    contactLength = 1e8
    for i in range(len(contactWalls)):
        contactWall = contactWalls[i]
        maxLength = max(contactWall.width,contactWall.height)
        if ('large' in wtypes and maxLength>3*12):
            contactWalls[i] = adjust_window(contactWalls[i],'large')
            windows.append(contactWall)
        elif 'mid' in wtypes and maxLength>3*9:
            contactWalls[i] = adjust_window(contactWalls[i],'mid')
            windows.append(contactWall)
        elif 'small' in wtypes and maxLength>2*5:
            contactWalls[i] = adjust_window(contactWalls[i],'small')
            windows.append(contactWall)
        elif 'balcony' in wtypes and maxLength>2*5:
            contactWalls[i] = adjust_window(contactWalls[i],'balcony')
            windows.append(contactWall)
    return windows

def find_window_by_length(contactWalls,wtypes=['mid'],ltype='max'):
    window = None
    contactLength = 0 if ltype=='max' else 1e8
    ufunc = np.greater if ltype=='max' else np.less
    for i in range(len(contactWalls)):
        contactWall = contactWalls[i]
        maxLength = max(contactWall.width,contactWall.height)
        if ufunc(maxLength,contactLength):
            if 'large' in wtypes and maxLength>3*12:
                contactWalls[i] = adjust_window(contactWalls[i],'large')
                window = contactWalls[i]
                contactLength = maxLength
            elif 'mid' in wtypes and maxLength>3*9:
                contactWalls[i] = adjust_window(contactWalls[i],'mid')
                window = contactWalls[i]
                contactLength = maxLength
            elif 'small' in wtypes and maxLength>2*5:
                contactWalls[i] = adjust_window(contactWalls[i],'small')
                window = contactWalls[i]
                contactLength = maxLength
    return [window] if window is not None else []

def adjust_window(window,wtype='mid'):
    hl = {'small':5,'mid':9,'large':12}
    if window.dir in [1,3]:
        if wtype=='balcony':
            window.rect[0] = window.rect[0]+window.rect[2]/10
            window.rect[2] = window.rect[2]*4/5
        else:
            length = hl[wtype]
            window.rect[0] = window.center[0]-length
            window.rect[2] = 2*length
    else:
        if wtype=='balcony':
            window.rect[1] = window.rect[1]+window.rect[3]/10
            window.rect[3] = window.rect[3]*4/5
        else:
            length = hl[wtype]
            window.rect[1] = window.center[1]-length
            window.rect[3] = 2*length
    return window

def add_window(rooms,house):
    for i in range(len(rooms)):
        # 1. Balcony: small(half=5)
        # 2. Living Room: mid(half=9),large(half=12)
        # 3. Bathroom: shortest wall, small
        # 4. Others: longest wall, mid
        contactWalls = find_contact_walls(rooms[i],house,reverse=True)
        if rooms[i].label == 'Balcony':
            rooms[i].windows.extend(find_windows(contactWalls,['balcony']))
        elif rooms[i].label == 'LivingRoom':
            rooms[i].windows.extend(find_windows(contactWalls,['mid','large']))
        elif rooms[i].label == 'Bathroom':
            rooms[i].windows.extend(find_window_by_length(contactWalls,['small'],'min'))
        else:
            rooms[i].windows.extend(find_window_by_length(contactWalls,['mid'],'max'))
    return rooms

def rooms_to_numpy(rooms):
    doors = []
    windows = []
    for i in range(len(rooms)):
        if rooms[i].entry is not None:
            door = rooms[i].entry.entry
            doors.append([i,door.rect[0],door.rect[1],door.rect[2],door.rect[3],door.dir])
        if len(rooms[i].windows) > 0:
            ws = [[i,w.rect[0],w.rect[1],w.rect[2],w.rect[3],w.dir] for w in rooms[i].windows]
            windows.extend(ws)
    return np.array(doors),np.array(windows)

def add_door_window(data):
    boundary = data.boundary
    living_idx = np.where(data.rType==0)[0][0]
    rooms = Room.rooms_from_data(data)
    house = Room.from_boundary(boundary[:,:2])
    house.lines = house.lines[1:]    

    rooms = add_interior_door(rooms,living_idx,house)
    rooms = add_window(rooms,house)
    
    return rooms_to_numpy(rooms)

def add_dw_fp(data):
    # data boundary(matlab),newBox(matlab),rType,rBoundary(matlab)
    doors,windows = add_door_window(data)
    data.doors = doors
    data.windows = windows
    return data


floorplan.py

import torch
import scipy.io as sio
import numpy as np
import cv2
import copy
from model.utils import *


class FloorPlan():

    def __init__(self, data, train=False, rot=None):
        self.data = copy.deepcopy(data)
        self._get_rot()
        if rot is not None:
            if train:
                boxes = self.data.box[:, :4][:, [1, 0, 3, 2]]
                boxes = align_box(boxes, self.rot, rot)[:, [1, 0, 3, 2]]
                self.data.box[:, :4] = boxes
            points = self.data.boundary[:, :2][:, [1, 0]]
            points = align_points(points, self.rot, rot)[:, [1, 0]]
            self.data.boundary[:, :2] = points
            self._get_rot()

    def _get_rot(self):
        door_line = self.data.boundary[:2, :2]  # [:,[1,0]]
        c = door_line.mean(0) - np.array([127.5,127.5])
        theta = np.arctan2(c[1], c[0]) + np.pi  # [-pi,pi]
        self.rot = theta

    def get_input_boundary(self, tensor=True):
        external = self.data.boundary[:, :2]
        door = self.data.boundary[:2, :2]

        boundary = np.zeros((128, 128), dtype=float)
        inside = np.zeros((128, 128), dtype=float)
        front = np.zeros((128, 128), dtype=float)

        pts = np.concatenate([external, external[:1]]) // 2
        pts_door = door // 2

        cv2.fillPoly(inside, pts.reshape(1, -1, 2), 1.0)
        cv2.polylines(boundary, pts.reshape(1, -1, 2), True, 1.0, 3)
        cv2.polylines(boundary, pts_door.reshape(1, -1, 2), True, 0.5, 3)
        cv2.polylines(front, pts_door.reshape(1, -1, 2), True, 1.0, 3)

        input_image = np.stack([inside, boundary, front], -1)
        if tensor: input_image = torch.tensor(input_image).permute((2, 0, 1)).float()
        return input_image

    def get_inside_box(self, tensor=True):
        external = self.data.boundary[:, :2]

        X, Y = np.linspace(0, 1, 256), np.linspace(0, 1, 256)
        x0, x1 = np.min(external[:, 0]), np.max(external[:, 0])
        y0, y1 = np.min(external[:, 1]), np.max(external[:, 1])
        box = np.array([[X[x0], Y[y0], X[x1], Y[y1]]])
        if tensor: box = torch.tensor(box).float()
        return box

    def get_rooms(self, tensor=True):
        rooms = self.data.box[:, -1]
        if tensor: rooms = torch.tensor(rooms).long()
        return rooms

    def get_attributes(self, gsize=5, alevel=10, relative=True, tensor=True):
        boxes = self.data.box[:, :4][:, [1, 0, 3, 2]]
        external = self.data.boundary

        h, w = 256, 256
        if relative:
            external = np.asarray(external)
            x0, x1 = np.min(external[:, 0]), np.max(external[:, 0])
            y0, y1 = np.min(external[:, 1]), np.max(external[:, 1])
            h, w = y1 - y0, x1 - x0
            boxes = boxes - np.array([y0, x0, y0, x0], dtype=float)
        boxes /= np.array([h, w, h, w])
        boxes[:, 2:] -= boxes[:, :2]  # y1,x1->h,w
        boxes[:, :2] += boxes[:, 2:] / 2  # y0,x0->yc,xc
        
        l = len(boxes)
        gbins = np.linspace(0,1,gsize+1) # [1,gsize]
        gbins[0],gbins[-1]=-np.inf,np.inf
        abins = np.linspace(0,1,alevel+1) # [1,gsize]
        abins[0],abins[-1]=-np.inf,np.inf

        attributes = np.zeros((l,gsize*gsize+alevel))
        # pos: xc*gsize+yc*gsize*gsize
        attributes[range(l),(np.digitize(boxes[:,0],gbins)-1)*gsize+np.digitize(boxes[:,1],gbins)-1]=1
        # area:(w*h)
        attributes[range(l),gsize*gsize+np.digitize(boxes[:,2:].prod(1),abins)-1]=1
        if tensor: attributes = torch.tensor(attributes).float()
        return attributes

    def get_triples(self, random=False, tensor=True):
        boxes = self.data.box[:, :4][:, [1, 0, 3, 2]]

        triples = []
        # add edge relation
        for u, v, _ in self.data.edge:
            uy0, ux0, uy1, ux1 = boxes[u]
            vy0, vx0, vy1, vx1 = boxes[v]
            uc = (uy0 + uy1) / 2, (ux0 + ux1) / 2
            vc = (vy0 + vy1) / 2, (vx0 + vx1) / 2

            # surrounding/inside -> X four quadrants
            if ux0 < vx0 and ux1 > vx1 and uy0 < vy0 and uy1 > vy1:
                relation = 'surrounding'
            elif ux0 >= vx0 and ux1 <= vx1 and uy0 >= vy0 and uy1 <= vy1:
                relation = 'inside'
            else:
                relation = point_box_relation(uc, boxes[v])

            triples.append([u, vocab['pred_name_to_idx'][relation], v])

        triples = np.array(triples, dtype=int)
        if tensor: triples = torch.tensor(triples).long()
        return triples

    def vis_box(self):
        h, w = 128, 128
        image = np.full((h, w, 4), 0, dtype=np.uint8)

        boxes = self.data.box[:, :4] // 2
        objs = self.data.box[:, -1]

        for i, obj in enumerate(objs):
            if obj == 14: continue
            color = colormap_255[obj]
            box = boxes[i]
            cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (color[0], color[1], color[2], 255), 3)

        return image

    def get_test_data(self, tensor=True):
        boundary = self.get_input_boundary(tensor=tensor)
        inside_box = self.get_inside_box(tensor=tensor)
        rooms = self.get_rooms(tensor=tensor)
        attrs = self.get_attributes(tensor=tensor)
        triples = self.get_triples(random=False, tensor=tensor)
        return boundary, inside_box, rooms, attrs, triples

    def adapt_graph(self, fp_graph):
        fp = FloorPlan(fp_graph.data, train=True, rot=self.rot)
        g_external = fp.data.boundary[:, :2]
        gx0, gx1 = np.min(g_external[:, 0]), np.max(g_external[:, 0])
        gy0, gy1 = np.min(g_external[:, 1]), np.max(g_external[:, 1])
        gw, gh = gx1 - gx0, gy1 - gy0

        fp.data.boundary = self.data.boundary
        b_external = self.data.boundary[:, :2]
        bx0, bx1 = np.min(b_external[:, 0]), np.max(b_external[:, 0])
        by0, by1 = np.min(b_external[:, 1]), np.max(b_external[:, 1])
        bh, bw = by1 - by0, bx1 - bx0
        box_adapter = lambda box: (((box - np.array([gx0, gy0, gx0, gy0])) * np.array([bw, bh, bw, bh])) / np.array(
            [gw, gh, gw, gh]) + np.array([bx0, by0, bx0, by0])).astype(int)

        fp.data.box[:, :4] = np.apply_along_axis(box_adapter, 1, fp.data.box[:, :4])
        return fp

    def adjust_graph(self):
        external = self.data.boundary[:, :2]
        bx0, bx1 = np.min(external[:, 0]), np.max(external[:, 0])
        by0, by1 = np.min(external[:, 1]), np.max(external[:, 1])
        hw_b = np.array([by1 - by0, bx1 - bx0])
        step = hw_b / 10

        pts = np.concatenate([external, external[:1]])
        mask = np.zeros((256, 256), dtype=np.uint8)
        cv2.fillPoly(mask, pts.reshape(1, -1, 2), 255)
        # plt.imshow(mask)
        # plt.show()
        mask = cv2.resize(mask[by0:by1 + 1, bx0:bx1 + 1], (10, 10))
        # plt.imshow(mask)
        # plt.show()
        mask[mask > 0] = 255

        outside_rooms = []
        for i in range(len(self.data.box)):
            box = self.data.box[i][:4][[1, 0, 3, 2]]
            center = (box[:2] + box[2:]) / 2
            center55 = ((center - np.array([by0, bx0])) * 10 / hw_b).astype(int)

            if not mask[center55[0], center55[1]]:
                outside_rooms.append([i, center55])

        candicate_coords55 = {}
        for i, coords55 in outside_rooms:
            row, col = coords55
            # left/right/up/down
            candicate_coords55[i] = np.array([
                next((col-c for c in range(col,-1,-1) if mask[row,c]==255),255),
                next((c-col for c in range(col+1,5) if mask[row,c]==255),255),
                next((row-r for r in range(row,-1,-1) if mask[r,col]==255),255),
                next((r-row for r in range(row+1,5) if mask[r,col]==255),255)])

        signs = np.array([
            [0, -1, 0, -1],
            [0, 1, 0, 1],
            [-1, 0, -1, 0],
            [1, 0, 1, 0]
        ])

        for i, coords55 in outside_rooms:
            deltas = candicate_coords55[i]
            idx = np.argmin(deltas)
            self.data.box[i, :4] += (signs[idx] * deltas[idx] * np.tile(step, 2)).astype(int)[[1, 0, 3, 2]]


if __name__ == "__main__":
    pass


graph.py

#!/usr/bin/python
#
# Copyright 2018 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import torch
import torch.nn as nn

from model.layers import build_mlp

"""
PyTorch modules for dealing with graphs.
"""


def _init_weights(module):
    if hasattr(module, 'weight'):
        if isinstance(module, nn.Linear):
            nn.init.kaiming_normal_(module.weight)


class GraphTripleConv(nn.Module):
    """
    A single layer of scene graph convolution.
    """

    def __init__(self, input_dim, attributes_dim=0, output_dim=None, hidden_dim=512,
                 pooling='avg', mlp_normalization='none'):
        super(GraphTripleConv, self).__init__()
        if output_dim is None:
            output_dim = input_dim
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.hidden_dim = hidden_dim

        assert pooling in ['sum', 'avg'], 'Invalid pooling "%s"' % pooling
        self.pooling = pooling
        net1_layers = [3 * input_dim + 2 * attributes_dim, hidden_dim, 2 * hidden_dim + output_dim]
        net1_layers = [l for l in net1_layers if l is not None]
        self.net1 = build_mlp(net1_layers, batch_norm=mlp_normalization)
        self.net1.apply(_init_weights)

        net2_layers = [hidden_dim, hidden_dim, output_dim]
        self.net2 = build_mlp(net2_layers, batch_norm=mlp_normalization)
        self.net2.apply(_init_weights)

    def forward(self, obj_vecs, pred_vecs, edges):
        """
        Inputs:
        - obj_vecs: FloatTensor of shape (O, D) giving vectors for all objects
        - pred_vecs: FloatTensor of shape (T, D) giving vectors for all predicates
        - edges: LongTensor of shape (T, 2) where edges[k] = [i, j] indicates the
          presence of a triple [obj_vecs[i], pred_vecs[k], obj_vecs[j]]

        Outputs:
        - new_obj_vecs: FloatTensor of shape (O, D) giving new vectors for objects
        - new_pred_vecs: FloatTensor of shape (T, D) giving new vectors for predicates
        """
        dtype, device = obj_vecs.dtype, obj_vecs.device
        O, T = obj_vecs.size(0), pred_vecs.size(0)
        Din, H, Dout = self.input_dim, self.hidden_dim, self.output_dim

        # Break apart indices for subjects and objects; these have shape (T,)
        s_idx = edges[:, 0].contiguous()
        o_idx = edges[:, 1].contiguous()

        # Get current vectors for subjects and objects; these have shape (T, Din)
        cur_s_vecs = obj_vecs[s_idx]
        cur_o_vecs = obj_vecs[o_idx]

        # Get current vectors for triples; shape is (T, 3 * Din)
        # Pass through net1 to get new triple vecs; shape is (T, 2 * H + Dout)
        cur_t_vecs = torch.cat([cur_s_vecs, pred_vecs, cur_o_vecs], dim=1)
        new_t_vecs = self.net1(cur_t_vecs)

        # Break apart into new s, p, and o vecs; s and o vecs have shape (T, H) and
        # p vecs have shape (T, Dout)
        new_s_vecs = new_t_vecs[:, :H]
        new_p_vecs = new_t_vecs[:, H:(H + Dout)]
        new_o_vecs = new_t_vecs[:, (H + Dout):(2 * H + Dout)]

        # Allocate space for pooled object vectors of shape (O, H)
        pooled_obj_vecs = torch.zeros(O, H, dtype=dtype, device=device)

        # Use scatter_add to sum vectors for objects that appear in multiple triples;
        # we first need to expand the indices to have shape (T, D)
        s_idx_exp = s_idx.view(-1, 1).expand_as(new_s_vecs)
        o_idx_exp = o_idx.view(-1, 1).expand_as(new_o_vecs)
        pooled_obj_vecs = pooled_obj_vecs.scatter_add(0, s_idx_exp, new_s_vecs)
        pooled_obj_vecs = pooled_obj_vecs.scatter_add(0, o_idx_exp, new_o_vecs)

        if self.pooling == 'avg':
            # Figure out how many times each object has appeared, again using
            # some scatter_add trickery.
            obj_counts = torch.zeros(O, dtype=dtype, device=device)
            ones = torch.ones(T, dtype=dtype, device=device)
            obj_counts = obj_counts.scatter_add(0, s_idx, ones)
            obj_counts = obj_counts.scatter_add(0, o_idx, ones)

            # Divide the new object vectors by the number of times they
            # appeared, but first clamp at 1 to avoid dividing by zero;
            # objects that appear in no triples will have output vector 0
            # so this will not affect them.
            obj_counts = obj_counts.clamp(min=1)
            pooled_obj_vecs = pooled_obj_vecs / obj_counts.view(-1, 1)

        # Send pooled object vectors through net2 to get output object vectors,
        # of shape (O, Dout)
        new_obj_vecs = self.net2(pooled_obj_vecs)

        return new_obj_vecs, new_p_vecs


class GraphTripleConvNet(nn.Module):
    """ A sequence of scene graph convolution layers  """

    def __init__(self, input_dim, num_layers=5, hidden_dim=512, pooling='avg',
                 mlp_normalization='none'):
        super(GraphTripleConvNet, self).__init__()

        self.num_layers = num_layers
        self.gconvs = nn.ModuleList()
        gconv_kwargs = {
            'input_dim': input_dim,
            'hidden_dim': hidden_dim,
            'pooling': pooling,
            'mlp_normalization': mlp_normalization,
        }
        for _ in range(self.num_layers):
            self.gconvs.append(GraphTripleConv(**gconv_kwargs))

    def forward(self, obj_vecs, pred_vecs, edges):
        for i in range(self.num_layers):
            gconv = self.gconvs[i]
            obj_vecs, pred_vecs = gconv(obj_vecs, pred_vecs, edges)
        return obj_vecs, pred_vecs


layers.py

#!/usr/bin/python
#
# Copyright 2018 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import functools

import torch
import torch.nn as nn
from torch.nn.functional import interpolate

class PPM(nn.Module):
    def __init__(self, in_dim, reduction_dim, bins, BatchNorm):
        super(PPM, self).__init__()
        self.features = []
        for bin in bins:
            self.features.append(nn.Sequential(
                nn.AdaptiveAvgPool2d(bin),
                nn.Conv2d(in_dim, reduction_dim, kernel_size=1, bias=False),
                BatchNorm(reduction_dim),
                #nn.ReLU(inplace=True)
                nn.LeakyReLU(inplace=True)
            ))
        self.features = nn.ModuleList(self.features)

    def forward(self, x):
        x_size = x.size()
        out = [x]
        for f in self.features:
            out.append(interpolate(f(x), x_size[2:], mode='bilinear', align_corners=True))
        return torch.cat(out, 1)

def get_normalization_2d(channels, normalization):
    if normalization == 'instance':
        return nn.InstanceNorm2d(channels)
    elif normalization == 'batch':
        return nn.BatchNorm2d(channels)
    elif normalization == 'none':
        return None
    else:
        raise ValueError('Unrecognized normalization type "%s"' % normalization)


def get_activation(name):
    kwargs = {}
    if name.lower().startswith('leakyrelu'):
        if '-' in name:
            slope = float(name.split('-')[1])
            kwargs = {'negative_slope': slope}
    name = 'leakyrelu'
    activations = {
        'relu': nn.ReLU,
        'leakyrelu': nn.LeakyReLU,
    }
    if name.lower() not in activations:
        raise ValueError('Invalid activation "%s"' % name)
    return activations[name.lower()](**kwargs)


def _init_conv(layer, method):
    if not isinstance(layer, nn.Conv2d):
        return
    if method == 'default':
        return
    elif method == 'kaiming-normal':
        nn.init.kaiming_normal(layer.weight)
    elif method == 'kaiming-uniform':
        nn.init.kaiming_uniform(layer.weight)


class Flatten(nn.Module):
    def forward(self, x):
        return x.view(x.size(0), -1)

    def __repr__(self):
        return 'Flatten()'


class Unflatten(nn.Module):
    def __init__(self, size):
        super(Unflatten, self).__init__()
        self.size = size

    def forward(self, x):
        return x.view(*self.size)

    def __repr__(self):
        size_str = ', '.join('%d' % d for d in self.size)
        return 'Unflatten(%s)' % size_str


class GlobalAvgPool(nn.Module):
    def forward(self, x):
        N, C = x.size(0), x.size(1)
        return x.view(N, C, -1).mean(dim=2)


class ResidualBlock(nn.Module):
    def __init__(self, channels, normalization='batch', activation='relu',
                 padding='same', kernel_size=3, init='default'):
        super(ResidualBlock, self).__init__()

        K = kernel_size
        P = _get_padding(K, padding)
        C = channels
        self.padding = P
        layers = [
            get_normalization_2d(C, normalization),
            get_activation(activation),
            nn.Conv2d(C, C, kernel_size=K, padding=P),
            get_normalization_2d(C, normalization),
            get_activation(activation),
            nn.Conv2d(C, C, kernel_size=K, padding=P),
        ]
        layers = [layer for layer in layers if layer is not None]
        for layer in layers:
            _init_conv(layer, method=init)
        self.net = nn.Sequential(*layers)

    def forward(self, x):
        P = self.padding
        shortcut = x
        if P == 0:
            shortcut = x[:, :, P:-P, P:-P]
        y = self.net(x)
        return shortcut + self.net(x)


def _get_padding(K, mode):
    """ Helper method to compute padding size """
    if mode == 'valid':
        return 0
    elif mode == 'same':
        assert K % 2 == 1, 'Invalid kernel size %d for "same" padding' % K
        return (K - 1) // 2


def build_cnn(arch, normalization='batch', activation='leakyrelu', padding='same',
              pooling='max', init='default'):
    """
    Build a CNN from an architecture string, which is a list of layer
    specification strings. The overall architecture can be given as a list or as
    a comma-separated string.

    All convolutions *except for the first* are preceeded by normalization and
    nonlinearity.

    All other layers support the following:
    - IX: Indicates that the number of input channels to the network is X.
          Can only be used at the first layer; if not present then we assume
          3 input channels.
    - CK-X: KxK convolution with X output channels
    - CK-X-S: KxK convolution with X output channels and stride S
    - R: Residual block keeping the same number of channels
    - UX: Nearest-neighbor upsampling with factor X
    - PX: Spatial pooling with factor X
    - FC-X-Y: Flatten followed by fully-connected layer

    Returns a tuple of:
    - cnn: An nn.Sequential
    - channels: Number of output channels
    """
    if isinstance(arch, str):
        arch = arch.split(',')
    cur_C = 3
    if len(arch) > 0 and arch[0][0] == 'I':
        cur_C = int(arch[0][1:])
        arch = arch[1:]

    first_conv = True
    flat = False
    layers = []
    for i, s in enumerate(arch):
        if s[0] == 'C':
            if not first_conv:
                layers.append(get_normalization_2d(cur_C, normalization))
                layers.append(get_activation(activation))
            first_conv = False
            vals = [int(i) for i in s[1:].split('-')]
            if len(vals) == 2:
                K, next_C = vals
                stride = 1
            elif len(vals) == 3:
                K, next_C, stride = vals
            # K, next_C = (int(i) for i in s[1:].split('-'))
            P = _get_padding(K, padding)
            conv = nn.Conv2d(cur_C, next_C, kernel_size=K, padding=P, stride=stride)
            layers.append(conv)
            _init_conv(layers[-1], init)
            cur_C = next_C
        elif s[0] == 'R':
            norm = 'none' if first_conv else normalization
            res = ResidualBlock(cur_C, normalization=norm, activation=activation,
                                padding=padding, init=init)
            layers.append(res)
            first_conv = False
        elif s[0] == 'U':
            factor = int(s[1:])
            layers.append(Interpolate(scale_factor=factor, mode='nearest'))
        elif s[0] == 'P':
            factor = int(s[1:])
            if pooling == 'max':
                pool = nn.MaxPool2d(kernel_size=factor, stride=factor)
            elif pooling == 'avg':
                pool = nn.AvgPool2d(kernel_size=factor, stride=factor)
            layers.append(pool)
        elif s[:2] == 'FC':
            _, Din, Dout = s.split('-')
            Din, Dout = int(Din), int(Dout)
            if not flat:
                layers.append(Flatten())
            flat = True
            layers.append(nn.Linear(Din, Dout))
            if i + 1 < len(arch):
                layers.append(get_activation(activation))
            cur_C = Dout
        else:
            raise ValueError('Invalid layer "%s"' % s)
    layers = [layer for layer in layers if layer is not None]
    # for layer in layers:
    #   print(layer)
    return nn.Sequential(*layers), cur_C


def build_mlp(dim_list, activation='leakyrelu', batch_norm='none',
              dropout=0, final_nonlinearity=True):
    layers = []
    for i in range(len(dim_list) - 1):
        dim_in, dim_out = dim_list[i], dim_list[i + 1]
        layers.append(nn.Linear(dim_in, dim_out))
        final_layer = (i == len(dim_list) - 2)
        if not final_layer or final_nonlinearity:
            if batch_norm == 'batch':
                layers.append(nn.BatchNorm1d(dim_out))
            if activation == 'relu':
                layers.append(nn.ReLU())
            elif activation == 'leakyrelu':
                layers.append(nn.LeakyReLU())
        if dropout > 0:
            layers.append(nn.Dropout(p=dropout))
    return nn.Sequential(*layers)


class ResnetBlock(nn.Module):
    def __init__(self, dim, padding_type, norm_layer, activation=nn.ReLU(True), use_dropout=False):
        super(ResnetBlock, self).__init__()
        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, activation, use_dropout)

    def build_conv_block(self, dim, padding_type, norm_layer, activation, use_dropout):
        conv_block = []
        p = 0
        if padding_type == 'reflect':
            conv_block += [nn.ReflectionPad2d(1)]
        elif padding_type == 'replicate':
            conv_block += [nn.ReplicationPad2d(1)]
        elif padding_type == 'zero':
            p = 1
        else:
            raise NotImplementedError('padding [%s] is not implemented' % padding_type)

        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p),
                       norm_layer(dim),
                       activation]
        if use_dropout:
            conv_block += [nn.Dropout(0.5)]

        p = 0
        if padding_type == 'reflect':
            conv_block += [nn.ReflectionPad2d(1)]
        elif padding_type == 'replicate':
            conv_block += [nn.ReplicationPad2d(1)]
        elif padding_type == 'zero':
            p = 1
        else:
            raise NotImplementedError('padding [%s] is not implemented' % padding_type)
        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p),
                       norm_layer(dim)]

        return nn.Sequential(*conv_block)

    def forward(self, x):
        out = x + self.conv_block(x)
        return out


class ConditionalBatchNorm2d(nn.Module):
    def __init__(self, num_features, num_classes):
        super(ConditionalBatchNorm2d).__init__()
        self.num_features = num_features
        self.bn = nn.BatchNorm2d(num_features, affine=False)
        self.embed = nn.Embedding(num_classes, num_features * 2)
        self.embed.weight.data[:, :num_features].normal_(1, 0.02)  # Initialise scale at N(1, 0.02)
        self.embed.weight.data[:, num_features:].zero_()  # Initialise bias at 0

    def forward(self, x, y):
        out = self.bn(x)
        gamma, beta = self.embed(y).chunk(2, 1)
        out = gamma.view(-1, self.num_features, 1, 1) * out + beta.view(-1, self.num_features, 1, 1)
        return out


def get_norm_layer(norm_type='instance'):
    if norm_type == 'batch':
        norm_layer = functools.partial(nn.BatchNorm2d, affine=True)
    elif norm_type == 'instance':
        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False)
    elif norm_type == 'conditional':
        norm_layer = functools.partial(ConditionalBatchNorm2d)
    else:
        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)
    return norm_layer


class Interpolate(nn.Module):
    def __init__(self, size=None, scale_factor=None, mode='nearest', align_corners=None):
        super(Interpolate, self).__init__()
        self.size = size
        self.scale_factor = scale_factor
        self.mode = mode
        self.align_corners = align_corners

    def forward(self, x):
        return interpolate(x, size=self.size, scale_factor=self.scale_factor, mode=self.mode,
                           align_corners=self.align_corners)


layout.py

#!/usr/bin/python
#
# Copyright 2018 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import torch
import torch.nn as nn
import torch.nn.functional as F

import  model.box_utils as box_utils


"""
Functions for computing image layouts from object vectors, bounding boxes,
and segmentation masks. These are used to compute course scene layouts which
are then fed as input to the cascaded refinement network.
"""


def boxes_to_layout(vecs, boxes, obj_to_img, H, W=None, pooling='sum'):
  """
  Inputs:
  - vecs: Tensor of shape (O, D) giving vectors
  - boxes: Tensor of shape (O, 4) giving bounding boxes in the format
    [x0, y0, x1, y1] in the [0, 1] coordinate space
  - obj_to_img: LongTensor of shape (O,) mapping each element of vecs to
    an image, where each element is in the range [0, N). If obj_to_img[i] = j
    then vecs[i] belongs to image j.
  - H, W: Size of the output

  Returns:
  - out: Tensor of shape (N, D, H, W)
  """
  O, D = vecs.size()
  if W is None:
    W = H

  grid = _boxes_to_grid(boxes, H, W)

  # If we don't add extra spatial dimensions here then out-of-bounds
  # elements won't be automatically set to 0
  img_in = vecs.view(O, D, 1, 1).expand(O, D, 8, 8)
  sampled = F.grid_sample(img_in, grid)   # (O, D, H, W)

  # Explicitly masking makes everything quite a bit slower.
  # If we rely on implicit masking the interpolated boxes end up
  # blurred around the edges, but it should be fine.
  # mask = ((X < 0) + (X > 1) + (Y < 0) + (Y > 1)).clamp(max=1)
  # sampled[mask[:, None]] = 0

  out = _pool_samples(sampled, obj_to_img, pooling=pooling)

  return out


def masks_to_layout(vecs, boxes, masks, obj_to_img, H, W=None, pooling='sum'):
  """
  Inputs:
  - vecs: Tensor of shape (O, D) giving vectors
  - boxes: Tensor of shape (O, 4) giving bounding boxes in the format
    [x0, y0, x1, y1] in the [0, 1] coordinate space
  - masks: Tensor of shape (O, M, M) giving binary masks for each object
  - obj_to_img: LongTensor of shape (O,) mapping objects to images
  - H, W: Size of the output image.

  Returns:
  - out: Tensor of shape (N, D, H, W)
  """
  O, D = vecs.size()
  M = masks.size(1)
  assert masks.size() == (O, M, M)
  if W is None:
    W = H
  grid = _boxes_to_grid(boxes, H, W)
  img_in = vecs.view(O, D, 1, 1) * masks.float().view(O, 1, M, M)
  sampled = F.grid_sample(img_in, grid)
  out = _pool_samples(sampled, obj_to_img, pooling=pooling)
  return out


def _boxes_to_grid(boxes, H, W):
  """
  Input:
  - boxes: FloatTensor of shape (O, 4) giving boxes in the [x0, y0, x1, y1]
    format in the [0, 1] coordinate space
  - H, W: Scalars giving size of output

  Returns:
  - grid: FloatTensor of shape (O, H, W, 2) suitable for passing to grid_sample
  """
  O = boxes.size(0)
  boxes = box_utils.centers_to_extents(boxes)
  boxes = boxes.view(O, 4, 1, 1)

  # w,h = boxes[:, 2], boxes[:, 3]
  # # All these are (O, 1, 1)
  # x0, y0 = boxes[:, 0]-w/2, boxes[:, 1]-h/2
  # x1, y1 = boxes[:, 0]+w/2, boxes[:, 1]+h/2

  x0, y0 = boxes[:, 0], boxes[:, 1]
  ww, hh = boxes[:, 2] - x0, boxes[:, 3] - y0
  # ww = x1 - x0
  # hh = y1 - y0

  X = torch.linspace(0, 1, steps=W).view(1, 1, W).to(boxes)
  Y = torch.linspace(0, 1, steps=H).view(1, H, 1).to(boxes)
  X = (X - x0) / ww # (O, 1, W)
  Y = (Y - y0) / hh  # (O, H, 1)
  
  # Stack does not broadcast its arguments so we need to expand explicitly
  X = X.expand(O, H, W)
  Y = Y.expand(O, H, W)
  grid = torch.stack([X, Y], dim=3)  # (O, H, W, 2)

  # Right now grid is in [0, 1] space; transform to [-1, 1]
  grid = grid.mul(2).sub(1)

  return grid


def _pool_samples(samples, obj_to_img, pooling='sum'):
  """
  Input:
  - samples: FloatTensor of shape (O, D, H, W)
  - obj_to_img: LongTensor of shape (O,) with each element in the range
    [0, N) mapping elements of samples to output images

  Output:
  - pooled: FloatTensor of shape (N, D, H, W)
  """
  dtype, device = samples.dtype, samples.device
  O, D, H, W = samples.size()
  N = obj_to_img.data.max().item() + 1
  
  # Use scatter_add to sum the sampled outputs for each image
  out = torch.zeros(N, D, H, W, dtype=dtype, device=device)
  idx = obj_to_img.view(O, 1, 1, 1).expand(O, D, H, W)
  #out = out.scatter_add(0, idx, samples)

  if pooling == 'avg':
    # Divide each output mask by the number of objects; use scatter_add again
    # to count the number of objects per image.
    out = out.scatter_add(0, idx, samples)
    ones = torch.ones(O, dtype=dtype, device=device)
    obj_counts = torch.zeros(N, dtype=dtype, device=device)
    obj_counts = obj_counts.scatter_add(0, obj_to_img, ones)
    obj_counts = obj_counts.clamp(min=1)
    out = out / obj_counts.view(N, 1, 1, 1)
  elif pooling == 'max':
    all_out = []
    obj_to_img_list = [i.item() for i in list(obj_to_img)]
    for i in range(N):
        start = obj_to_img_list.index(i)
        end = len(obj_to_img_list) - obj_to_img_list[::-1].index(i)
        all_out.append(torch.max(samples[start:end, :, :, :], dim=0)[0])
    out = torch.stack(all_out)
  elif pooling == 'sum':
    out = out.scatter_add(0, idx, samples)
    #raise ValueError('Invalid pooling "%s"' % pooling)

  return out

def masks_to_seg(boxes, masks, objs, obj_to_img, H, W=None, num_classes=15):
  """
  Inputs:
  - vecs: Tensor of shape (O, D) giving vectors
  - boxes: Tensor of shape (O, 4) giving bounding boxes in the format
    [x0, y0, x1, y1] in the [0, 1] coordinate space
  - obj_to_img: LongTensor of shape (O,) mapping each element of vecs to
    an image, where each element is in the range [0, N). If obj_to_img[i] = j
    then vecs[i] belongs to image j.
  - H, W: Size of the output

  Returns:
  - out: Tensor of shape (N, D, H, W)
  """
  dtype, device = boxes.dtype, boxes.device
  O, D = boxes.size()
  M = masks.size(1)
  assert masks.size() == (O, M, M)
  if W is None:
    W = H
  N = obj_to_img.data.max().item() + 1
  grid = _boxes_to_grid(boxes, H, W)
  mask_sampled = F.grid_sample(masks.float().view(O, 1, M, M), grid)
  seg = torch.zeros((N,num_classes,H,W)).to(device)
  # obj_to_img_list = [i.item() for i in list(obj_to_img)]
  for i in range(N):
    obj_to_i = (obj_to_img==i).nonzero().view(-1)
    # start = obj_to_img_list.index(i)
    # end = len(obj_to_img_list) - obj_to_img_list[::-1].index(i)
    # for j in range(start,end):
    for j in obj_to_i:
      obj = objs[j]
      seg[i,obj]=seg[i,obj]+mask_sampled[j]
  return seg

def boxes_to_seg(boxes, objs, obj_to_img, H, W=None,num_classes=15):
  """
  Inputs:
  - vecs: Tensor of shape (O, D) giving vectors
  - boxes: Tensor of shape (O, 4) giving bounding boxes in the format
    [x0, y0, x1, y1] in the [0, 1] coordinate space
  - obj_to_img: LongTensor of shape (O,) mapping each element of vecs to
    an image, where each element is in the range [0, N). If obj_to_img[i] = j
    then vecs[i] belongs to image j.
  - H, W: Size of the output

  Returns:
  - out: Tensor of shape (N, D, H, W)
  """
  dtype, device = boxes.dtype, boxes.device
  O, D = boxes.size()
  if W is None:
    W = H
  N = obj_to_img.data.max().item() + 1

  grid = _boxes_to_grid(boxes, H, W)
  mask_sampled = F.grid_sample(torch.ones(O,1,8,8).to(boxes), grid)
  
  seg = torch.zeros((N,num_classes,H,W)).to(device)
  obj_to_img_list = [i.item() for i in list(obj_to_img)]
  for i in range(N):
    start = obj_to_img_list.index(i)
    end = len(obj_to_img_list) - obj_to_img_list[::-1].index(i)
    for j in range(start,end):
    #obj_to_i = (obj_to_img==i).nonzero().view(-1)
    #for j in obj_to_i:
      obj = objs[j]
      seg[i,obj]=seg[i,obj]+mask_sampled[j]
  return seg

if __name__ == '__main__':
  vecs = torch.FloatTensor([
            [1, 0, 0], [0, 1, 0], [0, 0, 1],
            [1, 0, 0], [0, 1, 0], [0, 0, 1],
         ])
  boxes = torch.FloatTensor([
            [0.25, 0.125, 0.5, 0.875],
            [0, 0, 1, 0.25],
            [0.6125, 0, 0.875, 1],
            [0, 0.8, 1, 1.0],
            [0.25, 0.125, 0.5, 0.875],
            [0.6125, 0, 0.875, 1],
          ])
  obj_to_img = torch.LongTensor([0, 0, 0, 1, 1, 1])
  # vecs = torch.FloatTensor([[[1]]])
  # boxes = torch.FloatTensor([[[0.25, 0.25, 0.75, 0.75]]])
  vecs, boxes = vecs.cuda(), boxes.cuda()
  obj_to_img = obj_to_img.cuda()
  out = boxes_to_layout(vecs, boxes, obj_to_img, 256, pooling='sum')
  
  from torchvision.utils import save_image
  save_image(out.data, 'out.png')


  masks = torch.FloatTensor([
            [
              [0, 0, 1, 0, 0],
              [0, 1, 1, 1, 0],
              [1, 1, 1, 1, 1],
              [0, 1, 1, 1, 0],
              [0, 0, 1, 0, 0],
            ],
            [
              [0, 0, 1, 0, 0],
              [0, 1, 0, 1, 0],
              [1, 0, 0, 0, 1],
              [0, 1, 0, 1, 0],
              [0, 0, 1, 0, 0],
            ],
            [
              [0, 0, 1, 0, 0],
              [0, 1, 1, 1, 0],
              [1, 1, 1, 1, 1],
              [0, 1, 1, 1, 0],
              [0, 0, 1, 0, 0],
            ],
            [
              [0, 0, 1, 0, 0],
              [0, 1, 1, 1, 0],
              [1, 1, 1, 1, 1],
              [0, 1, 1, 1, 0],
              [0, 0, 1, 0, 0],
            ],
            [
              [0, 0, 1, 0, 0],
              [0, 1, 1, 1, 0],
              [1, 1, 1, 1, 1],
              [0, 1, 1, 1, 0],
              [0, 0, 1, 0, 0],
            ],
            [
              [0, 0, 1, 0, 0],
              [0, 1, 1, 1, 0],
              [1, 1, 1, 1, 1],
              [0, 1, 1, 1, 0],
              [0, 0, 1, 0, 0],
            ]
          ])
  masks = masks.cuda()
  out = masks_to_layout(vecs, boxes, masks, obj_to_img, 256)
  save_image(out.data, 'out_masks.png')


model.py

#!/usr/bin/python
#
# Copyright 2018 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licens8.0es/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import math
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision.ops import RoIAlign

import model.box_utils as box_utils
from model.graph import GraphTripleConv, GraphTripleConvNet
from model.layout import boxes_to_layout, masks_to_layout, boxes_to_seg, masks_to_seg
from model.layers import build_mlp,build_cnn
from model.utils import vocab

class Model(nn.Module):
  def __init__(self,
              embedding_dim=128,
              image_size=(128,128),
              input_dim=3,
              attribute_dim=35,
              # graph_net
              gconv_dim=128,
              gconv_hidden_dim=512,
              gconv_num_layers=5,
              # inside_cnn
              inside_cnn_arch="C3-32-2,C3-64-2,C3-128-2,C3-256-2",
              # refinement_net
              refinement_dims=(1024, 512, 256, 128, 64),
              # box_refine
              box_refine_arch = "I15,C3-64-2,C3-128-2,C3-256-2",
              roi_output_size = (8,8),
              roi_spatial_scale = 1.0/8.0,
              roi_cat_feature = True,
              # others
              mlp_activation='leakyrelu',
              mlp_normalization='none',
              cnn_activation='leakyrelu',
              cnn_normalization='batch'
              ):
    super(Model, self).__init__()
    ''' embedding '''
    self.vocab = vocab
    num_objs = len(vocab['object_idx_to_name'])
    num_preds = len(vocab['pred_idx_to_name'])
    num_doors = len(vocab['door_idx_to_name'])
    self.obj_embeddings = nn.Embedding(num_objs, embedding_dim)
    self.pred_embeddings = nn.Embedding(num_preds, embedding_dim)
    self.image_size = image_size
    self.feature_dim = embedding_dim+attribute_dim

    ''' graph_net '''
    self.gconv = GraphTripleConv(
      embedding_dim,
      attributes_dim=attribute_dim, 
      output_dim=gconv_dim,
      hidden_dim=gconv_hidden_dim,
      mlp_normalization=mlp_normalization
    )
    self.gconv_net = GraphTripleConvNet(
      gconv_dim,
      num_layers=gconv_num_layers-1,
      mlp_normalization=mlp_normalization
    )
  
    ''' inside_cnn '''
    inside_cnn,inside_feat_dim = build_cnn(
        f'I{input_dim},{inside_cnn_arch}',
        padding='valid'
    )
    self.inside_cnn = nn.Sequential(
      inside_cnn,
      nn.AdaptiveAvgPool2d(1)
    )
    inside_output_dim = inside_feat_dim
    obj_vecs_dim = gconv_dim+inside_output_dim

    ''' box_net '''
    box_net_dim = 4
    box_net_layers = [obj_vecs_dim, gconv_hidden_dim, box_net_dim]
    self.box_net = build_mlp(
      box_net_layers,
      activation=mlp_activation, 
      batch_norm=mlp_normalization
    )
    
    ''' relationship_net '''
    rel_aux_layers = [obj_vecs_dim, gconv_hidden_dim, num_doors]
    self.rel_aux_net = build_mlp(
      rel_aux_layers,
      activation=mlp_activation, 
      batch_norm=mlp_normalization
    )

    ''' refinement_net '''
    if refinement_dims!=None:
      self.refinement_net,_ = build_cnn(f"I{obj_vecs_dim},C3-128,C3-64,C3-{num_objs}")
    else:
      self.refinement_net = None

    ''' roi '''
    self.box_refine_backbone = None
    self.roi_cat_feature = roi_cat_feature
    if box_refine_arch!=None:
      box_refine_cnn,box_feat_dim = build_cnn(
        box_refine_arch,
        padding='valid'
      )
      self.box_refine_backbone = box_refine_cnn
      self.roi_align = RoIAlign(roi_output_size,roi_spatial_scale,-1) #(256,8,8)
      self.down_sample = nn.AdaptiveAvgPool2d(1)
      box_refine_layers = [obj_vecs_dim+256 if self.roi_cat_feature else 256, 512, 4]
      self.box_reg =build_mlp(
          box_refine_layers,
          activation=mlp_activation, 
          batch_norm=mlp_normalization
      )

  def forward(
    self, 
    objs, 
    triples, 
    boundary,
    obj_to_img=None,
    attributes=None,
    boxes_gt=None, 
    generate=False,
    refine=False,
    relative=False,
    inside_box=None
    ):
    """
    Required Inputs:
    - objs: LongTensor of shape (O,) giving categories for all objects
    - triples: LongTensor of shape (T, 3) where triples[t] = [s, p, o]
      means that there is a triple (objs[s], p, objs[o])

    Optional Inputs:
    - obj_to_img: LongTensor of shape (O,) where obj_to_img[o] = i
      means that objects[o] is an object in image i. If not given then
      all objects are assumed to belong to the same image.
    - boxes_gt: FloatTensor of shape (O, 4) giving boxes to use for computing
      the spatial layout; if not given then use predicted boxes.
    """
    # input size
    O, T = objs.size(0), triples.size(0)
    s, p, o = triples.chunk(3, dim=1)           # All have shape (T, 1)
    s, p, o = [x.squeeze(1) for x in [s, p, o]] # Now have shape (T,)
    edges = torch.stack([s, o], dim=1)          # Shape is (T, 2)
    B = boundary.size(0)
    H, W = self.image_size
  
    if obj_to_img is None:
      obj_to_img = torch.zeros(O, dtype=objs.dtype, device=objs.device)
    
    ''' embedding '''
    obj_vecs = self.obj_embeddings(objs)
    pred_vecs = self.pred_embeddings(p)

    ''' attribute '''
    if attributes is not None:
      obj_vecs = torch.cat([obj_vecs,attributes],1)
    obj_vecs_orig = obj_vecs
    
    ''' gconv '''
    obj_vecs, pred_vecs = self.gconv(obj_vecs, pred_vecs, edges)
    obj_vecs, pred_vecs = self.gconv_net(obj_vecs, pred_vecs, edges)

    ''' inside '''
    inside_vecs = self.inside_cnn(boundary).view(B,-1)
    obj_vecs = torch.cat([obj_vecs,inside_vecs[obj_to_img]],dim=1)

    ''' box '''
    boxes_pred = self.box_net(obj_vecs)
    if relative: boxes_pred = box_utils.box_rel2abs(boxes_pred,inside_box,obj_to_img)

    ''' relation '''
    # unused, for door position predition
    # rel_scores = self.rel_aux_net(obj_vecs)

    ''' generate '''
    gene_layout = None
    boxes_refine = None
    layout_boxes = boxes_pred if boxes_gt is None else boxes_gt
    if generate:
      layout_features = boxes_to_layout(obj_vecs,layout_boxes,obj_to_img,H,W)
      gene_layout = self.refinement_net(layout_features)
      
    ''' box refine '''
    if refine:
      gene_feat = self.box_refine_backbone(gene_layout)
      rois = torch.cat([
        obj_to_img.float().view(-1,1),
        box_utils.centers_to_extents(layout_boxes)*H
      ],-1)
      roi_feat = self.down_sample(self.roi_align(gene_feat,rois)).flatten(1)
      roi_feat = torch.cat([
        roi_feat,
        obj_vecs
      ],-1)
      boxes_refine = self.box_reg(roi_feat)
      if relative: boxes_refine = box_utils.box_rel2abs(boxes_refine,inside_box,obj_to_img)

    return boxes_pred, gene_layout, boxes_refine


test.py

from  model.floorplan import *
from  model.box_utils import *
from  model.model import Model
import os
from  model.utils import *

import Houseweb.views as vw

import numpy as np
import time
import math
import matlab.engine
  

global adjust,indxlist
adjust=False

def get_data(fp):
    batch = list(fp.get_test_data())
    batch[0] = batch[0].unsqueeze(0).cuda()
    batch[1] = batch[1].cuda()
    batch[2] = batch[2].cuda()
    batch[3] = batch[3].cuda()
    batch[4] = batch[4].cuda()
    return batch

def test(model,fp):
    with torch.no_grad():
        batch = get_data(fp)
        boundary,inside_box,rooms,attrs,triples = batch
        model_out = model(
            rooms, 
            triples, 
            boundary,
            obj_to_img = None,
            attributes = attrs,
            boxes_gt= None, 
            generate = True,
            refine = True,
            relative = True,
            inside_box=inside_box
        )
        boxes_pred,  gene_layout, boxes_refine= model_out
        boxes_pred = boxes_pred.detach()
        boxes_pred = centers_to_extents(boxes_pred)
        boxes_refine = boxes_refine.detach()
        boxes_refine = centers_to_extents(boxes_refine)
        gene_layout = gene_layout*boundary[:,:1]
        gene_preds = torch.argmax(gene_layout.softmax(1).detach(),dim=1)
        return boxes_pred.squeeze().cpu().numpy(),gene_preds.squeeze().cpu().double().numpy(),boxes_refine.squeeze().cpu().numpy()

def load_model():
    
    model = Model()
    model.cuda(0)
    model.load_state_dict(
        torch.load('./model/model.pth', map_location={'cuda:0': 'cuda:0'}))
    model.eval()
    return model

def get_userinfo(userRoomID,adptRoomID):
    start = time.perf_counter()
    global model
    test_index = vw.testNameList.index(userRoomID.split(".")[0])
    test_data = vw.test_data[test_index]

    # boundary
    Boundary = test_data.boundary
    boundary=[[float(x),float(y),float(z),float(k)] for x,y,z,k in list(Boundary)]
    
    test_fp =FloorPlan(test_data)

    train_index = vw.trainNameList.index(adptRoomID.split(".")[0])
    train_data = vw.train_data[train_index]
    train_fp =FloorPlan(train_data,train=True)
    fp_end = test_fp.adapt_graph(train_fp)
    fp_end.adjust_graph()
    return fp_end


def get_userinfo_adjust(userRoomID,adptRoomID,NewGraph):
    global adjust,indxlist
    test_index = vw.testNameList.index(userRoomID.split(".")[0])
    test_data = vw.test_data[test_index]
    # boundary
    Boundary = test_data.boundary
    boundary=[[float(x),float(y),float(z),float(k)] for x,y,z,k in list(Boundary)]
    
    test_fp =FloorPlan(test_data)

    train_index = vw.trainNameList.index(adptRoomID.split(".")[0])
    train_data = vw.train_data[train_index]
    train_fp =FloorPlan(train_data,train=True)
    fp_end = test_fp.adapt_graph(train_fp)
    fp_end.adjust_graph()

    
    newNode = NewGraph[0]
    newEdge = NewGraph[1]
    oldNode = NewGraph[2]
    
    temp = []
    for newindx, newrmname, newx, newy,scalesize in newNode:
        for type, oldrmname, oldx, oldy, oldindx in oldNode:
            if (int(newindx) == oldindx):
                tmp=int(newindx), (newx - oldx), ( newy- oldy),float(scalesize)
                temp.append(tmp)
    newbox=[]
    print(adjust)
    if adjust==True:
        oldbox = []
        for i in range(len(vw.boxes_pred)):
            indxtmp=[vw.boxes_pred[i][0],vw.boxes_pred[i][1],vw.boxes_pred[i][2],vw.boxes_pred[i][3],vw.boxes_pred[i][0]]
            oldbox.append(indxtmp)
    if adjust==False:
        indxlist=[]
        oldbox=fp_end.data.box.tolist()
        for i in range(len(oldbox)):
            indxlist.append([oldbox[i][4]])
        indxlist=np.array(indxlist)
        adjust=True
    oldbox=fp_end.data.box.tolist()

    # print("oldbox",oldbox)
    # print(oldbox,"oldbox")
    X=0
    Y=0
    for i in range(len(oldbox)):
        X= X+(oldbox[i][2]-oldbox[i][0])
        Y= Y+(oldbox[i][3]-oldbox[i][1])
    x_ave=(X/len(oldbox))/2
    y_ave=(Y/len(oldbox))/2

    index_mapping = {}
    #  The room that already exists
    #  Move: Just by the distance
    for newindx, tempx, tempy,scalesize in temp:
        index_mapping[newindx] = len(newbox)
        tmpbox=[]
        scalesize = int(scalesize)
        if scalesize<1:
            scale = math.sqrt(scalesize)
            scalex = (oldbox[newindx][2] - oldbox[newindx][0]) * (1 - scale) / 2
            scaley = (oldbox[newindx][3] - oldbox[newindx][1]) * (1 - scale) / 2
            tmpbox = [(oldbox[newindx][0] + tempx) + scalex, (oldbox[newindx][1] + tempy)+scaley,
                      (oldbox[newindx][2] + tempx) - scalex, (oldbox[newindx][3] + tempy) - scaley, oldbox[newindx][4]]
        if scalesize == 1:
            tmpbox = [(oldbox[newindx][0] + tempx) , (oldbox[newindx][1] + tempy) ,(oldbox[newindx][2] + tempx), (oldbox[newindx][3] + tempy), oldbox[newindx][4]]

        if scalesize>1:
            scale=math.sqrt(scalesize)
            scalex = (oldbox[newindx][2] - oldbox[newindx][0]) * ( scale-1) / 2
            scaley = (oldbox[newindx][3] - oldbox[newindx][1]) * (scale-1) / 2
            tmpbox = [(oldbox[newindx][0] + tempx) - scalex, (oldbox[newindx][1] + tempy) - scaley,
                      (oldbox[newindx][2] + tempx) + scalex, (oldbox[newindx][3] + tempy) + scaley, oldbox[newindx][4]]

           
        newbox.append(tmpbox)

    #  The room just added
    #  Move: The room node with the average size of the existing room
    for newindx, newrmname, newx, newy,scalesize in newNode:
        if int(newindx)>(len(oldbox)-1):
            scalesize=int(float(scalesize))
            index_mapping[int(newindx)] = (len(newbox))
            tmpbox=[]
            if scalesize < 1:
                scale = math.sqrt(scalesize)
                scalex = x_ave * (1 - scale) / 2
                scaley = y_ave* (1 - scale) / 2
                tmpbox = [(newx-x_ave) +scalex,(newy-y_ave) +scaley,(newx+x_ave)-scalex,(newy+y_ave)-scaley,vocab['object_name_to_idx'][newrmname]]

            if scalesize == 1:
                tmpbox = [(newx - x_ave), (newy - y_ave), (newx + x_ave), (newy + y_ave),vocab['object_name_to_idx'][newrmname]]
            if scalesize > 1:
                scale = math.sqrt(scalesize)
                scalex = x_ave * (scale - 1) / 2
                scaley = y_ave * (scale - 1) / 2
                tmpbox = [(newx-x_ave) - scalex, (newy-y_ave)  - scaley,(newx+x_ave) + scalex, (newy+y_ave) + scaley,vocab['object_name_to_idx'][newrmname]]
            print(scalesize)
            newbox.append(tmpbox)

    fp_end.data.box=np.array(newbox)
    adjust_Edge=[]
    for u, v in newEdge:
        tmp=[index_mapping[int(u)],index_mapping[int(v)], 0]
        adjust_Edge.append(tmp)
    fp_end.data.edge=np.array(adjust_Edge)
    rNode = fp_end.get_rooms(tensor=False)

    rEdge = fp_end.get_triples(tensor=False)[:, [0, 2, 1]]
    Edge = [[float(u), float(v), float(type2)] for u, v, type2 in rEdge]

    s=time.perf_counter()
    boxes_pred, gene_layout, boxes_refeine = test(vw.model, fp_end)

    e=time.perf_counter()
    print(' model test time: %s Seconds' % (e - s))

    boxes_pred = boxes_pred * 255
    
    fp_end.data.gene = gene_layout
    rBox = boxes_pred[:]
    Box = [[float(x), float(y), float(z), float(k)] for x, y, z, k in rBox]

    boundary_mat = matlab.double(boundary)
    rNode_mat = matlab.double(rNode.tolist())
    print("rNode.tolist()",rNode.tolist())
    Edge_mat = matlab.double(Edge)
    
    Box_mat=matlab.double(Box)
    
    fp_end.data.boundary =np.array(boundary)
    fp_end.data.rType =np.array(rNode).astype(int)
    fp_end.data.refineBox=np.array(Box)
    fp_end.data.rEdge=np.array(Edge)
    gene_mat=matlab.double(np.array(fp_end.data.gene).tolist())
    startcom= time.perf_counter()
    box_refine =  vw.engview.align_fp(boundary_mat, Box_mat,  rNode_mat,Edge_mat,matlab.double(fp_end.data.gene.astype(float).copy().tolist()) ,18,False, nargout=3)
    endcom = time.perf_counter()
    print(' matlab.compute time: %s Seconds' % (endcom - startcom))
    box_out=box_refine[0]
    box_order=box_refine[1]

    rBoundary=box_refine[2]
    fp_end.data.newBox = np.array(box_out)
    fp_end.data.order = np.array(box_order)
    fp_end.data.rBoundary = [np.array(rb) for rb in rBoundary]
    return fp_end,box_out,box_order, gene_layout, boxes_refeine


def get_userinfo_net(userRoomID,adptRoomID):
    global model
    test_index = vw.testNameList.index(userRoomID.split(".")[0])
    test_data = vw.test_data[test_index]

    # boundary
    Boundary = test_data.boundary
    boundary = [[float(x), float(y), float(z), float(k)] for x, y, z, k in list(Boundary)]
    test_fp = FloorPlan(test_data)

    train_index = vw.trainNameList.index(adptRoomID.split(".")[0])
    train_data = vw.train_data[train_index]
    train_fp = FloorPlan(train_data, train=True)
    fp_end = test_fp.adapt_graph(train_fp)
    fp_end.adjust_graph()
    boxes_pred, gene_layout, boxes_refeine = test(model, fp_end)
    boxes_pred=boxes_pred*255
    for i in range(len(boxes_pred)):
        for j in range(len(boxes_pred[i])):
            boxes_pred[i][j]=float(boxes_pred[i][j])
    return fp_end,boxes_pred, gene_layout, boxes_refeine

if __name__ == "__main__":
    pass


utils.py

import numpy as np

# index,name,type(private/public),floorTexture
room_label = [(0, 'LivingRoom', 1, "PublicArea",[220, 213, 205]),
              (1, 'MasterRoom', 0, "Bedroom",[138, 113, 91]),
              (2, 'Kitchen', 1, "FunctionArea",[244, 245, 247]),
              (3, 'Bathroom', 0, "FunctionArea",[224, 225, 227]),
              (4, 'DiningRoom', 1, "FunctionArea",[200, 193, 185]),
              (5, 'ChildRoom', 0, "Bedroom",[198, 173, 151]),
              (6, 'StudyRoom', 0, "Bedroom",[178, 153, 131]),
              (7, 'SecondRoom', 0, "Bedroom",[158, 133, 111]),
              (8, 'GuestRoom', 0, "Bedroom",[189, 172, 146]),
              (9, 'Balcony', 1, "PublicArea",[244, 237, 224]),
              (10, 'Entrance', 1, "PublicArea",[238, 235, 230]),
              (11, 'Storage', 0, "PublicArea",[226, 220, 206]),
              (12, 'Wall-in', 0, "PublicArea",[226, 220, 206]),
              (13, 'External', 0, "External",[255, 255, 255]),
              (14, 'ExteriorWall', 0, "ExteriorWall",[0, 0, 0]),
              (15, 'FrontDoor', 0, "FrontDoor",[255,255,0]),
              (16, 'InteriorWall', 0, "InteriorWall",[128,128,128]),
              (17, 'InteriorDoor', 0, "InteriorDoor",[255,255,255])]

# color palette for nyu40 labels
def create_color_palette():
    return [
       (0, 0, 0),
       (174, 199, 232),		# wall
       (152, 223, 138),		# floor
       (31, 119, 180), 		# cabinet
       (255, 187, 120),		# bed
       (188, 189, 34), 		# chair
       (140, 86, 75),  		# sofa
       (255, 152, 150),		# table
       (214, 39, 40),  		# door
       (197, 176, 213),		# window
       (148, 103, 189),		# bookshelf
       (196, 156, 148),		# picture
       (23, 190, 207), 		# counter
       (178, 76, 76),  
       (247, 182, 210),		# desk
       (66, 188, 102), 
       (219, 219, 141),		# curtain
       (140, 57, 197), 
       (202, 185, 52), 
       (51, 176, 203), 
       (200, 54, 131), 
       (92, 193, 61),  
       (78, 71, 183),  
       (172, 114, 82), 
       (255, 127, 14), 		# refrigerator
       (91, 163, 138), 
       (153, 98, 156), 
       (140, 153, 101),
       (158, 218, 229),		# shower curtain
       (100, 125, 154),
       (178, 127, 135),
       (120, 185, 128),
       (146, 111, 194),
       (44, 160, 44),  		# toilet
       (112, 128, 144),		# sink
       (96, 207, 209), 
       (227, 119, 194),		# bathtub
       (213, 92, 176), 
       (94, 106, 211), 
       (82, 84, 163),  		# otherfurn
       (100, 85, 144)
    ]
color_palette = create_color_palette()[1:]

semantics_cmap = {
    'living room': '#e6194b',#[230,25,75]
    'kitchen': '#3cb44b',#[60,180,75]
    'bedroom': '#ffe119',#[255,225,25]
    'bathroom': '#0082c8',#[0,130,200]
    'balcony': '#f58230',#[245,130,48]
    'corridor': '#911eb4',#[145,30,180]
    'dining room': '#46f0f0',#[70,240,240]
    'study': '#f032e6',#[240,50,230]
    'studio': '#d2f53c',#[210,245,60]
    'store room': '#fabebe',#[250,190,190]
    'garden': '#008080',#[0,128,128]
    'laundry room': '#e6beff',#[230,190,255]
    'office': '#aa6e28',#[170,110,40]
    'basement': '#fffac8',#[255,250,200]
    'garage': '#800000',#[128,0,0]
    'undefined': '#aaffc3',#[170,255,195]
    'door': '#808000',#[128,128,0]
    'window': '#ffd7b4',#[255,215,180]
    'outwall': '#000000',#[0,0,0]
}

colormap_255 = [
    [230,  25,  75],#LivingRoom
    [ 60, 180,  75],#MasterRoom
    [170, 255, 195],#Kitchen
    [  0, 130, 200],#Bathroom
    [245, 130,  48],#DiningRoom
    [145,  30, 180],#ChildRoom
    [ 70, 240, 240],#StudyRoom
    [240,  50, 230],#SecondRoom
    [210, 245,  60],#GuestRoom
    [250, 190, 190],#Balcony
    [  0, 128, 128],#Entrance
    [230, 190, 255],#Storage
    [170, 110,  40],#Wall-in
    [255, 255, 255],#External
    [128,   0,   0],#ExteriorWall
    [255, 225,  25],#FrontDoor
    [128, 128, 128],#InteriorWall
    [255, 255, 255],#InteriorDoor
    #[255, 215, 180],
    [  0,   0, 128],
    [128, 128,   0],
    [255, 255, 255],
    [  0,   0,   0]
]

cmaps = {
    'nyu40': color_palette,
    'semantics': semantics_cmap,
    '255': colormap_255
}

category = [category for category in room_label if category[1] not in set(['External',
                                                                           'ExteriorWall', 'FrontDoor', 'InteriorWall', 'InteriorDoor'])]

num_category = len(category)

pixel2length = 18/256

def label2name(label=0):
    if label < 0 or label > 17:
        raise Exception("Invalid label!", label)
    else:
        return room_label[label][1]


def label2index(label=0):
    if label < 0 or label > 17:
        raise Exception("Invalid label!", label)
    else:
        return label


def index2label(index=0):
    if index < 0 or index > 17:
        raise Exception("Invalid index!", index)
    else:
        return index


def compute_centroid(mask):
    sum_h = 0
    sum_w = 0
    count = 0
    shape_array = mask.shape
    for h in range(shape_array[0]):
        for w in range(shape_array[1]):
            if mask[h, w] != 0:
                sum_h += h
                sum_w += w
                count += 1
    return (sum_h//count, sum_w//count)


def log(file, msg='', is_print=True):
    if is_print:
        print(msg)
    file.write(msg + '\n')
    file.flush()


def collide2d(bbox1, bbox2, th=0):
    return not(
        (bbox1[0]-th > bbox2[2]) or
        (bbox1[2]+th < bbox2[0]) or
        (bbox1[1]-th > bbox2[3]) or
        (bbox1[3]+th < bbox2[1])
    )
#
# def rot90_2D(pts,k=1,cnt=np.array([127.5,127.5])):
#     ang = k*np.pi/2
#     R = np.array([[np.cos(ang),np.sin(ang)],[-np.sin(ang),np.cos(ang)]])
#     return np.dot(pts-cnt,R)+cnt
# def fliplr_2D(pts,size=255):
#     return np.stack([pts[:,0],size-pts[:,1]],1)
#
# def align_image(image,rot_old,rot_new=0):
#     k = np.ceil((rot_old-rot_new+2*np.pi)%(2*np.pi)/(np.pi/4))//2
#     return np.rot90(image,k)
#
# def align_box(box,rot_old,rot_new=0):
#     k = np.ceil((rot_old-rot_new+2*np.pi)%(2*np.pi)/(np.pi/4))//2
#     box = rot90_2D(box.reshape(-1,2),k).reshape(-1,4)
#     return np.concatenate([np.minimum(box[:,:2],box[:,2:]),np.maximum(box[:,:2],box[:,2:])],-1)#.round().astype(int)
#
# def fliplr_box(box,size=255):
#     box=fliplr_2D(box.reshape(-1,2),size=size).reshape(-1,4)
#     return np.concatenate([np.minimum(box[:,:2],box[:,2:]),np.maximum(box[:,:2],box[:,2:])],-1)#.round().astype(int)


def rot90_2D(pts, k=1, cnt=np.array([127.5, 127.5])):
    ang = k * np.pi / 2
    R = np.array([[np.cos(ang), np.sin(ang)], [-np.sin(ang), np.cos(ang)]])
    return np.dot(pts - cnt, R) + cnt


def fliplr_2D(pts, size=255):
    return np.stack([pts[:, 0], size - pts[:, 1]], 1)


def align_image(image, rot_old, rot_new=0):
    k = np.ceil((rot_old - rot_new + 2 * np.pi) % (2 * np.pi) / (np.pi / 4)) // 2
    return np.rot90(image, k)


def align_box(box, rot_old, rot_new=0):
    k = np.ceil((rot_old - rot_new + 2 * np.pi) % (2 * np.pi) / (np.pi / 4)) // 2
    box = rot90_2D(box.reshape(-1, 2), k).reshape(-1, 4)
    return np.concatenate([np.minimum(box[:, :2], box[:, 2:]), np.maximum(box[:, :2], box[:, 2:]) + 1],
                          -1).round().astype(int)


def align_points(points, rot_old, rot_new=0):
    k = np.ceil((rot_old - rot_new + 2 * np.pi) % (2 * np.pi) / (np.pi / 4)) // 2
    points = rot90_2D(points, k)
    return points.round().astype(int)

def graph2labels(graph):
    edges = graph.edges
    return sorted([
        tuple(sorted((room_label[graph.nodes[u]['category']][1],
        room_label[graph.nodes[v]['category']][1])))
        for u,v in edges
    ])

def graph2labels_withtype(graph):
    edges = graph.edges(data=True)
    return sorted([
        ('acc' if d['type'] else 'adj',
        *sorted(
            (room_label[graph.nodes[u]['category']][1],
            room_label[graph.nodes[v]['category']][1]))
        ) 
        for u,v,d in edges
    ])

def graph2functions(graph):
    edges = graph.edges
    return sorted([
        tuple(sorted((graph.nodes[u]['function'],
        graph.nodes[v]['function'])))
        for u,v in edges
    ])

def graph2functions_withtype(graph):
    edges = graph.edges(data=True)
    return sorted([
        ('acc' if d['type'] else 'adj',
        *sorted(
            (graph.nodes[u]['function'],
            graph.nodes[v]['function']))
        )
        for u,v,d in edges
    ])

def counter2labels(counter):
    return sorted({
        room_label[key][1]:value 
        for key,value in counter.items()
    }.items())

def counter2functions(counter):
    counter_new = {
        room_label[key][1]:value 
        for key,value in counter.items()
    }
    counter_new['Bedroom']=0
    for key in counter:
        if room_label[key][3]=='Bedroom':
            counter_new['Bedroom']+=counter_new.pop(room_label[key][1])
    return sorted(counter_new.items())

def point_box_relation(u,vbox):
    uy,ux = u
    vy0, vx0, vy1, vx1 = vbox

    if (ux<vx0 and uy<=vy0) or (ux==vx0 and uy==vy0):
        relation = 'left-above'
    elif (vx0<=ux<vx1 and uy<=vy0):
        relation = 'above'
    elif (vx1<=ux and uy<vy0) or (ux==vx1 and uy==vy0):
        relation = 'right-above'
    elif (vx1<=ux and vy0<=uy<vy1):
        relation = 'right-of'
    elif (vx1<ux and vy1<=uy) or (ux==vx1 and uy==vy1):
        relation = 'right-below'
    elif (vx0<ux<=vx1 and vy1<=uy):
        relation = 'below'
    elif (ux<=vx0 and vy1<uy) or (ux==vx0 and uy==vy1):
        relation = 'left-below'
    elif(ux<=vx0 and vy0<uy<=vy1):
        relation = "left-of"
    elif(vx0<ux<vx1 and vy0<uy<vy1):
        relation = "inside"

    return relation

def get_vocab():
    room_label = [(0, 'LivingRoom', 1, "PublicArea"),
              (1, 'MasterRoom', 0, "Bedroom"),
              (2, 'Kitchen', 1, "FunctionArea"),
              (3, 'Bathroom', 0, "FunctionArea"),
              (4, 'DiningRoom', 1, "FunctionArea"),
              (5, 'ChildRoom', 0, "Bedroom"),
              (6, 'StudyRoom', 0, "Bedroom"),
              (7, 'SecondRoom', 0, "Bedroom"),
              (8, 'GuestRoom', 0, "Bedroom"),
              (9, 'Balcony', 1, "PublicArea"),
              (10, 'Entrance', 1, "PublicArea"),
              (11, 'Storage', 0, "PublicArea"),
              (12, 'Wall-in', 0, "PublicArea"),
              (13, 'External', 0, "External"),
              (14, 'Internal', 0, "Internal")]
    
    predicates = [
        'left-above',
        'left-below',
        'left-of',
        'above',
        'inside',
        'surrounding',
        'below',
        'right-of',
        'right-above',
        'right-below'
    ]

    door_pos = [
        'nan',
        'bottom',
        'bottom-right','right-bottom',
        'right',
        'right-top','top-right',
        'top',
        'top-left','left-top',
        'left',
        'left-bottom','bottom-left'
    ]

    vocab = {
        'object_name_to_idx':{},
        'object_to_idx':{},
        'object_idx_to_name':[],
        'pred_idx_to_name':[],
        'pred_name_to_idx':{},
        'door_idx_to_name':[],
        'door_name_to_idx':{}
    }
    
    vocab['object_name_to_idx'] = { label:index for index,label,_,_ in room_label[:] }
    vocab['object_to_idx'] = {str(index):index for index,lable,_,_ in room_label}
    vocab['object_idx_to_name'] = [label for index,label,_,_ in room_label]
    vocab['pred_idx_to_name'] = [p for i,p in enumerate(predicates)]
    vocab['pred_name_to_idx'] = {p:i for i,p in enumerate(predicates)}
    vocab['door_idx_to_name'] = [p for i,p in enumerate(door_pos)]
    vocab['door_name_to_idx'] = {p:i for i,p in enumerate(door_pos)}

    return vocab

vocab = get_vocab()


######################################
retrieval
######################################

retrieval.py

import numpy as np
import time
import Houseweb.views as vw
def compute_tf(b):
    '''
    input: boundary points array (x,y,dir,isNew)
    return: tf.x, tf.y
    '''
    if b.shape[1]>2:
        b=b[:,:2]
    b = np.concatenate((b,b[:1]))
    nPoint = len(b)-1
    lineVec = b[1:]-b[:-1]
    lineLength = np.linalg.norm(lineVec,axis=1)
    
    perimeter = lineLength.sum()
    lineVec = lineVec/perimeter
    lineLength = lineLength/perimeter

    angles = np.zeros(nPoint)
    for i in range(nPoint):
        z = np.cross(lineVec[i],lineVec[(i+1)%nPoint])
        sign = np.sign(z)
        angles[i] = np.arccos(np.dot(lineVec[i],lineVec[(i+1)%nPoint]))*sign

    x = np.zeros(nPoint+1)
    y = np.zeros(nPoint+1)
    s = 0
    for i in range(1,nPoint+1):
        x[i] = lineLength[i-1]+x[i-1]
        y[i-1] = angles[i-1]+s
        s = y[i-1]
    y[-1] = s
    return x,y

def sample_tf(x,y,ndim=1000):
    '''
    input: tf.x,tf.y, ndim
    return: n-dim tf values
    '''
    t = np.linspace(0,1,ndim)
    return np.piecewise(t,[t>=xx for xx in x],y)

class DataRetriever():
    def __init__(self,tf_train,centroids,clusters):
        '''
        tf_train: tf of training data
        centroids: tf cluster centroids of training data
        clusters: data index for each cluster of training data
        '''
        self.tf_train = tf_train
        self.centroids = centroids
        self.clusters = clusters
    
    def retrieve_bf(self,datum,k=20):
        # compute tf for the data boundary
        x,y = compute_tf(datum.boundary)
        y_sampled = sample_tf(x,y,1000)
        dist = np.linalg.norm(y_sampled-self.tf_train,axis=1)
        if k>np.log2(len(self.tf_train)):
            index = np.argsort(dist)[:k]
        else:
            index = np.argpartition(dist,k)[:k]
            index = index[np.argsort(dist[index])]
        return index

    def retrieve_cluster(self,datum,k=20,multi_clusters=False):
        '''
        datum: test data
        k: retrieval num
        return: index for training data 
        '''
        # compute tf for the data boundary
        x,y = compute_tf(datum.boundary)
        y_sampled = sample_tf(x,y,1000)
        # compute distance to cluster centers
        dist = np.linalg.norm(y_sampled-self.centroids,axis=1)

        if multi_clusters:
            # more candicates
            c = int(np.max(np.clip(np.log2(k),1,5)))
            cluster_idx = np.argsort(dist)[:c]
            cluster = np.unique(self.clusters[cluster_idx].reshape(-1))
        else:
            # only candicates
            cluster_idx = np.argmin(dist)
            cluster = self.clusters[cluster_idx]

        # compute distance to cluster samples
        dist = np.linalg.norm(y_sampled-self.tf_train[cluster],axis=1)
        index = cluster[np.argsort(dist)[:k]]
        return index

def retrieval(test_data,k,multi_clusters):

    retriever = DataRetriever(vw.tf_train,vw.centroids,vw.clusters)
    datum = test_data
    # vis_boundary(datum.boundary)

    t1 = time.perf_counter()
    index = retriever.retrieve_cluster(datum,k,multi_clusters)
    t2 = time.perf_counter()
    print('cluster',t2-t1)
    data_retrieval = vw.train_data[index]
    # data_retrieval= trainNameList[index]
    # vis_boundary(data_retrieval[0].boundary)

    # t1 = time()
    # index = retriever.retrieve_bf(datum,k=10)
    # t2 = time()
    # print('bf',t2-t1)
    # data_retrieval = train_data[index]
    return index

def vis_boundary(b):
    import cv2
    import matplotlib.pyplot as plt
    img = np.ones((256,256,3))
    img = cv2.line(img,tuple(b[0,:2]),tuple(b[1,:2]),(1.,1.,0.),thickness=2)
    for i in range(1,len(b)-1):
        img = cv2.line(img,tuple(b[i,:2]),tuple(b[i+1,:2]),(0.,0.,0.),thickness=2)
    img = cv2.line(img,tuple(b[0,:2]),tuple(b[-1,:2]),(0.,0.,0.),thickness=2)
    plt.imshow(img)
    plt.show()

if __name__ == "__main__":
    import scipy.io as sio
    import pickle
    from time import time
    import cv2
    import matplotlib.pyplot as plt

    def vis_boundary(b):
        img = np.ones((256,256,3))
        img = cv2.line(img,tuple(b[0,:2]),tuple(b[1,:2]),(1.,1.,0.),thickness=2)
        for i in range(1,len(b)-1):
            img = cv2.line(img,tuple(b[i,:2]),tuple(b[i+1,:2]),(0.,0.,0.),thickness=2)
        img = cv2.line(img,tuple(b[0,:2]),tuple(b[-1,:2]),(0.,0.,0.),thickness=2)
        plt.imshow(img)
        plt.show()

    #data_train = sio.loadmat('data_train70.mat',squeeze_me=True,struct_as_record=False)['data']
    #data_test = #sio.loadmat('data_test15.mat',squeeze_me=True,struct_as_record=False)['data']
    t1 = time()
    train_data = pickle.load(open('data_train_converted.pkl','rb'))['data']
    t2 = time()
    print('load train',t2-t1)

    t1 = time()
    test_data = pickle.load(open('data_test_converted.pkl','rb'))
    test_data, testNameList, trainNameList = test_data['data'], list(test_data['testNameList']), list(
        test_data['trainNameList'])
    t2 = time()
    print('load test',t2-t1)

    t1 = time()
    tf_train = np.load('tf_train.npy')
    centroids = np.load('centroids_train.npy')
    clusters = np.load('clusters_train.npy')
    t2 = time()
    print('load tf/centroids/clusters',t2-t1)

    retriever = DataRetriever(tf_train,centroids,clusters)

    datum = np.random.choice(test_data,1)[0]
    vis_boundary(datum.boundary)

    t1 = time()
    index = retriever.retrieve_cluster(datum,k=10,multi_clusters=False)
    t2 = time()
    print('cluster',t2-t1)
    data_retrieval = train_data[index]
    vis_boundary(data_retrieval[0].boundary)

    t1 = time()
    index = retriever.retrieve_bf(datum,k=10)
    t2 = time()
    print('bf',t2-t1)
    data_retrieval = train_data[index]
    vis_boundary(data_retrieval[0].boundary)
